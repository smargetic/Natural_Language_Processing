{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smargetic/Natural_Language_Processing/blob/main/Machine_Translation/Translation_Model_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-eYx0G4p02W",
        "outputId": "794cdcc6-f4d1-47b1-be92-c36a7a51b05f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (7.16.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.1.5)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.1.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nbconvert) (24.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (2.18.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert) (1.4.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert) (4.3.6)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from nbclient>=0.5.0->nbconvert) (6.1.12)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert) (4.23.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert) (2.6)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.22.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.8.2)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.3.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat>=5.7->nbconvert) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nbconvert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E38McwRXbyKA",
        "outputId": "1070f019-37cf-4864-f4fe-d364c38cb978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#data storage - not sure if important\n",
        "import pandas as pd\n",
        "import numpy as np #can take away later\n",
        "\n",
        "#make sure to show all values in pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "#pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# import tensorflow as tf\n",
        "\n",
        "#visualize\n",
        "from IPython.display import display\n",
        "\n",
        "#help import other functions\n",
        "import os\n",
        "\n",
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Disable scientific notation\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "#for list comprehension\n",
        "import itertools\n",
        "\n",
        "# #cummulative list\n",
        "# from itertools import accumulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FJRgbpQDJyVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04ad2eb-f23e-471f-d733-adc457c8d964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Files currently present:\n",
            "['sentences_base.csv', 'ita_sentences_CC0.tsv', 'eng_sentences_detailed.tsv', 'eng_sentences.tsv', 'ita_sentences_detailed.tsv', 'eng_sentences_CC0.tsv', 'ita_sentences.tsv', 'Sentence pairs in English-Italian - 2024-07-26.tsv', 'Helper_Functions.ipynb', 'Model_Train_Predict.ipynb', '__pycache__', 'Data_Intake_and_Preprocessing.ipynb', 'intake_preprocess_utils.ipynb', 'intake_preprocess_utils.py', 'Neural_Net.ipynb']\n",
            "[NbConvertApp] Converting notebook intake_preprocess_utils.ipynb to script\n",
            "[NbConvertApp] Writing 11518 bytes to intake_preprocess_utils.txt\n",
            "\n",
            "\n",
            "New files in current directory:\n",
            "['sentences_base.csv', 'ita_sentences_CC0.tsv', 'eng_sentences_detailed.tsv', 'eng_sentences.tsv', 'ita_sentences_detailed.tsv', 'eng_sentences_CC0.tsv', 'ita_sentences.tsv', 'Sentence pairs in English-Italian - 2024-07-26.tsv', 'Helper_Functions.ipynb', 'Model_Train_Predict.ipynb', '__pycache__', 'Data_Intake_and_Preprocessing.ipynb', 'intake_preprocess_utils.ipynb', 'intake_preprocess_utils.py', 'Neural_Net.ipynb']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##to obtain functions from another .ipynb file\n",
        "\n",
        "#go to current directory\n",
        "os.chdir('/content/drive/My Drive/Coding Projects/Machine Translation')\n",
        "\n",
        "#List the files in the current directory\n",
        "print('\\nFiles currently present:')\n",
        "print(os.listdir())\n",
        "\n",
        "#Convert the notebook to a Python script\n",
        "!jupyter nbconvert --to script intake_preprocess_utils.ipynb\n",
        "os.rename('intake_preprocess_utils.txt', 'intake_preprocess_utils.py')\n",
        "\n",
        "print('\\n\\nNew files in current directory:')\n",
        "print(os.listdir())\n",
        "print('\\n\\n')\n",
        "\n",
        "#import functions\n",
        "from intake_preprocess_utils import get_file_and_disp, get_sample, dump_sample, data_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HOifKYsyxoIs"
      },
      "outputs": [],
      "source": [
        "# #english to italian translation - just to test\n",
        "# df_eng_it = get_file_and_disp(fileName=\"Sentence pairs in English-Italian - 2024-07-26.tsv.zip\" ,sep='\\t', stringName=\"English to Italian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mRoEVDsAWxDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c4a71266-1bce-4631-851d-ab7d007a70d7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   0                   1  2                    3\n",
              "0  1         hello world  1           ciao mondo\n",
              "1  2         how are you  2            come stai\n",
              "2  3  where are we going  3  dove stiamo andando"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8ae5ab7-f47a-4f85-9637-57f431f17fd9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>hello world</td>\n",
              "      <td>1</td>\n",
              "      <td>ciao mondo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how are you</td>\n",
              "      <td>2</td>\n",
              "      <td>come stai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>where are we going</td>\n",
              "      <td>3</td>\n",
              "      <td>dove stiamo andando</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8ae5ab7-f47a-4f85-9637-57f431f17fd9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8ae5ab7-f47a-4f85-9637-57f431f17fd9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8ae5ab7-f47a-4f85-9637-57f431f17fd9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-64ad1c0f-6da5-496b-9abc-59e75b460958\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64ad1c0f-6da5-496b-9abc-59e75b460958')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-64ad1c0f-6da5-496b-9abc-59e75b460958 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fae89efa-2bc3-41c4-9e72-d09f584202a4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fae89efa-2bc3-41c4-9e72-d09f584202a4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hello world\",\n          \"how are you\",\n          \"where are we going\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ciao mondo\",\n          \"come stai\",\n          \"dove stiamo andando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#test data set\n",
        "df = pd.DataFrame({\n",
        "                  0:[1,2,3],\n",
        "                  1:[\"hello world\", \"how are you\", \"where are we going\"],\n",
        "                  2:[1,2,3],\n",
        "                  3: [\"ciao mondo\", \"come stai\", \"dove stiamo andando\"]})\n",
        "\n",
        "display(df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QmDxJKD6dQ2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b6b9ce5-0acb-401f-baa6-fe033eb3a0c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nulls in English: 0\n",
            "Nulls in Italian: 0\n",
            "\n",
            "English/Italian Translations:\n",
            "\tEnglish vocabulary size: 11\n",
            "\tItalian vocabulary size: 10\n",
            "\n",
            "Done with Pytorch.\n",
            "\n",
            "English-Italian Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   eng_id        eng_sentence  it_id          it_sentence  \\\n",
              "0       1         hello world      1           ciao mondo   \n",
              "1       2         how are you      2            come stai   \n",
              "2       3  where are we going      3  dove stiamo andando   \n",
              "\n",
              "                              eng_tokens  \\\n",
              "0           [<sos>, hello, world, <eos>]   \n",
              "1          [<sos>, how, are, you, <eos>]   \n",
              "2  [<sos>, where, are, we, going, <eos>]   \n",
              "\n",
              "                               it_tokens      eng_tokens_enc    it_tokens_enc  \\\n",
              "0            [<sos>, ciao, mondo, <eos>]        [1, 5, 9, 2]     [1, 4, 7, 2]   \n",
              "1             [<sos>, come, stai, <eos>]    [1, 6, 3, 10, 2]     [1, 5, 8, 2]   \n",
              "2  [<sos>, dove, stiamo, andando, <eos>]  [1, 8, 3, 7, 4, 2]  [1, 6, 9, 3, 2]   \n",
              "\n",
              "                                                      eng_tokens_enc_p  \\\n",
              "0   [tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]   \n",
              "1  [tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]   \n",
              "2   [tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]   \n",
              "\n",
              "                                           it_tokens_enc_p  \n",
              "0  [tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]  \n",
              "1  [tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]  \n",
              "2  [tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e16e4bfb-b9d9-40e0-9c57-0b0593e0b788\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng_id</th>\n",
              "      <th>eng_sentence</th>\n",
              "      <th>it_id</th>\n",
              "      <th>it_sentence</th>\n",
              "      <th>eng_tokens</th>\n",
              "      <th>it_tokens</th>\n",
              "      <th>eng_tokens_enc</th>\n",
              "      <th>it_tokens_enc</th>\n",
              "      <th>eng_tokens_enc_p</th>\n",
              "      <th>it_tokens_enc_p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>hello world</td>\n",
              "      <td>1</td>\n",
              "      <td>ciao mondo</td>\n",
              "      <td>[&lt;sos&gt;, hello, world, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, ciao, mondo, &lt;eos&gt;]</td>\n",
              "      <td>[1, 5, 9, 2]</td>\n",
              "      <td>[1, 4, 7, 2]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how are you</td>\n",
              "      <td>2</td>\n",
              "      <td>come stai</td>\n",
              "      <td>[&lt;sos&gt;, how, are, you, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, come, stai, &lt;eos&gt;]</td>\n",
              "      <td>[1, 6, 3, 10, 2]</td>\n",
              "      <td>[1, 5, 8, 2]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>where are we going</td>\n",
              "      <td>3</td>\n",
              "      <td>dove stiamo andando</td>\n",
              "      <td>[&lt;sos&gt;, where, are, we, going, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, dove, stiamo, andando, &lt;eos&gt;]</td>\n",
              "      <td>[1, 8, 3, 7, 4, 2]</td>\n",
              "      <td>[1, 6, 9, 3, 2]</td>\n",
              "      <td>[tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e16e4bfb-b9d9-40e0-9c57-0b0593e0b788')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e16e4bfb-b9d9-40e0-9c57-0b0593e0b788 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e16e4bfb-b9d9-40e0-9c57-0b0593e0b788');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cf21d242-8cb5-42e5-8833-6f3da8eeaf3b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf21d242-8cb5-42e5-8833-6f3da8eeaf3b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cf21d242-8cb5-42e5-8833-6f3da8eeaf3b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  display(data_dict[key])\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"eng_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hello world\",\n          \"how are you\",\n          \"where are we going\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ciao mondo\",\n          \"come stai\",\n          \"dove stiamo andando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 5, 9, 2, 0, 0])\",\n          \"tensor([ 1,  6,  3, 10,  2,  0])\",\n          \"tensor([1, 8, 3, 7, 4, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 4, 7, 2, 0])\",\n          \"tensor([1, 5, 8, 2, 0])\",\n          \"tensor([1, 6, 9, 3, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian SING Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f53dccbf690>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'are': 3,\n",
              " 'going': 4,\n",
              " 'hello': 5,\n",
              " 'how': 6,\n",
              " 'we': 7,\n",
              " 'where': 8,\n",
              " 'world': 9,\n",
              " 'you': 10,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'andando': 3,\n",
              " 'ciao': 4,\n",
              " 'come': 5,\n",
              " 'dove': 6,\n",
              " 'mondo': 7,\n",
              " 'stai': 8,\n",
              " 'stiamo': 9,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#go through preprocessing\n",
        "data_dict= data_preprocessing(df.copy(), pytorchB=True, tensorflowB=False, store=False, sample=False, download=False, sing=False)\n",
        "for key in data_dict.keys():\n",
        "  print('\\n'+key+':')\n",
        "  display(data_dict[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FuiybsIls7m1"
      },
      "outputs": [],
      "source": [
        "#forward input: (batch size (aka. # sentences), # words in sentence (including padding))\n",
        "#forward output: (batch size (aka. # sentences), # words in sentence (including padding), embedding dim)\n",
        "class Embedding_Node(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Embedding_Node, self).__init__()\n",
        "\n",
        "    self.W_e = nn.Parameter(torch.randn(vocab_size, embedding_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.W_e[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tjcCtOuDuH_t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "09a03f6d-1f8c-4c73-bec0-fd5228edc9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "batch:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 1,  6,  3, 10,  2,  0],\n",
              "        [ 1,  5,  9,  2,  0,  0],\n",
              "        [ 1,  8,  3,  7,  4,  2]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1, 5, 8, 2, 0],\n",
              "        [1, 4, 7, 2, 0],\n",
              "        [1, 6, 9, 3, 2]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "batch:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 1,  6,  3, 10,  2,  0],\n",
              "        [ 1,  5,  9,  2,  0,  0],\n",
              "        [ 1,  8,  3,  7,  4,  2]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1, 5, 8, 2, 0],\n",
              "        [1, 4, 7, 2, 0],\n",
              "        [1, 6, 9, 3, 2]])"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "### Seperates data into batches --> NEED TO GO OVER\n",
        "\n",
        "for input_batch, target_batch in data_dict['English-Italian Pytorch Dataloader']:\n",
        "  print('\\nbatch:')\n",
        "  display(input_batch)\n",
        "  display(target_batch)\n",
        "\n",
        "print('\\n\\nbatch:')\n",
        "display(input_batch)\n",
        "display(target_batch)\n",
        "\n",
        "#get input and output\n",
        "input, output = input_batch, target_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "odBJfqGfnoLZ"
      },
      "outputs": [],
      "source": [
        "class RNN_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, input_dim):\n",
        "    super(RNN_Node, self).__init__()\n",
        "\n",
        "    #all parameters that go into the rnn node\n",
        "    self.layer_weight = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
        "    self.hidden_weight = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.bias = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #store dimensions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dim = input_dim\n",
        "\n",
        "  #forward pass is how its connected to the next rnn node (regardless of layer or column)\n",
        "  def forward(self, input, prev_hidden):\n",
        "    #broadcast bias\n",
        "    bias = self.bias.expand(input.shape[0], self.hidden_dim)\n",
        "\n",
        "    #get hidden node\n",
        "    hidden_node = torch.sigmoid(torch.matmul(self.hidden_weight, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.layer_weight, input.T).T+\n",
        "                                     bias) #could also do tanh instead of sigmoid\n",
        "\n",
        "    return hidden_node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xuBYxuXSsus3"
      },
      "outputs": [],
      "source": [
        "class LSTM_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, embed_dim):\n",
        "    super(LSTM_Node, self).__init__()\n",
        "\n",
        "    #forget weight / prev layer forget weight / forget bias\n",
        "    self.W_f = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_f = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_f = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #input weight / prev layer input weight / input bias\n",
        "    self.W_i = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_i = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_i = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #output weight / prev layer output weight / output bis\n",
        "    self.W_o = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_o = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_o = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #cell weight / prev layer cell weight / cell bias\n",
        "    self.W_c = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_c = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_c = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #store dimensions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "\n",
        "  #forward pass is how its connected to the next lstm node (regardless of layer or column)\n",
        "  def forward(self, input, prev_hidden, prev_cell):\n",
        "\n",
        "\n",
        "    #broadcast bias\n",
        "    b_f = self.b_f.expand(input.shape[0], self.hidden_dim)\n",
        "    b_i = self.b_i.expand(input.shape[0], self.hidden_dim)\n",
        "    b_o = self.b_o.expand(input.shape[0], self.hidden_dim)\n",
        "    b_c = self.b_c.expand(input.shape[0], self.hidden_dim)\n",
        "\n",
        "\n",
        "    #forget\n",
        "    f_t = torch.sigmoid(torch.matmul(self.W_f, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_f, input.T).T+\n",
        "                                     b_f)\n",
        "    #input\n",
        "    i_t = torch.sigmoid(torch.matmul(self.W_i, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_i, input.T).T+\n",
        "                                     b_i)\n",
        "    #output\n",
        "    o_t = torch.sigmoid(torch.matmul(self.W_o, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_o, input.T).T+\n",
        "                                     b_o)\n",
        "\n",
        "    #new cell data\n",
        "    nc_t = torch.tanh(torch.matmul(self.W_c, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_c, input.T).T+\n",
        "                                     b_c)\n",
        "\n",
        "    #cell\n",
        "    c_t = f_t*prev_cell + i_t*nc_t\n",
        "\n",
        "    #hidden\n",
        "    h_t = o_t*torch.tanh(c_t)\n",
        "\n",
        "    return h_t, c_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dHlOA5i1SlyU"
      },
      "outputs": [],
      "source": [
        "def add_norm(prev_x, new_x):\n",
        "  x = torch.cat(prev_x, new_x, dim=0)\n",
        "  x = nn.LayerNorm(x)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JuQ3OUL-hvFx"
      },
      "outputs": [],
      "source": [
        "class Transformer_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, embed_dim, ff_dim, decoder=False):\n",
        "    super(Transformer_Node, self).__init__()\n",
        "\n",
        "    ##layers##\n",
        "    #attention\n",
        "    self.attention = Attention_Node(hidden_dim)\n",
        "    self.decoder = decoder\n",
        "    if(decoder):\n",
        "      self.decoder_encoder_att = Attention_Node(hidden_dim)\n",
        "\n",
        "    #feed forwards\n",
        "    self.linear1 = nn.Linear(hidden_dim, ff_dim)\n",
        "    self.linear2 = nn.Linear(ff_dim, hidden_dim)\n",
        "\n",
        "\n",
        "  #how its connected to the next transformer node\n",
        "  def forward(self, inputs, encoder_hidden=None):\n",
        "    #multihead attention (with mask option) ?\n",
        "    if(self.decoder): # if decoder, only look at values before\n",
        "      attention_out = self.attention.forward(inputs, inputs, masked=True)\n",
        "    else:\n",
        "      attention_out = self.attention.forward(inputs, inputs)\n",
        "\n",
        "    #add and norm\n",
        "    x = add_norm(inputs, attention_out)\n",
        "\n",
        "    #encoder decoder attention\n",
        "    if(self.decoder):\n",
        "      x_prev = x\n",
        "      self.decoder_encoder_att.forward(encoder_hidden, x)\n",
        "      x = add_norm(x_prev, x)\n",
        "\n",
        "    x_prev = x\n",
        "    #feed forward\n",
        "    x = self.linear1(x)\n",
        "    x = self.linear2(x)\n",
        "\n",
        "    #activation function\n",
        "    x = nn.relu(x)\n",
        "\n",
        "    #add and norm\n",
        "    x = add_norm(x_prev, x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZubrtWaX4r7z"
      },
      "outputs": [],
      "source": [
        "#for this, we basically said that what should be in the __init__ function should be any parameters that could be learned\n",
        "\n",
        "#ok, so for node elements, we'll say that in the __init__ funciton we should have the parameters whos weight should be learned\n",
        "#but for nn layers, well have things that define the layers/ hyperparameters\n",
        "\n",
        "#__init__ layer = anything that needs to be consistently referenced in forward pass (especially parameters that need to be updated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0a0efF-QRWMP"
      },
      "outputs": [],
      "source": [
        "#define initial hidden states at run time - b/c of batch size\n",
        "def init_hidden(self, batch_size):\n",
        "  #get device\n",
        "  device = next(self.parameters()).device\n",
        "\n",
        "  #itialize tens based on node type\n",
        "  init_hidden_tensor = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "  init_cell_tensor = None\n",
        "  if(self.node_type==\"lstm\"):\n",
        "    init_cell_tensor = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "  return init_hidden_tensor, init_cell_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KUrdwxzVmO4E"
      },
      "outputs": [],
      "source": [
        "class EncoderNN(nn.Module):\n",
        "  def __init__(self, node_type, n_layers, hidden_dim, embed_dim, vocab_size):\n",
        "    super(EncoderNN, self).__init__()\n",
        "    # self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    #model parameters\n",
        "    self.n_layers = n_layers\n",
        "    self.node_type = node_type\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    #define embedding node\n",
        "    self.embedding_node = Embedding_Node(vocab_size, embed_dim)\n",
        "\n",
        "\n",
        "    #create layer of nodes based on type\n",
        "    node_class = RNN_Node if node_type == \"rnn\" else LSTM_Node\n",
        "    self.nodes = nn.ModuleList(\n",
        "          [node_class(hidden_dim, embed_dim)] +\n",
        "          [node_class(hidden_dim, hidden_dim) for _ in range(n_layers - 1)])\n",
        "\n",
        "  #forward pass\n",
        "  def forward(self, inputs):\n",
        "    #get blank nodes\n",
        "    node_list = self.nodes\n",
        "\n",
        "    #get shape params\n",
        "    batch_size = inputs.shape[0]\n",
        "    seq_size = inputs.shape[1]\n",
        "\n",
        "    #get initial states\n",
        "    # hidden_list, cell_list = self.init_hidden(inputs.shape[0])\n",
        "    hidden_tensor, cell_tensor = init_hidden(self, batch_size)\n",
        "    last_layer_hidden = torch.zeros(batch_size, seq_size, self.hidden_dim)\n",
        "\n",
        "    #turn input into embedding\n",
        "    embed_input = self.embedding_node.forward(inputs)\n",
        "\n",
        "    #iterate over each word in sentence\n",
        "    for word_i in range(0, seq_size):\n",
        "\n",
        "      input = embed_input[:,word_i] #input = (batch_size, hidden_dim) ##1 for each word\n",
        "\n",
        "      for layer in range(0,self.n_layers):\n",
        "        #if not first layer, then input is previous hidden state\n",
        "        if layer!=0:\n",
        "          input = hidden_tensor[layer-1]\n",
        "\n",
        "        #TRY TO SEE IF CAN MAKE NEATER\n",
        "        #forward pass -- TRY TO FIX LATER - AFTER TRANSFORMER\n",
        "        if(self.node_type==\"rnn\"):\n",
        "          hidden_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer]) # (batch, hidden dim)\n",
        "        elif(self.node_type=='lstm'):\n",
        "          hidden_tensor[layer], cell_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer], cell_tensor[layer]) # both of size (batch, hidden dim)\n",
        "\n",
        "      #store final hidden layer for each word - for attention\n",
        "      last_layer_hidden[:, word_i, :self.hidden_dim] = hidden_tensor[-1]\n",
        "\n",
        "    #format outputs\n",
        "    outputs = (hidden_tensor[-1], None) if self.node_type==\"rnn\" else (hidden_tensor[-1], cell_tensor[-1]) if self.node_type=='lstm' else None\n",
        "\n",
        "    return outputs, last_layer_hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "ctGekK2XXec4"
      },
      "outputs": [],
      "source": [
        "class Attention_Node(nn.Module):\n",
        "  def __init__(self, enc_hidden_dim, dec_hidden_dim, key_dim, query_dim, val_dim, score_dim=None, sim_method='dot', masked=False):\n",
        "    super(Attention_Node, self).__init__()\n",
        "\n",
        "    #dimensions\n",
        "    self.enc_hidden_dim = enc_hidden_dim\n",
        "    self.dec_hidden_dim = dec_hidden_dim\n",
        "    self.key_dim = key_dim\n",
        "    self.query_dim = query_dim\n",
        "    self.val_dim = val_dim\n",
        "\n",
        "    #key, query, value\n",
        "    self.W_key = nn.Linear(enc_hidden_dim, key_dim)\n",
        "    self.W_query = nn.Linear(dec_hidden_dim, query_dim)\n",
        "    self.W_value = nn.Linear(enc_hidden_dim, val_dim)\n",
        "\n",
        "    #set similarity score method - set it here so that if we train with one method, it doesn't get switched later\n",
        "    self.sim_method = sim_method\n",
        "\n",
        "    #bahdanau / additive method\n",
        "    if((sim_method == 'add') or (sim_method==\"bahdanau\")):\n",
        "      self.W_query_bah = nn.Linear(query_dim, score_dim)\n",
        "      self.W_key_bah = nn.Linear(key_dim, score_dim)\n",
        "      self.bias_bah = nn.Parameter(torch.zeros(score_dim))\n",
        "      self.V_a_bah = nn.Linear(score_dim, 1, bias=False)\n",
        "\n",
        "    #masking\n",
        "    self.masked = masked\n",
        "\n",
        "\n",
        "  def forward(self, key_hidden, query_hidden, value_hidden):\n",
        "\n",
        "    #apply linear transform\n",
        "    key = self.W_key(key_hidden)\n",
        "    value = self.W_value(value_hidden)\n",
        "    query = self.W_query(query_hidden)\n",
        "\n",
        "    #get attention scores\n",
        "    if(self.sim_method=='dot'): #dot product\n",
        "      attention_scores = torch.matmul(query, key.transpose(1, 2))\n",
        "    elif(self.sim_method=='scaled_dot'): #scaled dot product\n",
        "      attention_scores = torch.matmul(query, key.transpose(1, 2))/np.sqrt(self.key_dim)\n",
        "    else: #bahdanau\n",
        "      #linear transform\n",
        "      key = self.W_key_bah(key)\n",
        "      query = self.W_query_bah(query)\n",
        "\n",
        "      #generate score\n",
        "      score_tanh = torch.tanh(key.unsqueeze(1) + query.unsqueeze(2) + self.bias_bah)\n",
        "      attention_scores = self.V_a_bah(score_tanh).squeeze(-1)\n",
        "\n",
        "    #masked - make upper triangle of values negative inf\n",
        "    if(self.masked):\n",
        "      #upper triangle mask\n",
        "      mask = 1 - torch.triu(torch.ones(attention_scores.size(1), attention_scores.size(2)), diagonal=1)\n",
        "\n",
        "      #apply mask\n",
        "      masked_tensor = attention_scores * mask.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "      #change masked valeus with -inf\n",
        "      attention_scores = torch.where(mask.unsqueeze(0) == 0, torch.tensor(float('-inf')).to(attention_scores.device), masked_tensor)\n",
        "\n",
        "    #softmax\n",
        "    attention_dist = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "    #attention output - weighted sum\n",
        "    attention_output = torch.matmul(attention_dist, value)\n",
        "\n",
        "    return attention_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "gKiXWgCvfAuD"
      },
      "outputs": [],
      "source": [
        "#not sure if I should change the number of heads to 8 as default\n",
        "class DecoderNN(nn.Module):\n",
        "  def __init__(self, node_type, n_layers, dec_hidden_dim, enc_hidden_dim, embed_dim, vocab_size, attention=False, n_heads=1, key_dim=None, query_dim=None, val_dim=None, score_dim=None, sim_method='dot', masked=True):\n",
        "    super(DecoderNN, self).__init__()\n",
        "\n",
        "    #model parameters\n",
        "    self.n_layers = n_layers\n",
        "    self.node_type = node_type\n",
        "    # self.max_length = max_length\n",
        "    self.hidden_dim = dec_hidden_dim\n",
        "    self.vocab_size = vocab_size\n",
        "\n",
        "    #define embedding node\n",
        "    self.embedding_node = Embedding_Node(vocab_size, embed_dim)\n",
        "\n",
        "    #create layer of nodes based on type\n",
        "    node_class = RNN_Node if node_type == \"rnn\" else LSTM_Node\n",
        "    self.nodes = nn.ModuleList(\n",
        "          [node_class(dec_hidden_dim, embed_dim)] +\n",
        "          [node_class(dec_hidden_dim, dec_hidden_dim) for _ in range(n_layers - 1)])\n",
        "\n",
        "\n",
        "    #output weights\n",
        "    self.W_out = nn.Parameter(torch.randn(vocab_size, dec_hidden_dim))\n",
        "\n",
        "    #attention\n",
        "    self.attention = attention\n",
        "    if(attention):\n",
        "      #set up dimensions\n",
        "      if(key_dim==None):\n",
        "        key_dim = enc_hidden_dim // n_heads\n",
        "      if(query_dim==None):\n",
        "        query_dim = dec_hidden_dim // n_heads\n",
        "      if(val_dim==None):\n",
        "        val_dim = enc_hidden_dim // n_heads\n",
        "      #two options for score dim - either take max or avg of key and query - decided max to ensure enough space\n",
        "      if(score_dim==None):\n",
        "        score_dim = max(key_dim, query_dim)\n",
        "\n",
        "      #if dot product in involved, key_dim must = query_dim therefore, take larger dim to equal both\n",
        "      if(((sim_method=='dot')or(sim_method=='scaled_dot'))and(key_dim!=query_dim)):\n",
        "        max_val = max(key_dim, query_dim)\n",
        "        key_dim, query_dim = max_val, max_val\n",
        "\n",
        "      #other attention attributes\n",
        "      self.sim_method = sim_method\n",
        "      self.masked = masked\n",
        "\n",
        "      #create attention instance\n",
        "      self.attention_node = Attention_Node(enc_hidden_dim, dec_hidden_dim, key_dim, query_dim, val_dim, score_dim, sim_method, masked)\n",
        "\n",
        "      #linear layer to reduce concatenated size\n",
        "      self.attn_combine = nn.Linear(dec_hidden_dim + val_dim, dec_hidden_dim)\n",
        "\n",
        "\n",
        "  #forward pass - considered as going over one word (versus encoder going over entire sentence) - training\n",
        "  def forward(self, input, hidden_tensor, cell_tensor=None, encoder_flayer=None):\n",
        "\n",
        "    #initial nodes\n",
        "    node_list = self.nodes\n",
        "\n",
        "    #get embedding of input\n",
        "    input = self.embedding_node.forward(input)[:,0] #only take one word\n",
        "\n",
        "    #forward pass for all layers (remember - not entire sentence, just 1 word)\n",
        "    for layer in range(0,self.n_layers):\n",
        "      #if not first layer, then input is previous hidden state\n",
        "      if layer!=0:\n",
        "        input = hidden_tensor[layer-1]\n",
        "\n",
        "      #forward pass\n",
        "      if(self.node_type==\"rnn\"):\n",
        "        hidden_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer]) # (batch, hidden dim)\n",
        "      elif(self.node_type=='lstm'):\n",
        "        hidden_tensor[layer], cell_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer], cell_tensor[layer]) # both of size (batch, hidden dim)\n",
        "\n",
        "    #attention\n",
        "    if(self.attention):\n",
        "      #grab key, query, values\n",
        "      key_hidden = encoder_flayer\n",
        "      query_hidden = hidden_tensor[-1].unsqueeze(1)\n",
        "      value_hidden = encoder_flayer\n",
        "\n",
        "      #get attention output\n",
        "      attention_out = self.attention_node.forward(key_hidden, query_hidden, value_hidden)\n",
        "\n",
        "      #since we're only looking at one decoder sequence, can squeeze\n",
        "      attention_out = attention_out.squeeze(1)\n",
        "\n",
        "      #concatinate last hidden layer with attention output\n",
        "      concat_tensor = torch.cat((hidden_tensor[-1], attention_out), dim=1)\n",
        "\n",
        "      #apply linear transform\n",
        "      hidden_tensor[-1] = self.attn_combine(concat_tensor)\n",
        "\n",
        "    #generate final output\n",
        "    pred_output = torch.matmul(self.W_out, hidden_tensor[-1].T).T #during training - cross entropy fun converts this to prob\n",
        "\n",
        "    return hidden_tensor, cell_tensor, pred_output\n",
        "\n",
        "  #to generate predictions - generate one word at a time\n",
        "  #greedy decoding - uses/ predicts most probable word - singular\n",
        "  def pred(self, input, hidden_tens, cell_tens, encoder_flayer=None, sos_token=1, pad_token=0, eos_token=2):\n",
        "\n",
        "    #generate predicted word & others\n",
        "    hidden_tensor, cell_tensor, pred_logit = self.forward(input, hidden_tens, cell_tens, encoder_flayer)\n",
        "\n",
        "    #convert logits to prob\n",
        "    pred_prob = F.softmax(pred_logit, dim=1) #should be correct\n",
        "\n",
        "    #turn sos and pad tokens to not be possible predictions\n",
        "    pred_prob[:, sos_token] = -np.inf\n",
        "    pred_prob[:, pad_token] = -np.inf\n",
        "\n",
        "    return hidden_tensor, cell_tensor, pred_prob\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  ###Different methods of scoring###\n",
        "\n",
        "  *cum_log_probs = cummulative log of probabilities\n",
        "    -tensor of shape (batch, beam_width, vocab_size)\n",
        "  *counts = lenghts of sequences\n",
        "    -tensor of shape (batch, beam_width)\n",
        "'''\n",
        "def normalization_scores(cum_log_probs, counts, norm_method, alpha=.6):\n",
        "  #reshape counts so that shape permits every vocab elem being divided by corresponding count\n",
        "  counts = counts.unsqueeze(-1)\n",
        "\n",
        "  scores = None\n",
        "\n",
        "  #no bias to long or short sequences\n",
        "  if (norm_method=='avg'):\n",
        "    scores = cum_log_probs / counts\n",
        "    #decide how much to penalize longer sequences\n",
        "  elif (norm_method=='norm'):\n",
        "    scores = cum_log_probs / ((5 + counts)**alpha)\n",
        "    #bias to shorter sequences\n",
        "  else:\n",
        "    scores = cum_log_probs\n",
        "\n",
        "  return scores"
      ],
      "metadata": {
        "id": "-bXP3iFqyJlE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEED TO MODIFY BEAM PREDICTION TO TAKE CORRECT FINAL LAYER HIDDEN TENSOR FOR ALL ENCODER SEQUENCE -- USED FOR ATTENTION\n"
      ],
      "metadata": {
        "id": "_muyUz2kVpfE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "RQS3dWtMfNjg"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder_args, decoder_args, sos_token=1, eos_token=2, pad_token=0):#, greedy=True, beam_width=2):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "\n",
        "    #model structure\n",
        "    self.encoder = EncoderNN(*encoder_args)\n",
        "    self.decoder = DecoderNN(*decoder_args)\n",
        "\n",
        "    #set other model params to be ref later\n",
        "    # self.max_length = max_length\n",
        "    self.sos_token = sos_token\n",
        "    self.eos_token = eos_token\n",
        "    self.pad_token = pad_token\n",
        "\n",
        "    # Linear layer to project encoder hidden dim to decoder hidden dim\n",
        "    enc_hid = encoder_args[2]\n",
        "    dec_hid = decoder_args[2]\n",
        "    self.hidden_transform = nn.Linear(enc_hid, dec_hid)\n",
        "    self.cell_transform = nn.Linear(enc_hid, dec_hid)\n",
        "\n",
        "    #for attention - encoder final layer\n",
        "    self.enc_flayer_transform = nn.Linear(enc_hid, dec_hid)\n",
        "\n",
        "  #run encoder and initialize decoder with hidden states\n",
        "  def run_enc_init_dec(self, inputs):\n",
        "    #put on correct device\n",
        "    device = next(self.parameters()).device\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    #encoder\n",
        "    node_class = RNN_Node if self.encoder.node_type == \"rnn\" else LSTM_Node\n",
        "    (enc_hidden_node, enc_cell_node), enc_final_hidden_layer = self.encoder.forward(inputs)\n",
        "\n",
        "    #initialize hidden and cell tensor\n",
        "    dec_hidden_tensor, dec_cell_tensor = init_hidden(self.decoder, inputs.shape[0])\n",
        "\n",
        "    #linear transform encoder return values - in case hidden sizes don't match\n",
        "    dec_hidden_tensor[0] = self.hidden_transform(enc_hidden_node)\n",
        "    if (dec_cell_tensor!=None) and (enc_cell_node!=None):\n",
        "      dec_cell_tensor[0] = self.cell_transform(enc_cell_node)\n",
        "\n",
        "    #linearly transform encoder final layer - converts shape from (batch, seq, encoder_hidden) to (batch, seq, decoder_hidden)\n",
        "    #enc_final_hidden_layer = self.enc_flayer_transform(enc_final_hidden_layer) #\n",
        "\n",
        "    return dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer\n",
        "\n",
        "\n",
        "  #for the full system\n",
        "  def forward(self, inputs, outputs):\n",
        "    #put on correct device\n",
        "    device = next(self.parameters()).device\n",
        "#    inputs = inputs.to(device)\n",
        "    outputs = outputs.to(device)\n",
        "\n",
        "    #run encoder and initialize decoder with hidden states\n",
        "    dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer = self.run_enc_init_dec(inputs)\n",
        "\n",
        "    #decoder\n",
        "    pred_out_tensor = torch.zeros(outputs.size(0), len(outputs[0]), self.decoder.vocab_size, device=device) #before was device = outputs.device\n",
        "\n",
        "    for word_pos in range(0,len(outputs[0])):\n",
        "      print('WORD POSITION: {}'.format(word_pos))\n",
        "\n",
        "      #get particular word position for entire batch and reshape to have 2d array\n",
        "      word_batch = outputs[:,word_pos].unsqueeze(1)\n",
        "\n",
        "      #decoder forward pass\n",
        "      dec_hidden_tensor, dec_cell_tensor, pred_out = self.decoder.forward(word_batch, dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer)\n",
        "\n",
        "      #add value to prediction tensor\n",
        "      pred_out_tensor[:, word_pos, :] = pred_out\n",
        "\n",
        "\n",
        "    return pred_out_tensor #must make sure has shape (batch size, seq length, vocab size)\n",
        "\n",
        "  #performs beam search in order to generate predictions\n",
        "  #beam width = 1 is greedy search\n",
        "  def beam_pred(self, inputs, beam_width=1, max_length=30, norm_method='avg', alpha=.6):\n",
        "    #dimensions\n",
        "    batch_size = inputs.size(0)\n",
        "    vocab_size = self.decoder.vocab_size\n",
        "\n",
        "    #run encoder and initialize decoder with hidden states\n",
        "    dec_hidden_tensor, dec_cell_tensor, enc_flayer = self.run_enc_init_dec(inputs)\n",
        "\n",
        "    #initialize tensors\n",
        "    seqs = torch.full((batch_size, beam_width, 1 ), self.sos_token)\n",
        "    cum_log_probs = torch.full((batch_size, beam_width, 1 ), 0).to(dtype=torch.float32)\n",
        "    counts = torch.full((batch_size, beam_width), 0)\n",
        "\n",
        "    #init hidden and cell\n",
        "    hidden = dec_hidden_tensor.repeat_interleave(beam_width, dim=1)\n",
        "    cell = None\n",
        "    if (dec_cell_tensor is not None):\n",
        "      cell = dec_cell_tensor.repeat_interleave(beam_width, dim=1)\n",
        "\n",
        "    #mask\n",
        "    cont_mask = torch.full((batch_size, beam_width), True, dtype=torch.bool)\n",
        "\n",
        "    #adjust encoder final layer for beam width\n",
        "    enc_flayer_repeat = enc_flayer.repeat_interleave(beam_width, dim=0)\n",
        "\n",
        "    # print('\\n')\n",
        "    #keep generating words in sequence until max length or until all sequences reach eos token\n",
        "    for word_pos in range(0, max_length):\n",
        "      print('WORD POSITION: {}'.format(word_pos))\n",
        "\n",
        "      #flattened masked\n",
        "      flat_mask = cont_mask.flatten()\n",
        "\n",
        "      #grab unmasked values\n",
        "      seqs_unmasked = seqs[cont_mask]\n",
        "\n",
        "      hidden_unmasked = hidden[:,flat_mask,:]\n",
        "      cell_unmasked = None if cell is None else cell[:,flat_mask,:]\n",
        "\n",
        "\n",
        "      #get last value in sequence\n",
        "      last_seqs_unmasked = seqs_unmasked[:,-1:]#.squeeze()\n",
        "\n",
        "      #generate predictions\n",
        "      hidden_new, cell_new, prob_full_vocab = self.decoder.pred(last_seqs_unmasked, hidden_unmasked, cell_unmasked, enc_flayer_repeat, self.sos_token, self.pad_token, self.eos_token)\n",
        "\n",
        "      ### UNMASKED SCORES ###\n",
        "\n",
        "      #create new tensor of shape (batch_size, beam_width, vocab_size)\n",
        "      cum_log_probs_unmasked = torch.full((batch_size, beam_width, vocab_size), -np.inf)\n",
        "\n",
        "      #replace with probabilities generated\n",
        "      cum_log_probs_unmasked[cont_mask] = prob_full_vocab ##MAKE SURE THIS LOOKS RIGHT\n",
        "\n",
        "      #apply log to non -np.inf\n",
        "      neg_inf_mask = cum_log_probs_unmasked != -np.inf\n",
        "      cum_log_probs_unmasked[neg_inf_mask] = torch.log(cum_log_probs_unmasked[neg_inf_mask])\n",
        "\n",
        "      #add cumulative values from parents\n",
        "      cum_log_probs_unmasked[cont_mask] = cum_log_probs_unmasked[cont_mask]+cum_log_probs[cont_mask] ##MAKE SURE THIS LOOKS RIGHT\n",
        "\n",
        "      #increase respective counts\n",
        "      counts[cont_mask] = counts[cont_mask] + 1\n",
        "\n",
        "      #generated unmasked scores\n",
        "      scores_unmasked = normalization_scores(cum_log_probs_unmasked, counts, norm_method, alpha)\n",
        "\n",
        "      #flatten scores\n",
        "      scores_unmasked = scores_unmasked.flatten(start_dim=1)\n",
        "\n",
        "      ### MASKED SCORES ###\n",
        "\n",
        "      # #grab eos cum log values\n",
        "      cum_log_probs_masked = cum_log_probs.clone()\n",
        "      cum_log_probs_masked[cont_mask] = -float('inf')\n",
        "\n",
        "      #generate masked scores\n",
        "      scores_masked = normalization_scores(cum_log_probs_masked, counts, norm_method, alpha)\n",
        "\n",
        "      #flatten\n",
        "      scores_masked = scores_masked.flatten(start_dim=1)\n",
        "\n",
        "      #combine the two\n",
        "      scores_comb = torch.cat([scores_unmasked, scores_masked], dim=1)\n",
        "\n",
        "      #get k most prob\n",
        "      topk_vals, topk_indx = torch.topk(scores_comb, k=beam_width, dim=1)\n",
        "\n",
        "      ### find out where these actually belong ###\n",
        "\n",
        "      #predicted parent\n",
        "      topk_parent = topk_indx // vocab_size\n",
        "\n",
        "      #predicted vocab value\n",
        "      topk_vocab = topk_indx % vocab_size\n",
        "\n",
        "      ### CHANGE SEQUENCE VALUES ###\n",
        "\n",
        "      #generate blank new sequence\n",
        "      new_seqs = torch.full((batch_size, beam_width, seqs.shape[2]+1), 0)\n",
        "\n",
        "      #generate parent mask\n",
        "      parent_mask = topk_parent < beam_width\n",
        "\n",
        "      ## non eos values - extend previous sequence\n",
        "\n",
        "      #get batch indices where the parent_mask is true\n",
        "      batch_indices, beam_indices = torch.where(parent_mask)\n",
        "\n",
        "      #get the actual parent indices that we're referening to\n",
        "      parent_indices = topk_parent[batch_indices, beam_indices]\n",
        "\n",
        "      #get sequence values that we plan on extending\n",
        "      seqs_extend = seqs[batch_indices, parent_indices]\n",
        "\n",
        "      #extend seqs with respective child vocab\n",
        "      seqs_extend = torch.cat((seqs_extend, topk_vocab[parent_mask].unsqueeze(1)), dim=1)\n",
        "\n",
        "      #replace values in new sequence\n",
        "      new_seqs[parent_mask] = seqs_extend\n",
        "\n",
        "      ## eos seq - copy and extend with eos token\n",
        "\n",
        "      #get batch indices where the parent_mask is false\n",
        "      batch_indices, beam_indices = torch.where(~parent_mask)\n",
        "\n",
        "      #get parents were referning to\n",
        "      parent_indices = topk_parent[batch_indices, beam_indices]\n",
        "\n",
        "      #get true indx relative to batch\n",
        "      true_indx = ((parent_indices-beam_width)*vocab_size)+topk_vocab[~parent_mask]\n",
        "\n",
        "      #grab value in original seqs\n",
        "      seqs_eos = seqs[batch_indices, true_indx]\n",
        "\n",
        "      #extend with eos token\n",
        "      eos_tens = torch.full((seqs_eos.shape[0],1), self.eos_token)\n",
        "      seqs_eos = torch.cat((seqs_eos, eos_tens), dim=1)\n",
        "\n",
        "      #replace in new sequences\n",
        "      new_seqs[~parent_mask] = seqs_eos\n",
        "\n",
        "      #### NOT SURE IF I SHOULD DO THIS HERE\n",
        "      #replace old seqs with new one\n",
        "      seqs = new_seqs\n",
        "\n",
        "      ### CHANGE MASK VALUES ###\n",
        "\n",
        "      #grab the new last sequence values\n",
        "      new_last_seq_vals = seqs[:,:,-1:]\n",
        "\n",
        "      #create a new mask\n",
        "      cont_mask = (new_last_seq_vals != self.eos_token).squeeze(2)\n",
        "\n",
        "      #if all sequences have terminated, break out of loop\n",
        "      if(torch.all(cont_mask == False)):\n",
        "        print('\\n\\nEARLY BREAKOUT CLAUSE')\n",
        "        break\n",
        "\n",
        "      ### CHANGE CUM LOG PROB VALUES ###\n",
        "\n",
        "      #combine cum log probs from before\n",
        "      cum_log_probs_comb = torch.cat((cum_log_probs_unmasked.flatten(1), cum_log_probs_masked.flatten(1)), dim=1)\n",
        "\n",
        "      #grab indexes of top scores\n",
        "      cum_log_probs = torch.gather(cum_log_probs_comb, dim=1, index=topk_indx)\n",
        "\n",
        "      #reshape\n",
        "      cum_log_probs = cum_log_probs.reshape((batch_size, beam_width, 1))\n",
        "\n",
        "      ### CHANGE HIDDEN AND CELL VALUES ###\n",
        "\n",
        "      #replace hidden and cell unmasked with new vals\n",
        "      hidden[:,flat_mask,:] = hidden_new\n",
        "      if(cell is not None):\n",
        "        cell[:,flat_mask,:] = cell_new\n",
        "\n",
        "      # change eos values in parent index\n",
        "      topk_parent[~parent_mask] = true_indx\n",
        "\n",
        "      # adjust all to their linear values\n",
        "      adjust_vals = torch.arange(0,batch_size).unsqueeze(1) * beam_width\n",
        "      lin_seq = (topk_parent + adjust_vals).flatten()\n",
        "\n",
        "      #select indexes where top values were found\n",
        "      hidden = hidden[:,lin_seq,:]\n",
        "      if(cell is not None):\n",
        "        cell = cell[:,lin_seq,:]\n",
        "\n",
        "      ### CHANGE COUNT VALUES ###\n",
        "\n",
        "      #grab counts at indexes we used - then reshape\n",
        "      counts = counts.flatten()[lin_seq].reshape((batch_size, beam_width))\n",
        "\n",
        "      # ### CHANGE MASK VALUES ### -- **** SHOULD PUT THIS HIGHER TO AVOID UNNECESSARY COMPUTATION\n",
        "\n",
        "      # #grab the new last sequence values\n",
        "      # new_last_seq_vals = seqs[:,:,-1:]\n",
        "\n",
        "      # #create a new mask\n",
        "      # cont_mask = (new_last_seq_vals != self.eos_token).squeeze(2)\n",
        "\n",
        "      # #if all sequences have terminated, break out of loop\n",
        "      # if(torch.all(cont_mask == False)):\n",
        "      #   print('\\nEARLY BREAKOUT CLAUSE')\n",
        "      #   break\n",
        "\n",
        "\n",
        "      ### CHANGE FLAYER VALUES BASED ON NEW MASK ###\n",
        "\n",
        "      #see how many true values are within each beam per batch\n",
        "      repeat_counts = cont_mask.sum(dim=1)\n",
        "\n",
        "      #repeat same encoder flayer batch as many times as there are true in mask (width of beam)\n",
        "      enc_flayer_repeat = enc_flayer.repeat_interleave(repeat_counts, dim=0)\n",
        "\n",
        "\n",
        "    return seqs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sGhUmJQmJ2Px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e736a8b-037c-4977-a000-ad850f80a2cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'are': 3,\n",
              " 'going': 4,\n",
              " 'hello': 5,\n",
              " 'how': 6,\n",
              " 'we': 7,\n",
              " 'where': 8,\n",
              " 'world': 9,\n",
              " 'you': 10,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "data_dict[\"English Vocabulary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "a3G9it0h3vuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e17947-3d9a-44c5-a515-6329a9af9d09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "#have to seperate by word\n",
        "output[:,0].reshape(len(output),1)\n",
        "# len(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yFKRkAER4pI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537324d2-48dd-493a-dff8-da17b8b3a04a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "prev_input = torch.tensor([[1], [1], [1]])\n",
        "prev_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mUnpyblF9s4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df3fa12-ffcc-4321-b027-6873a3b6948d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  6,  3, 10,  2,  0],\n",
              "        [ 1,  5,  9,  2,  0,  0],\n",
              "        [ 1,  8,  3,  7,  4,  2]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # if(self.sim_method=='dot'):\n",
        "    #   attention_score = torch.bmm(query, key.T)\n",
        "    # elif(self.sim_method=='scaled_dot'):\n",
        "    #   attention_score = torch.bmm(query, key.T)/np.sqrt(self.d_k)\n",
        "    # else: #bahdanau"
      ],
      "metadata": {
        "id": "ECgtRd_cpgtR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "0eLejyzHk-V7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfdd2881-360b-458d-9d50-3b2b15f53aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocab size: 11\n",
            "Italian vocab size: 10\n",
            "WORD POSITION: 0\n",
            "WORD POSITION: 1\n",
            "WORD POSITION: 2\n",
            "WORD POSITION: 3\n",
            "WORD POSITION: 4\n",
            "WORD POSITION: 5\n",
            "WORD POSITION: 6\n",
            "WORD POSITION: 7\n",
            "WORD POSITION: 8\n",
            "WORD POSITION: 9\n",
            "WORD POSITION: 10\n",
            "WORD POSITION: 11\n",
            "WORD POSITION: 12\n",
            "WORD POSITION: 13\n",
            "WORD POSITION: 14\n",
            "WORD POSITION: 15\n",
            "WORD POSITION: 16\n",
            "WORD POSITION: 17\n",
            "WORD POSITION: 18\n",
            "WORD POSITION: 19\n",
            "WORD POSITION: 20\n",
            "WORD POSITION: 21\n",
            "WORD POSITION: 22\n",
            "WORD POSITION: 23\n",
            "WORD POSITION: 24\n",
            "WORD POSITION: 25\n",
            "WORD POSITION: 26\n",
            "WORD POSITION: 27\n",
            "WORD POSITION: 28\n",
            "WORD POSITION: 29\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#encoder param\n",
        "enc_node_type = \"rnn\"\n",
        "enc_n_layers = 2\n",
        "enc_hidden_dim = 4\n",
        "enc_embed_dim = 7\n",
        "eng_vocab_size = len(data_dict[\"English Vocabulary\"])\n",
        "attention=True\n",
        "n_heads=1\n",
        "key_dim=13\n",
        "query_dim=14\n",
        "val_dim=9\n",
        "score_dim=None\n",
        "# sim_method='bahdanau'\n",
        "sim_method='scaled_dot'\n",
        "masked=True\n",
        "\n",
        "#decoder_param\n",
        "dec_node_type = 'rnn'\n",
        "dec_n_layers = 5\n",
        "dec_hidden_dim = 12\n",
        "dec_embed_dim = 8\n",
        "it_vocab_size = len(data_dict[\"Italian Vocabulary\"])\n",
        "\n",
        "#seq2seq param\n",
        "# max_length = 30\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "greedy=True\n",
        "beam_width=2\n",
        "sos_token=1\n",
        "eos_token=2\n",
        "pad_token=0\n",
        "\n",
        "# (self, node_type, n_layers, hidden_dim, embed_dim, vocab_size)\n",
        "# (self, node_type, n_layers, hidden_dim, embed_dim, vocab_size, attention=False, max_length=30)\n",
        "\n",
        "print('English vocab size: {}'.format(eng_vocab_size))\n",
        "print('Italian vocab size: {}'.format(it_vocab_size))\n",
        "\n",
        "#key_dim, query_dim, val_dim\n",
        "\n",
        "#create seq2seq instance\n",
        "\n",
        "encoder_args = (enc_node_type, enc_n_layers, enc_hidden_dim, enc_embed_dim, eng_vocab_size)\n",
        "decoder_args = (dec_node_type, dec_n_layers, dec_hidden_dim, enc_hidden_dim, dec_embed_dim, it_vocab_size, attention, n_heads, key_dim, query_dim, val_dim, score_dim, sim_method, masked)\n",
        "seq2seq = Seq2Seq(encoder_args, decoder_args).to(device)#, greedy=greedy, beam_width=beam_width).to(device)\n",
        "\n",
        "# temp = seq2seq.forward(input, output)\n",
        "\n",
        "# #testing out decoder prediction\n",
        "pred_out = seq2seq.beam_pred(input, beam_width=2, norm_method='avg')\n",
        "\n",
        "# print('\\n\\nPREDICTED OUTPUT')\n",
        "# pred_out\n",
        "\n",
        "# temp = seq2seq.forward(input, output)\n",
        "\n",
        "# prev_input = torch.tensor([[1], [1], [1]])\n",
        "# #itialize tens based on node type\n",
        "# batch_size = 3\n",
        "# init_hidden_tensor = torch.zeros(dec_n_layers, batch_size, dec_hidden_dim).to(device)\n",
        "# init_cell_tensor = None\n",
        "# #create decoder instance\n",
        "# decoder = DecoderNN(*decoder_args)\n",
        "# hidden_tensor, cell_tensor, pred_word_indx = decoder.pred(prev_input, init_hidden_tensor, init_cell_tensor)\n",
        "# pred_word_indx\n",
        "\n",
        "#init_hidden_tensor, init_cell_tensor = init_hidden(batch_size=3)\n",
        "\n",
        "\n",
        "# #################################################\n",
        "\n",
        "# temp = seq2seq.forward(input, output)\n",
        "# print('this is seq2seq forward output')\n",
        "# display(temp)\n",
        "# print(\"output shape: {}\".format(temp.shape))\n",
        "# print(\"output type: {}\".format(type(temp)))\n",
        "# #forward step\n",
        "\n",
        "# # #encoder instance\n",
        "# encoder = EncoderNN(*encoder_args)\n",
        "# enc_out, final_hidden_layer = encoder.forward(input)\n",
        "# enc_hidden_node = enc_out[0]\n",
        "\n",
        "# print('\\n\\n\\nafter encoder test step')\n",
        "\n",
        "\n",
        "\n",
        "# #decoder instance\n",
        "# decoder = DecoderNN(*decoder_args)\n",
        "# #initialize hidden and cell list32\n",
        "# dec_hidden_list, dec_cell_list = init_hidden(decoder, output.shape[0])\n",
        "# dec_hidden_list[0] = enc_hidden_node\n",
        "\n",
        "# pred_out = decoder.forward(output[:,0].reshape(len(output), 1), dec_hidden_list, None, final_hidden_layer)\n",
        "# print('\\nafter decoder test step')\n",
        "\n",
        "# #create encoder instance\n",
        "# encoder = EncoderNN(node_type, n_layers, hidden_dim, embed_dim, eng_vocab_size)\n",
        "\n",
        "# #forward step\n",
        "# hidden_list, final_hidden_layer = encoder.forward(input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # #original shape is (n_layers, batch_size, hidden_dim), resulting shape (batch_size, beam_width, n_layers, hidden_dim)\n",
        "    # def layer_tensor_expand_with_beams(tens, beam_width):\n",
        "    #     #create dimension for beams\n",
        "    #     tens_beam = tens.unsqueeze(2)\n",
        "\n",
        "    #     #expand for beam width\n",
        "    #     tens_expand = tens_beam.expand(-1, -1, beam_width, -1)\n",
        "\n",
        "    #     #change to shape (batch, beam_width, layers, hidden_dim)\n",
        "    #     new_tens = tens_expand.permute(1, 2, 0, 3)\n",
        "\n",
        "    #     return new_tens\n",
        "\n",
        "\n",
        "\n",
        "    # #adjust shapes and repeat all layers for each in beam\n",
        "    # hidden = layer_tensor_expand_with_beams(dec_hidden_tensor, beam_width)\n",
        "    # cell = None\n",
        "    # if(dec_cell_tensor!=None):\n",
        "    #   cell = layer_tensor_expand_with_beams(dec_cell_tensor, beam_width)"
      ],
      "metadata": {
        "id": "9IxU7qekAX2F"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEED TO FUN ABOVE CoDE UNTIL WE SEE 2 AS VALUE - THATS EOS INDICATOR\n",
        "--SEE IF FIX OF PRED PROB = NONE AND PRED VOCAB= 2 VALUES ARE GOOD"
      ],
      "metadata": {
        "id": "6p0F6VIzjiSZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "3eb8f8ec-6c46-4318-a951-d74c5887cd85"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-28-f811e0500364>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-f811e0500364>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    NEED TO FUN ABOVE CoDE UNTIL WE SEE 2 AS VALUE - THATS EOS INDICATOR\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68w2HKH1lNK5"
      },
      "outputs": [],
      "source": [
        "print('true output')\n",
        "display(output)\n",
        "print(\"true output shape: {}\".format(output.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAVdhuINsyD3"
      },
      "source": [
        "Notes:\n",
        "\n",
        "- before running - write in comments how each dimension is looking like after each computation - helpful for debugging\n",
        "\n",
        "- incorporate batches!\n",
        "\n",
        "- transformers *\n",
        "\n",
        "- beam search\n",
        "\n",
        "- bidirectional *\n",
        "\n",
        "- different attention methods *\n",
        "\n",
        "-- evaluate with Bleu scores\n",
        "\n",
        "\n",
        "SHOULD ADD\n",
        "- dependency parsing, pretraining, and fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X8KzhGEsRrD"
      },
      "source": [
        "Run time notes:\n",
        "\n",
        "- embedding size: Common values for the embedding dimension in NLP tasks range from 50 to 300, but larger values like 512 or 1024 can be used for more complex tasks or larger datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsAm8IVIdpr0"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOPZVO0kK9xWHcCVgWFFBL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}