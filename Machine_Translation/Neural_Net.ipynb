{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smargetic/Natural_Language_Processing/blob/main/Machine_Translation/Neural_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-eYx0G4p02W",
        "outputId": "ce8de20f-a039-441a-d4c3-28cf1747f914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (7.16.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.1.5)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.1.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nbconvert) (24.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (2.18.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert) (1.4.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert) (4.3.6)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from nbclient>=0.5.0->nbconvert) (6.1.12)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert) (4.23.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert) (2.6)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.22.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.8.2)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.3.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nbconvert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E38McwRXbyKA",
        "outputId": "201f4aa6-6f06-4650-cf5f-3af7be8f914f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#data storage - not sure if important\n",
        "import pandas as pd\n",
        "import numpy as np #can take away later\n",
        "\n",
        "#make sure to show all values in pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "#pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# import tensorflow as tf\n",
        "\n",
        "#visualize\n",
        "from IPython.display import display\n",
        "\n",
        "#help import other functions\n",
        "import os\n",
        "\n",
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Disable scientific notation\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "#for list comprehension\n",
        "import itertools\n",
        "\n",
        "# #cummulative list\n",
        "# from itertools import accumulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FJRgbpQDJyVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13710f05-3679-4ee1-e54f-54fa02e46dbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Files currently present:\n",
            "['sentences_base.csv', 'ita_sentences_CC0.tsv', 'eng_sentences_detailed.tsv', 'eng_sentences.tsv', 'ita_sentences_detailed.tsv', 'eng_sentences_CC0.tsv', 'ita_sentences.tsv', 'Sentence pairs in English-Italian - 2024-07-26.tsv', 'Helper_Functions.ipynb', 'Model_Train_Predict.ipynb', '__pycache__', 'Data_Intake_and_Preprocessing.ipynb', 'intake_preprocess_utils.ipynb', 'intake_preprocess_utils.py', 'Neural_Net.ipynb']\n",
            "[NbConvertApp] Converting notebook intake_preprocess_utils.ipynb to script\n",
            "[NbConvertApp] Writing 11518 bytes to intake_preprocess_utils.txt\n",
            "\n",
            "\n",
            "New files in current directory:\n",
            "['sentences_base.csv', 'ita_sentences_CC0.tsv', 'eng_sentences_detailed.tsv', 'eng_sentences.tsv', 'ita_sentences_detailed.tsv', 'eng_sentences_CC0.tsv', 'ita_sentences.tsv', 'Sentence pairs in English-Italian - 2024-07-26.tsv', 'Helper_Functions.ipynb', 'Model_Train_Predict.ipynb', '__pycache__', 'Data_Intake_and_Preprocessing.ipynb', 'intake_preprocess_utils.ipynb', 'intake_preprocess_utils.py', 'Neural_Net.ipynb']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##to obtain functions from another .ipynb file\n",
        "\n",
        "#go to current directory\n",
        "os.chdir('/content/drive/My Drive/Coding Projects/Machine Translation')\n",
        "\n",
        "#List the files in the current directory\n",
        "print('\\nFiles currently present:')\n",
        "print(os.listdir())\n",
        "\n",
        "#Convert the notebook to a Python script\n",
        "!jupyter nbconvert --to script intake_preprocess_utils.ipynb\n",
        "os.rename('intake_preprocess_utils.txt', 'intake_preprocess_utils.py')\n",
        "\n",
        "print('\\n\\nNew files in current directory:')\n",
        "print(os.listdir())\n",
        "print('\\n\\n')\n",
        "\n",
        "#import functions\n",
        "from intake_preprocess_utils import get_file_and_disp, get_sample, dump_sample, data_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HOifKYsyxoIs"
      },
      "outputs": [],
      "source": [
        "# #english to italian translation - just to test\n",
        "# df_eng_it = get_file_and_disp(fileName=\"Sentence pairs in English-Italian - 2024-07-26.tsv.zip\" ,sep='\\t', stringName=\"English to Italian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mRoEVDsAWxDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "37f0c33f-6e5c-4d13-d79f-2416f14904f6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   0                   1  2                    3\n",
              "0  1         hello world  1           ciao mondo\n",
              "1  2         how are you  2            come stai\n",
              "2  3  where are we going  3  dove stiamo andando"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0538dfa7-ab43-41c3-bdf5-5db1685879af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>hello world</td>\n",
              "      <td>1</td>\n",
              "      <td>ciao mondo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how are you</td>\n",
              "      <td>2</td>\n",
              "      <td>come stai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>where are we going</td>\n",
              "      <td>3</td>\n",
              "      <td>dove stiamo andando</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0538dfa7-ab43-41c3-bdf5-5db1685879af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0538dfa7-ab43-41c3-bdf5-5db1685879af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0538dfa7-ab43-41c3-bdf5-5db1685879af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3c40bd4b-3fc5-46f6-b643-dad60bc87cb6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c40bd4b-3fc5-46f6-b643-dad60bc87cb6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3c40bd4b-3fc5-46f6-b643-dad60bc87cb6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_680367fd-bba2-4f96-ad9b-480092f2700c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_680367fd-bba2-4f96-ad9b-480092f2700c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hello world\",\n          \"how are you\",\n          \"where are we going\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ciao mondo\",\n          \"come stai\",\n          \"dove stiamo andando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#test data set\n",
        "df = pd.DataFrame({\n",
        "                  0:[1,2,3],\n",
        "                  1:[\"hello world\", \"how are you\", \"where are we going\"],\n",
        "                  2:[1,2,3],\n",
        "                  3: [\"ciao mondo\", \"come stai\", \"dove stiamo andando\"]})\n",
        "\n",
        "display(df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QmDxJKD6dQ2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94e125ed-4841-4761-aa94-e8e53fd48c6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nulls in English: 0\n",
            "Nulls in Italian: 0\n",
            "\n",
            "English/Italian Translations:\n",
            "\tEnglish vocabulary size: 11\n",
            "\tItalian vocabulary size: 10\n",
            "\n",
            "Done with Pytorch.\n",
            "\n",
            "English-Italian Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   eng_id        eng_sentence  it_id          it_sentence  \\\n",
              "0       1         hello world      1           ciao mondo   \n",
              "1       2         how are you      2            come stai   \n",
              "2       3  where are we going      3  dove stiamo andando   \n",
              "\n",
              "                              eng_tokens  \\\n",
              "0           [<sos>, hello, world, <eos>]   \n",
              "1          [<sos>, how, are, you, <eos>]   \n",
              "2  [<sos>, where, are, we, going, <eos>]   \n",
              "\n",
              "                               it_tokens      eng_tokens_enc    it_tokens_enc  \\\n",
              "0            [<sos>, ciao, mondo, <eos>]        [1, 5, 9, 2]     [1, 4, 7, 2]   \n",
              "1             [<sos>, come, stai, <eos>]    [1, 6, 3, 10, 2]     [1, 5, 8, 2]   \n",
              "2  [<sos>, dove, stiamo, andando, <eos>]  [1, 8, 3, 7, 4, 2]  [1, 6, 9, 3, 2]   \n",
              "\n",
              "                                                      eng_tokens_enc_p  \\\n",
              "0   [tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]   \n",
              "1  [tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]   \n",
              "2   [tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]   \n",
              "\n",
              "                                           it_tokens_enc_p  \n",
              "0  [tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]  \n",
              "1  [tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]  \n",
              "2  [tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f30df24-3dc0-4f4a-acdc-3a5cc8c205db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng_id</th>\n",
              "      <th>eng_sentence</th>\n",
              "      <th>it_id</th>\n",
              "      <th>it_sentence</th>\n",
              "      <th>eng_tokens</th>\n",
              "      <th>it_tokens</th>\n",
              "      <th>eng_tokens_enc</th>\n",
              "      <th>it_tokens_enc</th>\n",
              "      <th>eng_tokens_enc_p</th>\n",
              "      <th>it_tokens_enc_p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>hello world</td>\n",
              "      <td>1</td>\n",
              "      <td>ciao mondo</td>\n",
              "      <td>[&lt;sos&gt;, hello, world, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, ciao, mondo, &lt;eos&gt;]</td>\n",
              "      <td>[1, 5, 9, 2]</td>\n",
              "      <td>[1, 4, 7, 2]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how are you</td>\n",
              "      <td>2</td>\n",
              "      <td>come stai</td>\n",
              "      <td>[&lt;sos&gt;, how, are, you, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, come, stai, &lt;eos&gt;]</td>\n",
              "      <td>[1, 6, 3, 10, 2]</td>\n",
              "      <td>[1, 5, 8, 2]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>where are we going</td>\n",
              "      <td>3</td>\n",
              "      <td>dove stiamo andando</td>\n",
              "      <td>[&lt;sos&gt;, where, are, we, going, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, dove, stiamo, andando, &lt;eos&gt;]</td>\n",
              "      <td>[1, 8, 3, 7, 4, 2]</td>\n",
              "      <td>[1, 6, 9, 3, 2]</td>\n",
              "      <td>[tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f30df24-3dc0-4f4a-acdc-3a5cc8c205db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4f30df24-3dc0-4f4a-acdc-3a5cc8c205db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4f30df24-3dc0-4f4a-acdc-3a5cc8c205db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c6caa644-0f80-4b53-9bf6-a324a344345b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6caa644-0f80-4b53-9bf6-a324a344345b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c6caa644-0f80-4b53-9bf6-a324a344345b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  display(data_dict[key])\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"eng_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hello world\",\n          \"how are you\",\n          \"where are we going\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ciao mondo\",\n          \"come stai\",\n          \"dove stiamo andando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 5, 9, 2, 0, 0])\",\n          \"tensor([ 1,  6,  3, 10,  2,  0])\",\n          \"tensor([1, 8, 3, 7, 4, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 4, 7, 2, 0])\",\n          \"tensor([1, 5, 8, 2, 0])\",\n          \"tensor([1, 6, 9, 3, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian SING Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7e45604dbad0>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'are': 3,\n",
              " 'going': 4,\n",
              " 'hello': 5,\n",
              " 'how': 6,\n",
              " 'we': 7,\n",
              " 'where': 8,\n",
              " 'world': 9,\n",
              " 'you': 10,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'andando': 3,\n",
              " 'ciao': 4,\n",
              " 'come': 5,\n",
              " 'dove': 6,\n",
              " 'mondo': 7,\n",
              " 'stai': 8,\n",
              " 'stiamo': 9,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#go through preprocessing\n",
        "data_dict= data_preprocessing(df.copy(), pytorchB=True, tensorflowB=False, store=False, sample=False, download=False, sing=False)\n",
        "for key in data_dict.keys():\n",
        "  print('\\n'+key+':')\n",
        "  display(data_dict[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FuiybsIls7m1"
      },
      "outputs": [],
      "source": [
        "#forward input: (batch size (aka. # sentences), # words in sentence (including padding))\n",
        "#forward output: (batch size (aka. # sentences), # words in sentence (including padding), embedding dim)\n",
        "class Embedding_Node(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Embedding_Node, self).__init__()\n",
        "\n",
        "    self.W_e = nn.Parameter(torch.randn(vocab_size, embedding_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.W_e[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tjcCtOuDuH_t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "8b196d7d-0d84-40fd-eb69-a506ec7ffc44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "batch:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 1,  8,  3,  7,  4,  2],\n",
              "        [ 1,  5,  9,  2,  0,  0],\n",
              "        [ 1,  6,  3, 10,  2,  0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1, 6, 9, 3, 2],\n",
              "        [1, 4, 7, 2, 0],\n",
              "        [1, 5, 8, 2, 0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "batch:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 1,  8,  3,  7,  4,  2],\n",
              "        [ 1,  5,  9,  2,  0,  0],\n",
              "        [ 1,  6,  3, 10,  2,  0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1, 6, 9, 3, 2],\n",
              "        [1, 4, 7, 2, 0],\n",
              "        [1, 5, 8, 2, 0]])"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "### Seperates data into batches --> NEED TO GO OVER\n",
        "\n",
        "for input_batch, target_batch in data_dict['English-Italian Pytorch Dataloader']:\n",
        "  print('\\nbatch:')\n",
        "  display(input_batch)\n",
        "  display(target_batch)\n",
        "\n",
        "print('\\n\\nbatch:')\n",
        "display(input_batch)\n",
        "display(target_batch)\n",
        "\n",
        "#get input and output\n",
        "input, output = input_batch, target_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ctGekK2XXec4"
      },
      "outputs": [],
      "source": [
        "class Attention_Node(nn.Module):\n",
        "  def __init__(self,hidden_dim):\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    #key, query, value\n",
        "    self.W_key = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.W_query = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.W_value = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "  def forward(self, key_hidden, query_hidden, masked=False):\n",
        "    #key, query, value\n",
        "    key = self.W_key(key_hidden)\n",
        "    query = self.W_query(query_hidden)\n",
        "    value = self.W_value(key_hidden)\n",
        "\n",
        "    #get attention scores\n",
        "    attention_score = torch.matmul(query.T, key)\n",
        "\n",
        "    #masked - make upper triangle of values negative inf\n",
        "    if(masked):\n",
        "      mask = torch.triu(torch.ones_like(attention_score), diagonal=0).bool()\n",
        "      attention_score[~mask] = float('-inf')\n",
        "\n",
        "    #softmax\n",
        "    attention_dist = F.softmax(attention_score, dim=0)\n",
        "\n",
        "    #attention output - weighted sum\n",
        "    attention_output = torch.dot(attention_dist, value)\n",
        "\n",
        "    return attention_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RFJnOWSM4CxZ"
      },
      "outputs": [],
      "source": [
        "# att_node = Attention_Node(embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "odBJfqGfnoLZ"
      },
      "outputs": [],
      "source": [
        "class RNN_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, input_dim):\n",
        "    super(RNN_Node, self).__init__()\n",
        "\n",
        "    #all parameters that go into the rnn node\n",
        "    self.layer_weight = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
        "    self.hidden_weight = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.bias = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #store dimensions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dim = input_dim\n",
        "\n",
        "  #forward pass is how its connected to the next rnn node (regardless of layer or column)\n",
        "  def forward(self, input, prev_hidden):\n",
        "    #broadcast bias\n",
        "    bias = self.bias.expand(input.shape[0], self.hidden_dim)\n",
        "\n",
        "    #get hidden node\n",
        "    hidden_node = torch.sigmoid(torch.matmul(self.hidden_weight, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.layer_weight, input.T).T+\n",
        "                                     bias) #could also do tanh instead of sigmoid\n",
        "\n",
        "    return hidden_node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f8vTC4ea4iUE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xuBYxuXSsus3"
      },
      "outputs": [],
      "source": [
        "class LSTM_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, embed_dim):\n",
        "    super(LSTM_Node, self).__init__()\n",
        "\n",
        "    #forget weight / prev layer forget weight / forget bias\n",
        "    self.W_f = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_f = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_f = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #input weight / prev layer input weight / input bias\n",
        "    self.W_i = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_i = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_i = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #output weight / prev layer output weight / output bis\n",
        "    self.W_o = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_o = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_o = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #cell weight / prev layer cell weight / cell bias\n",
        "    self.W_c = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_c = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_c = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #store dimensions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "\n",
        "  #forward pass is how its connected to the next lstm node (regardless of layer or column)\n",
        "  def forward(self, input, prev_hidden, prev_cell):\n",
        "\n",
        "\n",
        "    #broadcast bias\n",
        "    b_f = self.b_f.expand(input.shape[0], self.hidden_dim)\n",
        "    b_i = self.b_i.expand(input.shape[0], self.hidden_dim)\n",
        "    b_o = self.b_o.expand(input.shape[0], self.hidden_dim)\n",
        "    b_c = self.b_c.expand(input.shape[0], self.hidden_dim)\n",
        "\n",
        "\n",
        "    #forget\n",
        "    f_t = torch.sigmoid(torch.matmul(self.W_f, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_f, input.T).T+\n",
        "                                     b_f)\n",
        "    #input\n",
        "    i_t = torch.sigmoid(torch.matmul(self.W_i, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_i, input.T).T+\n",
        "                                     b_i)\n",
        "    #output\n",
        "    o_t = torch.sigmoid(torch.matmul(self.W_o, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_o, input.T).T+\n",
        "                                     b_o)\n",
        "\n",
        "    #new cell data\n",
        "    nc_t = torch.tanh(torch.matmul(self.W_c, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_c, input.T).T+\n",
        "                                     b_c)\n",
        "\n",
        "    #cell\n",
        "    c_t = f_t*prev_cell + i_t*nc_t\n",
        "\n",
        "    #hidden\n",
        "    h_t = o_t*torch.tanh(c_t)\n",
        "\n",
        "    return h_t, c_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dHlOA5i1SlyU"
      },
      "outputs": [],
      "source": [
        "def add_norm(prev_x, new_x):\n",
        "  x = torch.cat(prev_x, new_x, dim=0)\n",
        "  x = nn.LayerNorm(x)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JuQ3OUL-hvFx"
      },
      "outputs": [],
      "source": [
        "class Transformer_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, embed_dim, ff_dim, decoder=False):\n",
        "    super(Transformer_Node, self).__init__()\n",
        "\n",
        "    ##layers##\n",
        "    #attention\n",
        "    self.attention = Attention_Node(hidden_dim)\n",
        "    self.decoder = decoder\n",
        "    if(decoder):\n",
        "      self.decoder_encoder_att = Attention_Node(hidden_dim)\n",
        "\n",
        "    #feed forwards\n",
        "    self.linear1 = nn.Linear(hidden_dim, ff_dim)\n",
        "    self.linear2 = nn.Linear(ff_dim, hidden_dim)\n",
        "\n",
        "\n",
        "  #how its connected to the next transformer node\n",
        "  def forward(self, inputs, encoder_hidden=None):\n",
        "    #multihead attention (with mask option) ?\n",
        "    if(self.decoder): # if decoder, only look at values before\n",
        "      attention_out = self.attention.forward(inputs, inputs, masked=True)\n",
        "    else:\n",
        "      attention_out = self.attention.forward(inputs, inputs)\n",
        "\n",
        "    #add and norm\n",
        "    x = add_norm(inputs, attention_out)\n",
        "\n",
        "    #encoder decoder attention\n",
        "    if(self.decoder):\n",
        "      x_prev = x\n",
        "      self.decoder_encoder_att.forward(encoder_hidden, x)\n",
        "      x = add_norm(x_prev, x)\n",
        "\n",
        "    x_prev = x\n",
        "    #feed forward\n",
        "    x = self.linear1(x)\n",
        "    x = self.linear2(x)\n",
        "\n",
        "    #activation function\n",
        "    x = nn.relu(x)\n",
        "\n",
        "    #add and norm\n",
        "    x = add_norm(x_prev, x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dZYVWsZ8haMS"
      },
      "outputs": [],
      "source": [
        "# class Transformer_Encoder(nn.Module):\n",
        "#   def __init__(self, hidden_dim, n_layers, vocab_size):\n",
        "#     super(Transformer_Encoder, self).__init__()\n",
        "\n",
        "#     #embedding\n",
        "#     self.embedding_node = Embedding_Node(vocab_size, hidden_dim)\n",
        "\n",
        "#     #layers\n",
        "#     self.layers = nn.ModuleList([Transformer_Node(hidden_dim) for i in range(0,n_layers)])\n",
        "\n",
        "#   def forward(self, inputs):\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "67QpPRLRXRlE"
      },
      "outputs": [],
      "source": [
        "# class Transformer_Node(nn.Module):\n",
        "#   def __init__(self, hidden_dim):\n",
        "#     super(Transformer_Node, self).__init__()\n",
        "\n",
        "#   def forward_encoder(self, inputs):\n",
        "#     pass\n",
        "\n",
        "#   def forward_decoder(self, inputs):\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZubrtWaX4r7z"
      },
      "outputs": [],
      "source": [
        "#for this, we basically said that what should be in the __init__ function should be any parameters that could be learned\n",
        "\n",
        "#ok, so for node elements, we'll say that in the __init__ funciton we should have the parameters whos weight should be learned\n",
        "#but for nn layers, well have things that define the layers/ hyperparameters\n",
        "\n",
        "#__init__ layer = anything that needs to be consistently referenced in forward pass (especially parameters that need to be updated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_LbTrPpDu0UD"
      },
      "outputs": [],
      "source": [
        "  # #define initial hidden states at run time - b/c of batch size\n",
        "  # def init_hidden(self, batch_size):\n",
        "  #   init_hidden_list = [torch.zeros(batch_size, self.hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   init_cell_list = None\n",
        "  #   if(self.node_type==\"lstm\"):\n",
        "  #     init_cell_list = [torch.zeros(batch_size, self.hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   return init_hidden_list, init_cell_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0a0efF-QRWMP"
      },
      "outputs": [],
      "source": [
        "#define initial hidden states at run time - b/c of batch size\n",
        "def init_hidden(self, batch_size):\n",
        "  #get device\n",
        "  device = next(self.parameters()).device\n",
        "\n",
        "  #itialize tens based on node type\n",
        "  init_hidden_tensor = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "  init_cell_tensor = None\n",
        "  if(self.node_type==\"lstm\"):\n",
        "    init_cell_tensor = torch.zeros(self.n_laryers, batch_size, self.hidden_dim).to(device)\n",
        "  return init_hidden_tensor, init_cell_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "li0D68hrlhen"
      },
      "outputs": [],
      "source": [
        "# input.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KUrdwxzVmO4E"
      },
      "outputs": [],
      "source": [
        "class EncoderNN(nn.Module):\n",
        "  def __init__(self, node_type, n_layers, hidden_dim, embed_dim, vocab_size):\n",
        "    super(EncoderNN, self).__init__()\n",
        "    # self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    #model parameters\n",
        "    self.n_layers = n_layers\n",
        "    self.node_type = node_type\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    #define embedding node\n",
        "    self.embedding_node = Embedding_Node(vocab_size, embed_dim)\n",
        "\n",
        "\n",
        "    #create layer of nodes based on type\n",
        "    node_class = RNN_Node if node_type == \"rnn\" else LSTM_Node\n",
        "    self.nodes = nn.ModuleList(\n",
        "          [node_class(hidden_dim, embed_dim)] +\n",
        "          [node_class(hidden_dim, hidden_dim) for _ in range(n_layers - 1)])\n",
        "\n",
        "  #forward pass\n",
        "  def forward(self, inputs):\n",
        "\n",
        "    #get blank nodes\n",
        "    node_list = self.nodes\n",
        "\n",
        "    #get shape params\n",
        "    batch_size = inputs.shape[0]\n",
        "    seq_size = inputs.shape[1]\n",
        "\n",
        "    #get initial states\n",
        "    # hidden_list, cell_list = self.init_hidden(inputs.shape[0])\n",
        "    hidden_tensor, cell_tensor = init_hidden(self, batch_size)\n",
        "    last_layer_hidden = torch.zeros(batch_size, seq_size, self.hidden_dim)\n",
        "\n",
        "    #turn input into embedding\n",
        "    embed_input = self.embedding_node.forward(inputs)\n",
        "\n",
        "    # print('this is the embedding inputs:')\n",
        "    # display(embed_input)\n",
        "\n",
        "    #store final layer hidden nodes (for attention)\n",
        "    # final_hidden_layer = []\n",
        "    # final_hidden_tensor = torch.zeros(batch_size, )\n",
        "\n",
        "\n",
        "    #iterate over each word in sentence\n",
        "    for word_i in range(0, seq_size):\n",
        "\n",
        "      input = embed_input[:,word_i] #input = (batch_size, hidden_dim) ##1 for each word\n",
        "\n",
        "      for layer in range(0,self.n_layers):\n",
        "        #if not first layer, then input is previous hidden state\n",
        "        if layer!=0:\n",
        "          input = hidden_tensor[layer-1]\n",
        "\n",
        "        #TRY TO SEE IF CAN MAKE NEATER\n",
        "        #forward pass -- TRY TO FIX LATER - AFTER TRANSFORMER\n",
        "        if(self.node_type==\"rnn\"):\n",
        "          hidden_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer]) # (batch, hidden dim)\n",
        "        elif(self.node_type=='lstm'):\n",
        "          hidden_tensor[layer], cell_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer], cell_tensor[layer]) # both of size (batch, hidden dim)\n",
        "\n",
        "      #store final hidden layer for each word - for attention\n",
        "      last_layer_hidden[:, word_i, :self.hidden_dim] = hidden_tensor[-1]\n",
        "\n",
        "    #format outputs\n",
        "    outputs = (hidden_tensor[-1], None) if self.node_type==\"rnn\" else (hidden_tensor[-1], cell_tensor[-1]) if self.node_type=='lstm' else None\n",
        "\n",
        "    return outputs, last_layer_hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nxcIFsTwXpvV"
      },
      "outputs": [],
      "source": [
        "# class BeamNode(nn.Module):\n",
        "#   def __init__(self, pred_vocab_indxs=[], pred_probs=[-np.inf], hidden_tens=None, cell_tens=None, parent_node=None):\n",
        "#     super(BeamNode, self).__init__()\n",
        "\n",
        "  #   # #relationship\n",
        "  #   # self.parent_node = parent_node\n",
        "\n",
        "  #   # #values\n",
        "  #   # self.pred_prob = pred_prob\n",
        "  #   # self.pred_vocab_indx = pred_vocab_indx\n",
        "\n",
        "  #   #running values\n",
        "  #   self.pred_probs = pred_probs\n",
        "  #   self.pred_vocab_indxs = pred_vocab_indxs\n",
        "\n",
        "  #   #recurrent states\n",
        "  #   self.hidden_tens = hidden_tens\n",
        "  #   self.cell_tens = cell_tens\n",
        "\n",
        "  #   #current state\n",
        "  #   self.eof_flag = 0\n",
        "\n",
        "  # def add_pred_probs(self, val):\n",
        "  #   self.pred_probs.append(val)\n",
        "\n",
        "  # def add_pred_vocab_indx(self, val):\n",
        "  #   self.pred_vocab_indxs.append(val)\n",
        "\n",
        "  # #calculate average log prob for comparing results\n",
        "  # def avg_log_prob(self):\n",
        "  #   norm_score = np.sum(np.log(self.pred_probs))/len(self.pred_probs)\n",
        "  #   return norm_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gKiXWgCvfAuD"
      },
      "outputs": [],
      "source": [
        "class DecoderNN(nn.Module):\n",
        "  def __init__(self, node_type, n_layers, hidden_dim, embed_dim, vocab_size, attention=False):\n",
        "    super(DecoderNN, self).__init__()\n",
        "\n",
        "    #model parameters\n",
        "    self.n_layers = n_layers\n",
        "    self.node_type = node_type\n",
        "    # self.max_length = max_length\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.vocab_size = vocab_size\n",
        "\n",
        "    #define embedding node\n",
        "    self.embedding_node = Embedding_Node(vocab_size, embed_dim)\n",
        "\n",
        "    #create layer of nodes based on type\n",
        "    node_class = RNN_Node if node_type == \"rnn\" else LSTM_Node\n",
        "    self.nodes = nn.ModuleList(\n",
        "          [node_class(hidden_dim, embed_dim)] +\n",
        "          [node_class(hidden_dim, hidden_dim) for _ in range(n_layers - 1)])\n",
        "\n",
        "\n",
        "    # # #store initial hidden states\n",
        "    # # #self.hidden = torch.randn(n_layers, hidden_dim)\n",
        "    # # self.cell = torch.randn(n_layers, hidden_dim) #only really applicable for lstm\n",
        "    # self.prev_hidden = torch.randn(n_layers, hidden_dim)\n",
        "    # self.prev_cell = torch.randn(n_layers, hidden_dim) #only really applicable for lstm\n",
        "\n",
        "\n",
        "    #output weights\n",
        "    self.W_out = nn.Parameter(torch.randn(vocab_size, hidden_dim))\n",
        "\n",
        "    #attention\n",
        "    self.attention = attention\n",
        "    if(attention):\n",
        "      self.attention_node = Attention_Node(hidden_dim)\n",
        "\n",
        "\n",
        "  # #define initial hidden states at run time - b/c of batch size\n",
        "  # def init_hidden(self, batch_size):\n",
        "  #   init_hidden_list = [torch.zeros(batch_size, hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   init_cell_list = None\n",
        "  #   if(self.node_type==\"lstm\"):\n",
        "  #     init_cell_list = [torch.zeros(batch_size, hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   return init_hidden_list, init_cell_list\n",
        "\n",
        "  #forward pass - considered as going over one word (versus encoder going over entire sentence) - training\n",
        "  def forward(self, input, hidden_tensor, cell_tensor=None, encoder_flayer=None):\n",
        "\n",
        "    #initial nodes\n",
        "    node_list = self.nodes\n",
        "\n",
        "    #get embedding of input\n",
        "    input = self.embedding_node.forward(input)[:,0] #only take one word\n",
        "\n",
        "    #forward pass for all layers (remember - not entire sentence, just 1 word)\n",
        "    for layer in range(0,self.n_layers):\n",
        "      #if not first layer, then input is previous hidden state\n",
        "      if layer!=0:\n",
        "        input = hidden_tensor[layer-1]\n",
        "\n",
        "      #forward pass\n",
        "      if(self.node_type==\"rnn\"):\n",
        "        hidden_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer]) # (batch, hidden dim)\n",
        "      elif(self.node_type=='lstm'):\n",
        "        hidden_tensor[layer], cell_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer], cell_tensor[layer]) # both of size (batch, hidden dim)\n",
        "\n",
        "      # print('\\nLAYER {}:'.format(layer))\n",
        "      # display(hidden_tensor)\n",
        "\n",
        "\n",
        "    #COME BACK TO ATTENTION\n",
        "    #attention\n",
        "    # if(self.attention):\n",
        "    #   attention_out = self.attention_node.forward(encoder_flayer, hidden_list[-1])\n",
        "    #   hidden_list[-1] = torch.cat((hidden_list[-1], attention_out), dim=0)\n",
        "\n",
        "    #generate final output\n",
        "    pred_output = torch.matmul(self.W_out, hidden_tensor[-1].T).T #during training - cross entropy fun converts this to prob\n",
        "\n",
        "    return hidden_tensor, cell_tensor, pred_output\n",
        "\n",
        "  #to generate predictions - generate one word at a time\n",
        "  #greedy decoding - uses/ predicts most probable word - singular\n",
        "  def pred(self, input, hidden_tens, cell_tens, encoder_flayer=None, sos_token=1,pad_token=0,eos_token=2):\n",
        "    # #adjust input\n",
        "    # input = input.unsqueeze(1)\n",
        "\n",
        "    #generate predicted word & others\n",
        "    hidden_tensor, cell_tensor, pred_logit = self.forward(input, hidden_tens, cell_tens, encoder_flayer)\n",
        "\n",
        "    #convert logits to prob\n",
        "    pred_prob = F.softmax(pred_logit, dim=1) #should be correct\n",
        "\n",
        "    #turn sos and pad tokens to not be possible predictions\n",
        "    pred_prob[:, sos_token] = -np.inf\n",
        "    pred_prob[:, pad_token] = -np.inf\n",
        "\n",
        "    return hidden_tensor, cell_tensor, pred_prob\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pFcsmyCYZEEy"
      },
      "outputs": [],
      "source": [
        "# def print_beam_nodes(node, order_count):\n",
        "#   print('\\nNode {}:'.format(order_count))\n",
        "#   # print('\\tParent Node:')\n",
        "#   # display(node.parent_node)\n",
        "#   print('\\tPred Prob List: {}'.format(node.pred_probs))\n",
        "#   print('\\tPred Vocab Index: {}'.format(node.pred_vocab_indxs))\n",
        "#   print('\\tHidden Tensor:')\n",
        "#   display(node.hidden_tens)\n",
        "#   print('shape: {}'.format(node.hidden_tens.shape))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  ###Different methods of scoring###\n",
        "\n",
        "  *cum_log_probs = cummulative log of probabilities\n",
        "    -tensor of shape (batch, beam_width, vocab_size)\n",
        "  *counts = lenghts of sequences\n",
        "    -tensor of shape (batch, beam_width)\n",
        "'''\n",
        "def normalization_scores(cum_log_probs, counts, norm_method, alpha=.6):\n",
        "  #reshape counts so that shape permits every vocab elem being divided by corresponding count\n",
        "  counts = counts.unsqueeze(-1)\n",
        "\n",
        "  scores = None\n",
        "\n",
        "  #no bias to long or short sequences\n",
        "  if (norm_method=='avg'):\n",
        "    scores = cum_log_probs / counts\n",
        "    #decide how much to penalize longer sequences\n",
        "  elif (norm_method=='norm'):\n",
        "    scores = cum_log_probs / ((5 + counts)**alpha)\n",
        "    #bias to shorter sequences\n",
        "  else:\n",
        "    scores = cum_log_probs\n",
        "\n",
        "  return scores"
      ],
      "metadata": {
        "id": "-bXP3iFqyJlE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "RQS3dWtMfNjg"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder_args, decoder_args, sos_token=1, eos_token=2, pad_token=0):#, greedy=True, beam_width=2):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "\n",
        "    #model structure\n",
        "    self.encoder = EncoderNN(*encoder_args)\n",
        "    self.decoder = DecoderNN(*decoder_args)\n",
        "\n",
        "    # #set other model params to be ref later\n",
        "    # self.encoder.node_type = encoder_args[0]\n",
        "    # self.decoder.node_type = decoder_args[0]\n",
        "\n",
        "    #set other model params to be ref later\n",
        "    # self.max_length = max_length\n",
        "    self.sos_token = sos_token\n",
        "    self.eos_token = eos_token\n",
        "    self.pad_token = pad_token\n",
        "\n",
        "    # #search params\n",
        "    # self.greedy = greedy\n",
        "    # self.beam_width = beam_width\n",
        "\n",
        "    # Linear layer to project encoder hidden dim to decoder hidden dim\n",
        "    enc_hid = encoder_args[2]\n",
        "    dec_hid = decoder_args[2]\n",
        "    self.hidden_transform = nn.Linear(enc_hid, dec_hid)\n",
        "    self.cell_transform = nn.Linear(enc_hid, dec_hid)\n",
        "\n",
        "  #run encoder and initialize decoder with hidden states\n",
        "  def run_enc_init_dec(self, inputs):\n",
        "    #put on correct device\n",
        "    device = next(self.parameters()).device\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    #encoder\n",
        "    node_class = RNN_Node if self.encoder.node_type == \"rnn\" else LSTM_Node\n",
        "    (enc_hidden_node, enc_cell_node), enc_final_hidden_layer = self.encoder.forward(inputs)\n",
        "\n",
        "    #initialize hidden and cell tensor\n",
        "    dec_hidden_tensor, dec_cell_tensor = init_hidden(self.decoder, inputs.shape[0])\n",
        "\n",
        "    #linear transform encoder return values - in case hidden sizes don't match\n",
        "    dec_hidden_tensor[0] = self.hidden_transform(enc_hidden_node)\n",
        "    if (dec_cell_tensor!=None) and (enc_cell_node!=None):\n",
        "      dec_cell_tensor[0] = self.cell_transform(enc_cell_node)\n",
        "\n",
        "    return dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer\n",
        "\n",
        "\n",
        "  #for the full system\n",
        "  def forward(self, inputs, outputs):\n",
        "    #put on correct device\n",
        "    device = next(self.parameters()).device\n",
        "#    inputs = inputs.to(device)\n",
        "    outputs = outputs.to(device)\n",
        "\n",
        "    # #encoder\n",
        "    # node_class = RNN_Node if self.encoder.node_type == \"rnn\" else LSTM_Node\n",
        "    # (enc_hidden_node, enc_cell_node), enc_final_hidden_layer = self.encoder.forward(inputs)\n",
        "\n",
        "    # #initialize hidden and cell tensor\n",
        "    # dec_hidden_tensor, dec_cell_tensor = init_hidden(self.decoder, inputs.shape[0])\n",
        "\n",
        "    # #linear transform encoder return values - in case hidden sizes don't match\n",
        "    # dec_hidden_tensor[0] = self.hidden_transform(enc_hidden_node)\n",
        "    # if (dec_cell_tensor!=None) and (enc_cell_node!=None):\n",
        "    #   dec_cell_tensor[0] = self.cell_transform(enc_cell_node)\n",
        "\n",
        "    #run encoder and initialize decoder with hidden states\n",
        "    dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer = self.run_enc_init_dec(inputs)\n",
        "\n",
        "    #decoder\n",
        "    pred_out_tensor = torch.zeros(outputs.size(0), len(outputs[0]), self.decoder.vocab_size, device=device) #before was device = outputs.device\n",
        "\n",
        "    for word_pos in range(0,len(outputs[0])):\n",
        "      # print('\\nWORD POSITION: {}'.format(word_pos))\n",
        "      #get particular word position for entire batch and reshape to have 2d array\n",
        "      word_batch = outputs[:,word_pos].unsqueeze(1)\n",
        "\n",
        "      #decoder forward pass\n",
        "      dec_hidden_tensor, dec_cell_tensor, pred_out = self.decoder.forward(word_batch, dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer)\n",
        "\n",
        "      #add value to prediction tensor\n",
        "      pred_out_tensor[:, word_pos, :] = pred_out\n",
        "\n",
        "\n",
        "    return pred_out_tensor #must make sure has shape (batch size, seq length, vocab size)\n",
        "\n",
        "  def greedy_pred(self, inputs, beam_width=1, max_length=30, norm_method='avg', alpha=.6):\n",
        "    #dimensions\n",
        "    batch_size = inputs.size(0)\n",
        "    vocab_size = self.decoder.vocab_size\n",
        "\n",
        "    #run encoder and initialize decoder with hidden states\n",
        "    dec_hidden_tensor, dec_cell_tensor, enc_flayer = self.run_enc_init_dec(inputs)\n",
        "\n",
        "    #initialize tensors\n",
        "    seqs = torch.full((batch_size, beam_width, 1 ), self.sos_token)\n",
        "    cum_log_probs = torch.full((batch_size, beam_width, 1 ), 0).to(dtype=torch.float32)\n",
        "    counts = torch.full((batch_size, beam_width), 0)\n",
        "\n",
        "    hidden = torch.cat((dec_hidden_tensor, dec_hidden_tensor), dim=1)\n",
        "    cell = dec_cell_tensor if dec_hidden_tensor is not None else None\n",
        "\n",
        "    #mask\n",
        "    cont_mask = torch.full((batch_size, beam_width), True, dtype=torch.bool)\n",
        "    # valid_batch = batch_size\n",
        "\n",
        "\n",
        "    print('\\n\\n')\n",
        "    for word_pos in range(0, max_length):\n",
        "      print('\\nWORD POSITION: {}'.format(word_pos))\n",
        "\n",
        "      #flattened masked\n",
        "      flat_mask = cont_mask.flatten()\n",
        "\n",
        "      #grab unmasked values\n",
        "      seqs_unmasked = seqs[cont_mask]\n",
        "      # cum_log_probs_unmasked = cum_log_probs[cont_mask]\n",
        "      # counts_unmasked = counts[cont_mask]\n",
        "\n",
        "      hidden_unmasked = hidden[:,flat_mask,:]\n",
        "      cell_unmasked = None if cell is None else cell[:,flat_mask,:]\n",
        "\n",
        "      #get last value in sequence\n",
        "      last_seqs_unmasked = seqs_unmasked[:,-1:]#.squeeze()\n",
        "\n",
        "      #generate predictions\n",
        "      hidden_new, cell_new, prob_full_vocab = self.decoder.pred(last_seqs_unmasked, hidden_unmasked, cell_unmasked, sos_token=self.sos_token, pad_token=self.pad_token)\n",
        "\n",
        "      ### UNMASKED SCORES ###\n",
        "\n",
        "      #create new tensor of shape (batch_size, beam_width, vocab_size)\n",
        "      cum_log_probs_unmasked = torch.full((batch_size, beam_width, vocab_size), -np.inf)\n",
        "\n",
        "      #replace with probabilities generated\n",
        "      cum_log_probs_unmasked[cont_mask] = prob_full_vocab ##MAKE SURE THIS LOOKS RIGHT\n",
        "\n",
        "      #apply log to non -np.inf\n",
        "      neg_inf_mask = cum_log_probs_unmasked != -np.inf\n",
        "      cum_log_probs_unmasked[neg_inf_mask] = torch.log(cum_log_probs_unmasked[neg_inf_mask])\n",
        "\n",
        "      #add cumulative values from parents\n",
        "      cum_log_probs_unmasked[cont_mask] = cum_log_probs_unmasked[cont_mask]+cum_log_probs[cont_mask] ##MAKE SURE THIS LOOKS RIGHT\n",
        "\n",
        "      #increase respective counts\n",
        "      # counts_unmasked = counts.clone()\n",
        "      # counts_unmasked[cont_mask] = counts_unmasked[cont_mask] + 1\n",
        "      counts[cont_mask] = counts[cont_mask] + 1\n",
        "\n",
        "      #generated unmasked scores\n",
        "      scores_unmasked = normalization_scores(cum_log_probs_unmasked, counts, norm_method, alpha)\n",
        "\n",
        "      #flatten scores\n",
        "      scores_unmasked = scores_unmasked.flatten(start_dim=1)\n",
        "\n",
        "      ### MASKED SCORES ###\n",
        "\n",
        "      # #grab eos cum log values\n",
        "      cum_log_probs_masked = cum_log_probs.clone()\n",
        "      cum_log_probs_masked[cont_mask] = -float('inf')\n",
        "\n",
        "      #generate masked scores\n",
        "      scores_masked = normalization_scores(cum_log_probs_masked, counts, norm_method, alpha)\n",
        "\n",
        "      #flatten\n",
        "      scores_masked = scores_masked.flatten(start_dim=1)\n",
        "\n",
        "      #combine the two\n",
        "      scores_comb = torch.cat([scores_unmasked, scores_masked], dim=1)\n",
        "\n",
        "      #get k most prob\n",
        "      topk_vals, topk_indx = torch.topk(scores_comb, k=beam_width, dim=1)\n",
        "\n",
        "      ### find out where these actually belong ###\n",
        "\n",
        "      #predicted parent\n",
        "      topk_parent = topk_indx // vocab_size\n",
        "\n",
        "      #predicted vocab value\n",
        "      topk_vocab = topk_indx % vocab_size\n",
        "\n",
        "      ### CHANGE SEQUENCE VALUES ###\n",
        "\n",
        "      #generate blank new sequence\n",
        "      new_seqs = torch.full((batch_size, beam_width, seqs.shape[2]+1), 0)\n",
        "\n",
        "      #generate parent mask\n",
        "      parent_mask = topk_parent < beam_width\n",
        "\n",
        "      ## non eos values - extend previous sequence\n",
        "\n",
        "      #get batch indices where the parent_mask is true\n",
        "      batch_indices, beam_indices = torch.where(parent_mask)\n",
        "\n",
        "      #get the actual parent indices that we're referening to\n",
        "      parent_indices = topk_parent[batch_indices, beam_indices]\n",
        "\n",
        "      #get sequence values that we plan on extending\n",
        "      seqs_extend = seqs[batch_indices, parent_indices]\n",
        "\n",
        "      #extend seqs with respective child vocab\n",
        "      seqs_extend = torch.cat((seqs_extend, topk_vocab[parent_mask].unsqueeze(1)), dim=1)\n",
        "\n",
        "      #replace values in new sequence\n",
        "      new_seqs[parent_mask] = seqs_extend\n",
        "\n",
        "      ## eos seq - copy and extend with eos token\n",
        "\n",
        "      #get batch indices where the parent_mask is false\n",
        "      batch_indices, beam_indices = torch.where(~parent_mask)\n",
        "\n",
        "      #get parents were referning to\n",
        "      parent_indices = topk_parent[batch_indices, beam_indices]\n",
        "\n",
        "      #get true indx relative to batch\n",
        "      true_indx = ((parent_indices-beam_width)*vocab_size)+topk_vocab[~parent_mask]\n",
        "\n",
        "      #grab value in original seqs\n",
        "      seqs_eos = seqs[batch_indices, true_indx]\n",
        "\n",
        "      #extend with eos token\n",
        "      eos_tens = torch.full((seqs_eos.shape[0],1), self.eos_token)\n",
        "      seqs_eos = torch.cat((seqs_eos, eos_tens), dim=1)\n",
        "\n",
        "      #replace in new sequences\n",
        "      new_seqs[~parent_mask] = seqs_eos\n",
        "\n",
        "      #### NOT SURE IF I SHOULD DO THIS HERE\n",
        "      #replace old seqs with new one\n",
        "      seqs = new_seqs\n",
        "\n",
        "      ### CHANGE CUM LOG PROB VALUES ###\n",
        "\n",
        "      #combine cum log probs from before\n",
        "      cum_log_probs_comb = torch.cat((cum_log_probs_unmasked.flatten(1), cum_log_probs_masked.flatten(1)), dim=1)\n",
        "\n",
        "      #grab indexes of top scores\n",
        "      cum_log_probs = torch.gather(cum_log_probs_comb, dim=1, index=topk_indx)\n",
        "\n",
        "      ### CHANGE HIDDEN AND CELL VALUES ###\n",
        "\n",
        "      #replace hidden and cell unmasked with new vals\n",
        "      hidden[:,flat_mask,:] = hidden_new\n",
        "      if(cell is not None):\n",
        "        cell[:,flat_mask,:] = cell_new\n",
        "      # topk_parent = torch.tensor([[2, 0],[0, 0],[3, 1]])\n",
        "      # topk_vocab = torch.tensor([[4, 2],[3, 4],[0, 4]])\n",
        "\n",
        "      # change eos values in parent index\n",
        "      topk_parent[~parent_mask] = true_indx\n",
        "\n",
        "      # adjust all to their linear values\n",
        "      adjust_vals = torch.arange(0,batch_size).unsqueeze(1) * beam_width\n",
        "      lin_seq = (topk_parent + adjust_vals).flatten()\n",
        "\n",
        "      #select indexes where top values were found\n",
        "      hidden = hidden[:,lin_seq,:]\n",
        "      if(cell is not None):\n",
        "        cell = cell[:,lin_seq,:]\n",
        "\n",
        "      ### CHANGE COUNT VALUES ###\n",
        "\n",
        "      #grab counts at indexes we used - then reshape\n",
        "      counts = counts.flatten()[lin_seq].reshape((batch_size, beam_width))\n",
        "\n",
        "      ### CHANGE MASK VALUES ###\n",
        "\n",
        "      #grab the new last sequence values\n",
        "      new_last_seq_vals = seqs[:,:,-1:]\n",
        "\n",
        "      #create a new mask\n",
        "      cont_mask = (new_last_seq_vals != self.eos_token).squeeze(2)\n",
        "\n",
        "      #if all sequences have terminated, break out of loop\n",
        "      if(torch.all(cont_mask == False)):\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "    return seqs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sGhUmJQmJ2Px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc971a2-dab0-4484-a4f4-ce17e2e73e97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'are': 3,\n",
              " 'going': 4,\n",
              " 'hello': 5,\n",
              " 'how': 6,\n",
              " 'we': 7,\n",
              " 'where': 8,\n",
              " 'world': 9,\n",
              " 'you': 10,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "data_dict[\"English Vocabulary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "a3G9it0h3vuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2e5bbc-b9f4-4e96-df86-bc9781152fa7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#have to seperate by word\n",
        "output[:,0].reshape(len(output),1)\n",
        "# len(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yFKRkAER4pI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e33214-8d92-48f0-d210-34079f125e57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "prev_input = torch.tensor([[1], [1], [1]])\n",
        "prev_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mUnpyblF9s4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a142a1-7369-4e0f-ef38-64ef10a8d832"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  8,  3,  7,  4,  2],\n",
              "        [ 1,  5,  9,  2,  0,  0],\n",
              "        [ 1,  6,  3, 10,  2,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "0eLejyzHk-V7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "bbe62cfb-5ce9-4baa-fb33-4dad86a8088c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocab size: 11\n",
            "Italian vocab size: 10\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "WORD POSITION: 0\n",
            "\n",
            "WORD POSITION: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (10) must match the size of tensor b (6) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-9787363e2469>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#testing out decoder prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mpred_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# print('\\n\\nPREDICTED OUTPUT')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-669e44203289>\u001b[0m in \u001b[0;36mgreedy_pred\u001b[0;34m(self, inputs, beam_width, max_length, norm_method, alpha)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0;31m#add cumulative values from parents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0mcum_log_probs_unmasked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcont_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcum_log_probs_unmasked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcont_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcum_log_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcont_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m##MAKE SURE THIS LOOKS RIGHT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0;31m#increase respective counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (6) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "\n",
        "#encoder param\n",
        "enc_node_type = \"rnn\"\n",
        "enc_n_layers = 2\n",
        "enc_hidden_dim = 4\n",
        "enc_embed_dim = 7\n",
        "eng_vocab_size = len(data_dict[\"English Vocabulary\"])\n",
        "\n",
        "#decoder_param\n",
        "dec_node_type = \"rnn\"\n",
        "dec_n_layers = 5\n",
        "dec_hidden_dim = 6\n",
        "dec_embed_dim = 8\n",
        "it_vocab_size = len(data_dict[\"Italian Vocabulary\"])\n",
        "\n",
        "#seq2seq param\n",
        "# max_length = 30\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "greedy=True\n",
        "beam_width=2\n",
        "sos_token=1\n",
        "eos_token=2\n",
        "pad_token=0\n",
        "\n",
        "# (self, node_type, n_layers, hidden_dim, embed_dim, vocab_size)\n",
        "# (self, node_type, n_layers, hidden_dim, embed_dim, vocab_size, attention=False, max_length=30)\n",
        "\n",
        "print('English vocab size: {}'.format(eng_vocab_size))\n",
        "print('Italian vocab size: {}'.format(it_vocab_size))\n",
        "\n",
        "#create seq2seq instance\n",
        "encoder_args = (enc_node_type, enc_n_layers, enc_hidden_dim, enc_embed_dim, eng_vocab_size)\n",
        "decoder_args = (dec_node_type, dec_n_layers, dec_hidden_dim, dec_embed_dim, it_vocab_size)\n",
        "seq2seq = Seq2Seq(encoder_args, decoder_args).to(device)#, greedy=greedy, beam_width=beam_width).to(device)\n",
        "\n",
        "#testing out decoder prediction\n",
        "pred_out = seq2seq.greedy_pred(input, beam_width=2, norm_method='avg')\n",
        "\n",
        "# print('\\n\\nPREDICTED OUTPUT')\n",
        "# pred_out\n",
        "\n",
        "# temp = seq2seq.forward(input, output)\n",
        "\n",
        "# prev_input = torch.tensor([[1], [1], [1]])\n",
        "# #itialize tens based on node type\n",
        "# batch_size = 3\n",
        "# init_hidden_tensor = torch.zeros(dec_n_layers, batch_size, dec_hidden_dim).to(device)\n",
        "# init_cell_tensor = None\n",
        "# #create decoder instance\n",
        "# decoder = DecoderNN(*decoder_args)\n",
        "# hidden_tensor, cell_tensor, pred_word_indx = decoder.pred(prev_input, init_hidden_tensor, init_cell_tensor)\n",
        "# pred_word_indx\n",
        "\n",
        "#init_hidden_tensor, init_cell_tensor = init_hidden(batch_size=3)\n",
        "\n",
        "\n",
        "# #################################################\n",
        "\n",
        "# temp = seq2seq.forward(input, output)\n",
        "# print('this is seq2seq forward output')\n",
        "# display(temp)\n",
        "# print(\"output shape: {}\".format(temp.shape))\n",
        "# print(\"output type: {}\".format(type(temp)))\n",
        "# #forward step\n",
        "\n",
        "# # #encoder instance\n",
        "# encoder = EncoderNN(*encoder_args)\n",
        "# enc_out, final_hidden_layer = encoder.forward(input)\n",
        "# enc_hidden_node = enc_out[0]\n",
        "\n",
        "# print('\\n\\n\\nafter encoder test step')\n",
        "\n",
        "\n",
        "\n",
        "# #decoder instance\n",
        "# decoder = DecoderNN(*decoder_args)\n",
        "# #initialize hidden and cell list32\n",
        "# dec_hidden_list, dec_cell_list = init_hidden(decoder, output.shape[0])\n",
        "# dec_hidden_list[0] = enc_hidden_node\n",
        "\n",
        "# pred_out = decoder.forward(output[:,0].reshape(len(output), 1), dec_hidden_list, None, final_hidden_layer)\n",
        "# print('\\nafter decoder test step')\n",
        "\n",
        "# #create encoder instance\n",
        "# encoder = EncoderNN(node_type, n_layers, hidden_dim, embed_dim, eng_vocab_size)\n",
        "\n",
        "# #forward step\n",
        "# hidden_list, final_hidden_layer = encoder.forward(input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# temp_list = [-np.inf, -np.inf, 2.2337, 1.5088, -1.1219, -0.1127,  0.3876,\n",
        "#           -0.1635,  0.8167, -1.1368]\n",
        "# new_vals = [x/4 for x in temp_list]\n",
        "# display(new_vals)\n"
      ],
      "metadata": {
        "id": "30E5pZk80Idc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEED TO FUN ABOVE CoDE UNTIL WE SEE 2 AS VALUE - THATS EOS INDICATOR\n",
        "--SEE IF FIX OF PRED PROB = NONE AND PRED VOCAB= 2 VALUES ARE GOOD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "6p0F6VIzjiSZ",
        "outputId": "ab615e5d-46e1-4ae1-fc1b-605b202a8ae4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-33-f811e0500364>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-f811e0500364>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    NEED TO FUN ABOVE CoDE UNTIL WE SEE 2 AS VALUE - THATS EOS INDICATOR\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68w2HKH1lNK5"
      },
      "outputs": [],
      "source": [
        "print('true output')\n",
        "display(output)\n",
        "print(\"true output shape: {}\".format(output.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAVdhuINsyD3"
      },
      "source": [
        "Notes:\n",
        "\n",
        "- before running - write in comments how each dimension is looking like after each computation - helpful for debugging\n",
        "\n",
        "- incorporate batches!\n",
        "\n",
        "- transformers\n",
        "\n",
        "- beam search\n",
        "\n",
        "- bidirectional\n",
        "\n",
        "- different attention methods\n",
        "\n",
        "-- evaluate with Bleu scores\n",
        "\n",
        "\n",
        "SHOULD ADD\n",
        "- dependency parsing, pretraining, and fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X8KzhGEsRrD"
      },
      "source": [
        "Run time notes:\n",
        "\n",
        "- embedding size: Common values for the embedding dimension in NLP tasks range from 50 to 300, but larger values like 512 or 1024 can be used for more complex tasks or larger datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsAm8IVIdpr0"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCf6oljaPnAZtN1g9zGZBY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}