{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smargetic/Natural_Language_Processing/blob/main/Machine_Translation/Neural_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-eYx0G4p02W"
      },
      "outputs": [],
      "source": [
        "!pip install nbconvert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E38McwRXbyKA"
      },
      "outputs": [],
      "source": [
        "#data storage - not sure if important\n",
        "import pandas as pd\n",
        "\n",
        "#make sure to show all values in pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "#pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#visualize\n",
        "from IPython.display import display\n",
        "\n",
        "#help import other functions\n",
        "import os\n",
        "\n",
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJRgbpQDJyVT",
        "outputId": "d116df1e-2795-48f6-dac7-0eefd3224747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Files currently present:\n",
            "['sentences_base.csv', 'ita_sentences_CC0.tsv', 'eng_sentences_detailed.tsv', 'eng_sentences.tsv', 'ita_sentences_detailed.tsv', 'eng_sentences_CC0.tsv', 'ita_sentences.tsv', 'Sentence pairs in English-Italian - 2024-07-26.tsv', 'Helper_Functions.ipynb', 'Model_Train_Predict.ipynb', '__pycache__', 'Data_Intake_and_Preprocessing.ipynb', 'intake_preprocess_utils.ipynb', 'intake_preprocess_utils.py', 'Neural_Net.ipynb']\n",
            "[NbConvertApp] Converting notebook intake_preprocess_utils.ipynb to script\n",
            "[NbConvertApp] Writing 11518 bytes to intake_preprocess_utils.txt\n",
            "\n",
            "\n",
            "New files in current directory:\n",
            "['sentences_base.csv', 'ita_sentences_CC0.tsv', 'eng_sentences_detailed.tsv', 'eng_sentences.tsv', 'ita_sentences_detailed.tsv', 'eng_sentences_CC0.tsv', 'ita_sentences.tsv', 'Sentence pairs in English-Italian - 2024-07-26.tsv', 'Helper_Functions.ipynb', 'Model_Train_Predict.ipynb', '__pycache__', 'Data_Intake_and_Preprocessing.ipynb', 'intake_preprocess_utils.ipynb', 'intake_preprocess_utils.py', 'Neural_Net.ipynb']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##to obtain functions from another .ipynb file\n",
        "\n",
        "#go to current directory\n",
        "os.chdir('/content/drive/My Drive/Coding Projects/Machine Translation')\n",
        "\n",
        "#List the files in the current directory\n",
        "print('\\nFiles currently present:')\n",
        "print(os.listdir())\n",
        "\n",
        "#Convert the notebook to a Python script\n",
        "!jupyter nbconvert --to script intake_preprocess_utils.ipynb\n",
        "os.rename('intake_preprocess_utils.txt', 'intake_preprocess_utils.py')\n",
        "\n",
        "print('\\n\\nNew files in current directory:')\n",
        "print(os.listdir())\n",
        "print('\\n\\n')\n",
        "\n",
        "#import functions\n",
        "from intake_preprocess_utils import get_file_and_disp, get_sample, dump_sample, data_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HOifKYsyxoIs"
      },
      "outputs": [],
      "source": [
        "# #english to italian translation - just to test\n",
        "# df_eng_it = get_file_and_disp(fileName=\"Sentence pairs in English-Italian - 2024-07-26.tsv.zip\" ,sep='\\t', stringName=\"English to Italian\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test data set\n",
        "df = pd.DataFrame({\n",
        "                  0:[1,2,3],\n",
        "                  1:[\"hello world\", \"how are you\", \"where are we going\"],\n",
        "                  2:[1,2,3],\n",
        "                  3: [\"ciao mondo\", \"come stai\", \"dove stiamo andando\"]})\n",
        "\n",
        "display(df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "mRoEVDsAWxDV",
        "outputId": "ccabfa00-aa18-4b1e-b03c-1a1e2c173f08"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   0                   1  2                    3\n",
              "0  1         hello world  1           ciao mondo\n",
              "1  2         how are you  2            come stai\n",
              "2  3  where are we going  3  dove stiamo andando"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc88cc1b-5e58-4e48-aad7-83904c3c859b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>hello world</td>\n",
              "      <td>1</td>\n",
              "      <td>ciao mondo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how are you</td>\n",
              "      <td>2</td>\n",
              "      <td>come stai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>where are we going</td>\n",
              "      <td>3</td>\n",
              "      <td>dove stiamo andando</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc88cc1b-5e58-4e48-aad7-83904c3c859b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc88cc1b-5e58-4e48-aad7-83904c3c859b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc88cc1b-5e58-4e48-aad7-83904c3c859b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-21814368-d331-47b4-9cf7-3bd0d32f8185\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21814368-d331-47b4-9cf7-3bd0d32f8185')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-21814368-d331-47b4-9cf7-3bd0d32f8185 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0131ad6f-23da-4e91-b299-2fae3174ad27\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0131ad6f-23da-4e91-b299-2fae3174ad27 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hello world\",\n          \"how are you\",\n          \"where are we going\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ciao mondo\",\n          \"come stai\",\n          \"dove stiamo andando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#go through preprocessing\n",
        "data_dict= data_preprocessing(df.copy(), pytorchB=True, tensorflowB=False, store=False, sample=False, download=False, sing=False)\n",
        "for key in data_dict.keys():\n",
        "  print('\\n'+key+':')\n",
        "  display(data_dict[key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QmDxJKD6dQ2j",
        "outputId": "4cd96b33-3ad6-4f00-d5ec-0a94683fe7a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nulls in English: 0\n",
            "Nulls in Italian: 0\n",
            "\n",
            "English/Italian Translations:\n",
            "\tEnglish vocabulary size: 11\n",
            "\tItalian vocabulary size: 10\n",
            "\n",
            "Done with Pytorch.\n",
            "\n",
            "English-Italian Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   eng_id        eng_sentence  it_id          it_sentence  \\\n",
              "0       1         hello world      1           ciao mondo   \n",
              "1       2         how are you      2            come stai   \n",
              "2       3  where are we going      3  dove stiamo andando   \n",
              "\n",
              "                              eng_tokens  \\\n",
              "0           [<sos>, hello, world, <eos>]   \n",
              "1          [<sos>, how, are, you, <eos>]   \n",
              "2  [<sos>, where, are, we, going, <eos>]   \n",
              "\n",
              "                               it_tokens      eng_tokens_enc    it_tokens_enc  \\\n",
              "0            [<sos>, ciao, mondo, <eos>]        [1, 5, 9, 2]     [1, 4, 7, 2]   \n",
              "1             [<sos>, come, stai, <eos>]    [1, 6, 3, 10, 2]     [1, 5, 8, 2]   \n",
              "2  [<sos>, dove, stiamo, andando, <eos>]  [1, 8, 3, 7, 4, 2]  [1, 6, 9, 3, 2]   \n",
              "\n",
              "                                                      eng_tokens_enc_p  \\\n",
              "0   [tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]   \n",
              "1  [tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]   \n",
              "2   [tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]   \n",
              "\n",
              "                                           it_tokens_enc_p  \n",
              "0  [tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]  \n",
              "1  [tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]  \n",
              "2  [tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2271fa40-aff7-4c1d-a34f-1e43929224a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng_id</th>\n",
              "      <th>eng_sentence</th>\n",
              "      <th>it_id</th>\n",
              "      <th>it_sentence</th>\n",
              "      <th>eng_tokens</th>\n",
              "      <th>it_tokens</th>\n",
              "      <th>eng_tokens_enc</th>\n",
              "      <th>it_tokens_enc</th>\n",
              "      <th>eng_tokens_enc_p</th>\n",
              "      <th>it_tokens_enc_p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>hello world</td>\n",
              "      <td>1</td>\n",
              "      <td>ciao mondo</td>\n",
              "      <td>[&lt;sos&gt;, hello, world, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, ciao, mondo, &lt;eos&gt;]</td>\n",
              "      <td>[1, 5, 9, 2]</td>\n",
              "      <td>[1, 4, 7, 2]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how are you</td>\n",
              "      <td>2</td>\n",
              "      <td>come stai</td>\n",
              "      <td>[&lt;sos&gt;, how, are, you, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, come, stai, &lt;eos&gt;]</td>\n",
              "      <td>[1, 6, 3, 10, 2]</td>\n",
              "      <td>[1, 5, 8, 2]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>where are we going</td>\n",
              "      <td>3</td>\n",
              "      <td>dove stiamo andando</td>\n",
              "      <td>[&lt;sos&gt;, where, are, we, going, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, dove, stiamo, andando, &lt;eos&gt;]</td>\n",
              "      <td>[1, 8, 3, 7, 4, 2]</td>\n",
              "      <td>[1, 6, 9, 3, 2]</td>\n",
              "      <td>[tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2271fa40-aff7-4c1d-a34f-1e43929224a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2271fa40-aff7-4c1d-a34f-1e43929224a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2271fa40-aff7-4c1d-a34f-1e43929224a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6aeb00c0-1220-48f0-829b-1ab5ac6c2274\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6aeb00c0-1220-48f0-829b-1ab5ac6c2274')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6aeb00c0-1220-48f0-829b-1ab5ac6c2274 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  display(data_dict[key])\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"eng_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hello world\",\n          \"how are you\",\n          \"where are we going\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ciao mondo\",\n          \"come stai\",\n          \"dove stiamo andando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 5, 9, 2, 0, 0])\",\n          \"tensor([ 1,  6,  3, 10,  2,  0])\",\n          \"tensor([1, 8, 3, 7, 4, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 4, 7, 2, 0])\",\n          \"tensor([1, 5, 8, 2, 0])\",\n          \"tensor([1, 6, 9, 3, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian SING Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x78dda4bab670>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'are': 3,\n",
              " 'going': 4,\n",
              " 'hello': 5,\n",
              " 'how': 6,\n",
              " 'we': 7,\n",
              " 'where': 8,\n",
              " 'world': 9,\n",
              " 'you': 10,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'andando': 3,\n",
              " 'ciao': 4,\n",
              " 'come': 5,\n",
              " 'dove': 6,\n",
              " 'mondo': 7,\n",
              " 'stai': 8,\n",
              " 'stiamo': 9,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FuiybsIls7m1"
      },
      "outputs": [],
      "source": [
        "#forward input: (batch size (aka. # sentences), # words in sentence (including padding))\n",
        "#forward output: (batch size (aka. # sentences), # words in sentence (including padding), embedding dim)\n",
        "class Embedding_Node(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Embedding_Node, self).__init__()\n",
        "\n",
        "    self.W_e = nn.Parameter(torch.randn(vocab_size, embedding_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.W_e[x]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Seperates data into batches --> NEED TO GO OVER\n",
        "\n",
        "for input_batch, target_batch in data_dict['English-Italian Pytorch Dataloader']:\n",
        "  print('\\nbatch:')\n",
        "  display(input_batch)\n",
        "  display(target_batch)\n",
        "\n",
        "print('\\n\\nbatch:')\n",
        "display(input_batch)\n",
        "display(target_batch)\n",
        "\n",
        "#get input and output\n",
        "input, output = input_batch, target_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "tjcCtOuDuH_t",
        "outputId": "7be0d8f1-dfd1-4c43-f1fb-43bd2831fcdd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "batch:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 1,  6,  3, 10,  2,  0],\n",
              "        [ 1,  8,  3,  7,  4,  2],\n",
              "        [ 1,  5,  9,  2,  0,  0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1, 5, 8, 2, 0],\n",
              "        [1, 6, 9, 3, 2],\n",
              "        [1, 4, 7, 2, 0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "batch:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 1,  6,  3, 10,  2,  0],\n",
              "        [ 1,  8,  3,  7,  4,  2],\n",
              "        [ 1,  5,  9,  2,  0,  0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1, 5, 8, 2, 0],\n",
              "        [1, 6, 9, 3, 2],\n",
              "        [1, 4, 7, 2, 0]])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ctGekK2XXec4"
      },
      "outputs": [],
      "source": [
        "class Attention_Node(nn.Module):\n",
        "  def __init__(self,hidden_dim):\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    #key, query, value\n",
        "    self.W_key = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.W_query = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.W_value = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "  def forward(self, key_hidden, query_hidden, masked=False):\n",
        "    #key, query, value\n",
        "    key = self.W_key(key_hidden)\n",
        "    query = self.W_query(query_hidden)\n",
        "    value = self.W_value(key_hidden)\n",
        "\n",
        "    #get attention scores\n",
        "    attention_score = torch.matmul(query.T, key)\n",
        "\n",
        "    #masked - make upper triangle of values negative inf\n",
        "    if(masked):\n",
        "      mask = torch.triu(torch.ones_like(attention_score), diagonal=0).bool()\n",
        "      attention_score[~mask] = float('-inf')\n",
        "\n",
        "    #softmax\n",
        "    attention_dist = F.softmax(attention_score, dim=0)\n",
        "\n",
        "    #attention output - weighted sum\n",
        "    attention_output = torch.dot(attention_dist, value)\n",
        "\n",
        "    return attention_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# att_node = Attention_Node(embedding_dim)"
      ],
      "metadata": {
        "id": "RFJnOWSM4CxZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "odBJfqGfnoLZ"
      },
      "outputs": [],
      "source": [
        "class RNN_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, input_dim):\n",
        "    super(RNN_Node, self).__init__()\n",
        "\n",
        "    #all parameters that go into the rnn node\n",
        "    self.layer_weight = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
        "    self.hidden_weight = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.bias = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #store dimensions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dim = input_dim\n",
        "\n",
        "  #forward pass is how its connected to the next rnn node (regardless of layer or column)\n",
        "  def forward(self, input, prev_hidden):\n",
        "\n",
        "    #broadcast bias\n",
        "    bias = self.bias.expand(input.shape[0], self.hidden_dim)\n",
        "\n",
        "    #get hidden node\n",
        "    hidden_node = torch.sigmoid(torch.matmul(self.hidden_weight, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.layer_weight, input.T).T+\n",
        "                                     bias) #could also do tanh instead of sigmoid\n",
        "\n",
        "    return hidden_node\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8vTC4ea4iUE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xuBYxuXSsus3"
      },
      "outputs": [],
      "source": [
        "class LSTM_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, embed_dim):\n",
        "    super(LSTM_Node, self).__init__()\n",
        "\n",
        "    #forget weight / prev layer forget weight / forget bias\n",
        "    self.W_f = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_f = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_f = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #input weight / prev layer input weight / input bias\n",
        "    self.W_i = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_i = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_i = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #output weight / prev layer output weight / output bis\n",
        "    self.W_o = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_o = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_o = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #cell weight / prev layer cell weight / cell bias\n",
        "    self.W_c = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_c = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_c = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #store dimensions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "\n",
        "  #forward pass is how its connected to the next lstm node (regardless of layer or column)\n",
        "  def forward(self, input, prev_hidden, prev_cell):\n",
        "\n",
        "\n",
        "    #broadcast bias\n",
        "    b_f = self.b_f.expand(input.shape[0], self.hidden_dim)\n",
        "    b_i = self.b_i.expand(input.shape[0], self.hidden_dim)\n",
        "    b_o = self.b_o.expand(input.shape[0], self.hidden_dim)\n",
        "    b_c = self.b_c.expand(input.shape[0], self.hidden_dim)\n",
        "\n",
        "\n",
        "    #forget\n",
        "    f_t = torch.sigmoid(torch.matmul(self.W_f, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_f, input.T).T+\n",
        "                                     b_f)\n",
        "    #input\n",
        "    i_t = torch.sigmoid(torch.matmul(self.W_i, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_i, input.T).T+\n",
        "                                     b_i)\n",
        "    #output\n",
        "    o_t = torch.sigmoid(torch.matmul(self.W_o, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_o, input.T).T+\n",
        "                                     b_o)\n",
        "\n",
        "    #new cell data\n",
        "    nc_t = torch.tanh(torch.matmul(self.W_c, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_c, input.T).T+\n",
        "                                     b_c)\n",
        "\n",
        "    #cell\n",
        "    c_t = f_t*prev_cell + i_t*nc_t\n",
        "\n",
        "    #hidden\n",
        "    h_t = o_t*torch.tanh(c_t)\n",
        "\n",
        "    return h_t, c_t\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_norm(prev_x, new_x):\n",
        "  x = torch.cat(prev_x, new_x, dim=0)\n",
        "  x = nn.LayerNorm(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "dHlOA5i1SlyU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JuQ3OUL-hvFx"
      },
      "outputs": [],
      "source": [
        "class Transformer_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, embed_dim, ff_dim, decoder=False):\n",
        "    super(Transformer_Node, self).__init__()\n",
        "\n",
        "    ##layers##\n",
        "    #attention\n",
        "    self.attention = Attention_Node(hidden_dim)\n",
        "    self.decoder = decoder\n",
        "    if(decoder):\n",
        "      self.decoder_encoder_att = Attention_Node(hidden_dim)\n",
        "\n",
        "    #feed forwards\n",
        "    self.linear1 = nn.Linear(hidden_dim, ff_dim)\n",
        "    self.linear2 = nn.Linear(ff_dim, hidden_dim)\n",
        "\n",
        "\n",
        "  #how its connected to the next transformer node\n",
        "  def forward(self, inputs, encoder_hidden=None):\n",
        "    #multihead attention (with mask option) ?\n",
        "    if(self.decoder): # if decoder, only look at values before\n",
        "      attention_out = self.attention.forward(inputs, inputs, masked=True)\n",
        "    else:\n",
        "      attention_out = self.attention.forward(inputs, inputs)\n",
        "\n",
        "    #add and norm\n",
        "    x = add_norm(inputs, attention_out)\n",
        "\n",
        "    #encoder decoder attention\n",
        "    if(self.decoder):\n",
        "      x_prev = x\n",
        "      self.decoder_encoder_att.forward(encoder_hidden, x)\n",
        "      x = add_norm(x_prev, x)\n",
        "\n",
        "    x_prev = x\n",
        "    #feed forward\n",
        "    x = self.linear1(x)\n",
        "    x = self.linear2(x)\n",
        "\n",
        "    #activation function\n",
        "    x = nn.relu(x)\n",
        "\n",
        "    #add and norm\n",
        "    x = add_norm(x_prev, x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dZYVWsZ8haMS"
      },
      "outputs": [],
      "source": [
        "# class Transformer_Encoder(nn.Module):\n",
        "#   def __init__(self, hidden_dim, n_layers, vocab_size):\n",
        "#     super(Transformer_Encoder, self).__init__()\n",
        "\n",
        "#     #embedding\n",
        "#     self.embedding_node = Embedding_Node(vocab_size, hidden_dim)\n",
        "\n",
        "#     #layers\n",
        "#     self.layers = nn.ModuleList([Transformer_Node(hidden_dim) for i in range(0,n_layers)])\n",
        "\n",
        "#   def forward(self, inputs):\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "67QpPRLRXRlE"
      },
      "outputs": [],
      "source": [
        "# class Transformer_Node(nn.Module):\n",
        "#   def __init__(self, hidden_dim):\n",
        "#     super(Transformer_Node, self).__init__()\n",
        "\n",
        "#   def forward_encoder(self, inputs):\n",
        "#     pass\n",
        "\n",
        "#   def forward_decoder(self, inputs):\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZubrtWaX4r7z"
      },
      "outputs": [],
      "source": [
        "#for this, we basically said that what should be in the __init__ function should be any parameters that could be learned\n",
        "\n",
        "#ok, so for node elements, we'll say that in the __init__ funciton we should have the parameters whos weight should be learned\n",
        "#but for nn layers, well have things that define the layers/ hyperparameters\n",
        "\n",
        "#__init__ layer = anything that needs to be consistently referenced in forward pass (especially parameters that need to be updated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "KUrdwxzVmO4E"
      },
      "outputs": [],
      "source": [
        "class EncoderNN(nn.Module):\n",
        "  def __init__(self, node_type, n_layers, hidden_dim, embed_dim, vocab_size):\n",
        "    super(EncoderNN, self).__init__()\n",
        "\n",
        "    #model parameters\n",
        "    self.n_layers = n_layers\n",
        "    self.node_type = node_type\n",
        "\n",
        "    #define embedding node\n",
        "    self.embedding_node = Embedding_Node(vocab_size, embed_dim) # I guess this is one node?\n",
        "\n",
        "\n",
        "    #create layer of nodes based on type\n",
        "    node_class = RNN_Node if node_type == \"rnn\" else LSTM_Node\n",
        "    self.nodes = nn.ModuleList(\n",
        "          [node_class(hidden_dim, embed_dim)] +\n",
        "          [node_class(hidden_dim, hidden_dim) for _ in range(n_layers - 1)])\n",
        "\n",
        "  #define initial hidden states at run time - b/c of batch size\n",
        "  def init_hidden(self, batch_size):\n",
        "    init_hidden_node = [torch.zeros(batch_size, hidden_dim) for _ in range(self.n_layers)]\n",
        "    init_cell_node = None\n",
        "    if(self.node_type==\"lstm\"):\n",
        "      init_cell_node = [torch.zeros(batch_size, hidden_dim) for _ in range(self.n_layers)]\n",
        "    return init_hidden_node, init_cell_node\n",
        "\n",
        "\n",
        "  #forward pass - considered\n",
        "  def forward(self, inputs):\n",
        "\n",
        "    #get blank nodes\n",
        "    node_list = self.nodes\n",
        "\n",
        "    #get initial states\n",
        "    hidden_list, cell_list = self.init_hidden(inputs.shape[0])\n",
        "\n",
        "    #store final layer hidden nodes (for attention)\n",
        "    final_hidden_layer = []\n",
        "\n",
        "    #turn input into embedding\n",
        "    embed_input = self.embedding_node.forward(inputs)\n",
        "\n",
        "    #iterate over each word in sentence (# sent=batch size)\n",
        "    for word_i in range(0, embed_input.shape[1]):\n",
        "\n",
        "      input = embed_input[:,word_i] #input = (batch_size, hidden_dim) ##1 for each word\n",
        "\n",
        "      for layer in range(0,self.n_layers):\n",
        "        #if not first layer, then input is previous hidden state\n",
        "        if layer!=0:\n",
        "          input = hidden_list[layer-1]\n",
        "\n",
        "        #TRY TO SEE IF CAN MAKE NEATER\n",
        "        #forward pass\n",
        "        if(self.node_type==\"rnn\"):\n",
        "          hidden_list[layer] = node_list[layer].forward(input, hidden_list[layer]) # (batch, hidden dim)\n",
        "        elif(self.node_type=='lstm'):\n",
        "          hidden_list[layer], cell_list[layer] = node_list[layer].forward(input, hidden_list[layer], cell_list[layer]) # both of size (batch, hidden dim)\n",
        "\n",
        "      #store final hidden layer\n",
        "      final_hidden_layer.append(hidden_list[-1])\n",
        "\n",
        "      #format outputs\n",
        "      outputs = hidden_list[-1] if self.node_type==\"rnn\" else (hidden_list[-1], cell_list[-1]) if self.node_type=='lstm' else None\n",
        "\n",
        "\n",
        "    return outputs, final_hidden_layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYOOCwmMCgv8",
        "outputId": "fa140867-f9a5-4036-bb42-f26c580bf47d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  6,  3, 10,  2,  0],\n",
              "        [ 1,  8,  3,  7,  4,  2],\n",
              "        [ 1,  5,  9,  2,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#go through preprocessing\n",
        "data_dict= data_preprocessing(df.copy(), pytorchB=True, tensorflowB=False, store=False, sample=False, download=False, sing=False)\n",
        "for key in data_dict.keys():\n",
        "  print('\\n'+key+':')\n",
        "  display(data_dict[key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IAg0fdpbTAKE",
        "outputId": "63073757-1a78-431e-c3ca-c9dc22620499"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nulls in English: 0\n",
            "Nulls in Italian: 0\n",
            "\n",
            "English/Italian Translations:\n",
            "\tEnglish vocabulary size: 11\n",
            "\tItalian vocabulary size: 10\n",
            "\n",
            "Done with Pytorch.\n",
            "\n",
            "English-Italian Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   eng_id        eng_sentence  it_id          it_sentence  \\\n",
              "0       1         hello world      1           ciao mondo   \n",
              "1       2         how are you      2            come stai   \n",
              "2       3  where are we going      3  dove stiamo andando   \n",
              "\n",
              "                              eng_tokens  \\\n",
              "0           [<sos>, hello, world, <eos>]   \n",
              "1          [<sos>, how, are, you, <eos>]   \n",
              "2  [<sos>, where, are, we, going, <eos>]   \n",
              "\n",
              "                               it_tokens      eng_tokens_enc    it_tokens_enc  \\\n",
              "0            [<sos>, ciao, mondo, <eos>]        [1, 5, 9, 2]     [1, 4, 7, 2]   \n",
              "1             [<sos>, come, stai, <eos>]    [1, 6, 3, 10, 2]     [1, 5, 8, 2]   \n",
              "2  [<sos>, dove, stiamo, andando, <eos>]  [1, 8, 3, 7, 4, 2]  [1, 6, 9, 3, 2]   \n",
              "\n",
              "                                                      eng_tokens_enc_p  \\\n",
              "0   [tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]   \n",
              "1  [tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]   \n",
              "2   [tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]   \n",
              "\n",
              "                                           it_tokens_enc_p  \n",
              "0  [tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]  \n",
              "1  [tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]  \n",
              "2  [tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81759443-095a-4676-aaf7-b30c9b4ce908\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng_id</th>\n",
              "      <th>eng_sentence</th>\n",
              "      <th>it_id</th>\n",
              "      <th>it_sentence</th>\n",
              "      <th>eng_tokens</th>\n",
              "      <th>it_tokens</th>\n",
              "      <th>eng_tokens_enc</th>\n",
              "      <th>it_tokens_enc</th>\n",
              "      <th>eng_tokens_enc_p</th>\n",
              "      <th>it_tokens_enc_p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>hello world</td>\n",
              "      <td>1</td>\n",
              "      <td>ciao mondo</td>\n",
              "      <td>[&lt;sos&gt;, hello, world, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, ciao, mondo, &lt;eos&gt;]</td>\n",
              "      <td>[1, 5, 9, 2]</td>\n",
              "      <td>[1, 4, 7, 2]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how are you</td>\n",
              "      <td>2</td>\n",
              "      <td>come stai</td>\n",
              "      <td>[&lt;sos&gt;, how, are, you, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, come, stai, &lt;eos&gt;]</td>\n",
              "      <td>[1, 6, 3, 10, 2]</td>\n",
              "      <td>[1, 5, 8, 2]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>where are we going</td>\n",
              "      <td>3</td>\n",
              "      <td>dove stiamo andando</td>\n",
              "      <td>[&lt;sos&gt;, where, are, we, going, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, dove, stiamo, andando, &lt;eos&gt;]</td>\n",
              "      <td>[1, 8, 3, 7, 4, 2]</td>\n",
              "      <td>[1, 6, 9, 3, 2]</td>\n",
              "      <td>[tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81759443-095a-4676-aaf7-b30c9b4ce908')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81759443-095a-4676-aaf7-b30c9b4ce908 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81759443-095a-4676-aaf7-b30c9b4ce908');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6addc181-b77e-4667-9339-6cf713f6af27\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6addc181-b77e-4667-9339-6cf713f6af27')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6addc181-b77e-4667-9339-6cf713f6af27 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  display(data_dict[key])\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"eng_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hello world\",\n          \"how are you\",\n          \"where are we going\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ciao mondo\",\n          \"come stai\",\n          \"dove stiamo andando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 5, 9, 2, 0, 0])\",\n          \"tensor([ 1,  6,  3, 10,  2,  0])\",\n          \"tensor([1, 8, 3, 7, 4, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 4, 7, 2, 0])\",\n          \"tensor([1, 5, 8, 2, 0])\",\n          \"tensor([1, 6, 9, 3, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian SING Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x78debfc57010>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'are': 3,\n",
              " 'going': 4,\n",
              " 'hello': 5,\n",
              " 'how': 6,\n",
              " 'we': 7,\n",
              " 'where': 8,\n",
              " 'world': 9,\n",
              " 'you': 10,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'andando': 3,\n",
              " 'ciao': 4,\n",
              " 'come': 5,\n",
              " 'dove': 6,\n",
              " 'mondo': 7,\n",
              " 'stai': 8,\n",
              " 'stiamo': 9,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# node_type = \"lstm\"\n",
        "# n_layers = 2\n",
        "# hidden_dim = 4\n",
        "# embed_dim = 7\n",
        "# #vocab size\n",
        "# eng_vocab_size = len(data_dict[\"English Vocabulary\"])\n",
        "# it_vocab_size = len(data_dict[\"Italian Vocabulary\"])\n",
        "\n",
        "# print('English vocab size: {}'.format(eng_vocab_size))\n",
        "# print('Italian vocab size: {}'.format(it_vocab_size))\n",
        "\n",
        "# #create encoder instance\n",
        "# encoder = EncoderNN(node_type, n_layers, hidden_dim, embed_dim, eng_vocab_size)\n",
        "\n",
        "# #forward step\n",
        "# hidden_list, final_hidden_layer = encoder.forward(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2zaz2EZ1hX6",
        "outputId": "559d2144-7c57-4438-c884-58170ec28832"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocab size: 11\n",
            "Italian vocab size: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input"
      ],
      "metadata": {
        "id": "M16k_wSP3IDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #forward step\n",
        "# hidden_list, final_hidden_layer = encoder.forward(input)"
      ],
      "metadata": {
        "id": "irGVEb6N2w1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKiXWgCvfAuD"
      },
      "outputs": [],
      "source": [
        "class DecoderNN(nn.Module):\n",
        "  def __init__(self, node_type, n_layers, hidden_dim, vocab_size, attention=False, max_length=30):\n",
        "    super(DecoderNN, self).__init__()\n",
        "\n",
        "    #model parameters\n",
        "    self.n_layers = n_layers\n",
        "    self.node_type = node_type\n",
        "    self.max_length = max_length\n",
        "\n",
        "    #define embedding node\n",
        "    self.embedding_node = Embedding_Node(vocab_size, hidden_dim) # I guess this is one node?\n",
        "\n",
        "    #create layer of nodes based on type\n",
        "    if(node_type==\"rnn\"):\n",
        "      self.nodes = nn.ModuleList([RNN_Node(hidden_dim) for i in range(0,n_layers)])\n",
        "    else:\n",
        "      self.nodes = nn.ModuleList([LSTM_Node(hidden_dim) for i in range(0,n_layers)])\n",
        "\n",
        "    # #store initial hidden states\n",
        "    # #self.hidden = torch.randn(n_layers, hidden_dim)\n",
        "    # self.cell = torch.randn(n_layers, hidden_dim) #only really applicable for lstm\n",
        "    self.prev_hidden = torch.randn(n_layers, hidden_dim)\n",
        "    self.prev_cell = torch.randn(n_layers, hidden_dim) #only really applicable for lstm\n",
        "\n",
        "\n",
        "    #output weights\n",
        "    self.W_out = nn.Parameter(torch.randn(vocab_size, hidden_dim))\n",
        "\n",
        "    #attention\n",
        "    self.attention = attention\n",
        "    if(attention):\n",
        "      self.attention_node = Attention_Node(hidden_dim)\n",
        "\n",
        "  #forward pass - must iterate over\n",
        "  def forward(self, input, prev_hidden, prev_cell=None, encoder_flayer=None):\n",
        "    #start with blank hidden and cell states\n",
        "    hidden_list = self.prev_hidden\n",
        "    cell_list = self.prev_cell\n",
        "\n",
        "    #depending on the length, replace hidden and cell states\n",
        "    hidden_list[:len(prev_hidden)] = prev_hidden\n",
        "    if(prev_cell!=None):\n",
        "      cell_list[:len(prev_cell)] = prev_cell\n",
        "\n",
        "    #initial nodes\n",
        "    node_list = self.nodes\n",
        "\n",
        "    #get embedding of input\n",
        "    input = self.embedding_node.forward(input)\n",
        "\n",
        "\n",
        "    #put input through all layers\n",
        "    for i in range(0,self.n_layers):\n",
        "      if(self.node_type=='rnn'):\n",
        "        hidden_list[i] = node_list[i].forward(input, hidden_list[i])\n",
        "      elif (self.node_type=='lstm'):\n",
        "        hidden_list[i], cell_list[i] = node_list[i].forward(input, hidden_list[i], cell_list[i])\n",
        "\n",
        "      #new input is prev output\n",
        "      input = hidden_list[i]\n",
        "\n",
        "    #attention\n",
        "    if(self.attention):\n",
        "      attention_out = self.attention_node.forward(encoder_flayer, hidden_list[-1])\n",
        "      hidden_list[-1] = torch.cat((hidden_list[-1], attention_out), dim=0)\n",
        "\n",
        "    #generate final output\n",
        "    output = torch.dot(self.W_out, hidden_list[-1])\n",
        "\n",
        "    return output, hidden_list, cell_list\n",
        "\n",
        "  #to generate predictions - could either do this step by step, or generate all predictions in one go\n",
        "  def pred(self, hidden_list, cell_list=None, encoder_flayer=None):\n",
        "    output_list = []\n",
        "    input = 0 # <sos> = start of sentence\n",
        "\n",
        "    #keep predicting unless reach max_length or break out clause\n",
        "    for count in range(0,self.max_length):\n",
        "      input, hidden_list, cell_list = self.forward(input, hidden_list, cell_list)\n",
        "\n",
        "      output_list.append(input)\n",
        "\n",
        "      #<eos>\n",
        "      if(input==1):\n",
        "        break\n",
        "\n",
        "    # #turn into tensor\n",
        "    # output_list = torch.cat(output_list, dim=0)\n",
        "    # display(output_list)\n",
        "\n",
        "    #attention\n",
        "    if(self.attention):\n",
        "      attention_out = self.attention_node.forward(encoder_flayer, output_list)\n",
        "      output_list = torch.cat((output_list, attention_out), dim=0)\n",
        "    else: #DOUBLE CHECK ON THIS\n",
        "      output_list = torch.cat(output_list, dim=0)\n",
        "\n",
        "    #put through softmax\n",
        "    output_list = F.softmax(output_list, dim=0)\n",
        "\n",
        "    return output_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQS3dWtMfNjg"
      },
      "outputs": [],
      "source": [
        "### NEED TO FIX - ONLY FINAL HIDDEN STATE AND CELL STATE ARE PASSED TO THE DECODER ###\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder_args, decoder_args):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "\n",
        "    #model structure\n",
        "    self.encoder = EncoderNN(*encoder_args)\n",
        "    self.decoder = DecoderNN(*decoder_args)\n",
        "\n",
        "    #set other model params to be ref later\n",
        "    self.encoder.node_type = encoder_args[0]\n",
        "    self.decoder.node_type = decoder_args[0]\n",
        "\n",
        "\n",
        "  #for the full system\n",
        "  def forward(self, inputs, outputs):\n",
        "\n",
        "    #encoder\n",
        "    if (self.encoder.node_type == \"rnn\"):\n",
        "      hidden_list, final_hidden_layer = self.encoder.forward(inputs)\n",
        "      cell_list = None\n",
        "    elif (self.encoder.node_type == \"lstm\"):\n",
        "      hidden_list, cell_list, final_hidden_layer = self.encoder.forward(inputs)\n",
        "\n",
        "    #decoder - does this only use the last hidden state/ cell state???? ******\n",
        "    pred_out = []\n",
        "    for i in range(0, len(outputs)):\n",
        "      if(self.decoder.node_type == \"rnn\"):\n",
        "        pred_out[i], hidden_list, cell_list = self.decoder.forward(input=outputs[i], prev_hidden=hidden_list, encoder_flayer=final_hidden_layer)\n",
        "      elif (self.decoder.node_type == \"lstm\")\n",
        "        pred_out[i], hidden_list, cell_list = self.decoder.forward(input=outputs[i], prev_hidden=hidden_list, prev_cell=cell_list, encoder_flayer=final_hidden_layer)\n",
        "\n",
        "\n",
        "    return pred_out #must make sure has shape (batch size, seq length, vocab size)\n",
        "\n",
        "\n",
        "  def pred(self, inputs):\n",
        "    # #encoder\n",
        "    if (self.encoder.node_type == \"rnn\"):\n",
        "      hidden_list, final_hidden_layer = self.encoder.forward(inputs)\n",
        "      cell_list = None\n",
        "    elif (self.encoder.node_type == \"lstm\"):\n",
        "      hidden_list, cell_list, final_hidden_layer = self.encoder.forward(inputs)\n",
        "\n",
        "    #decoder\n",
        "    if (self.decoder.node_type == \"rnn\"):\n",
        "      pred_out = self.decoder.pred(hidden_list, encoder_flayer=final_hidden_layer)\n",
        "    elif (self.decoder.node_type == \"lstm\"):\n",
        "      pred_out = self.decoder.pred(hidden_list, cell_list, encoder_flayer=final_hidden_layer)\n",
        "\n",
        "    return pred_out\n",
        "\n",
        "    #input to decoder depends on what the encoder was\n",
        "\n",
        "    # #decoder\n",
        "    # if(self.decoder.node_type == \"rnn\"):\n",
        "    #   outputs = self.decoder.forward(hidden_list)\n",
        "    # else:\n",
        "    #   outputs = self.decoder.forward(hidden_list, cell_list)\n",
        "\n",
        "    #attention\n",
        "\n",
        "\n",
        "    # return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eLejyzHk-V7"
      },
      "outputs": [],
      "source": [
        "node_type = \"lstm\"\n",
        "n_layers = 2\n",
        "hidden_dim = 4\n",
        "embed_dim = 7\n",
        "#vocab size\n",
        "eng_vocab_size = len(data_dict[\"English Vocabulary\"])\n",
        "it_vocab_size = len(data_dict[\"Italian Vocabulary\"])\n",
        "\n",
        "print('English vocab size: {}'.format(eng_vocab_size))\n",
        "print('Italian vocab size: {}'.format(it_vocab_size))\n",
        "\n",
        "#create encoder instance\n",
        "encoder = EncoderNN(node_type, n_layers, hidden_dim, embed_dim, eng_vocab_size)\n",
        "\n",
        "#forward step\n",
        "hidden_list, final_hidden_layer = encoder.forward(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAVdhuINsyD3"
      },
      "source": [
        "Notes:\n",
        "\n",
        "- before running - write in comments how each dimension is looking like after each computation - helpful for debugging\n",
        "\n",
        "- incorporate batches!\n",
        "\n",
        "- transformers\n",
        "\n",
        "- beam search\n",
        "\n",
        "- bidirectional\n",
        "\n",
        "- different attention methods\n",
        "\n",
        "-- evaluate with Bleu scores\n",
        "\n",
        "\n",
        "SHOULD ADD\n",
        "- dependency parsing, pretraining, and fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run time notes:\n",
        "\n",
        "- embedding size: Common values for the embedding dimension in NLP tasks range from 50 to 300, but larger values like 512 or 1024 can be used for more complex tasks or larger datasets."
      ],
      "metadata": {
        "id": "6X8KzhGEsRrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GsAm8IVIdpr0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTVWTOL18mwpdBgasip0kE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}