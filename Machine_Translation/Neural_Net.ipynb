{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smargetic/Natural_Language_Processing/blob/main/Machine_Translation/Neural_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-eYx0G4p02W",
        "outputId": "0d6d2ea2-c596-4487-cd99-f936697c526b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (7.16.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (0.10.1)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (5.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert) (24.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (2.18.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (1.4.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (5.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert) (4.3.6)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.5.0->nbconvert) (6.1.12)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7->nbconvert) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7->nbconvert) (4.23.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert) (2.6)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.22.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.8.2)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.3.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nbconvert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E38McwRXbyKA",
        "outputId": "fb6770fa-bec6-4af8-8f63-91be5408557c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#data storage - not sure if important\n",
        "import pandas as pd\n",
        "import numpy as np #can take away later\n",
        "\n",
        "#make sure to show all values in pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "#pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#visualize\n",
        "from IPython.display import display\n",
        "\n",
        "#help import other functions\n",
        "import os\n",
        "\n",
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJRgbpQDJyVT",
        "outputId": "8a55b327-b2d4-46d8-9fe0-d5696ce29d35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Files currently present:\n",
            "['sentences_base.csv', 'ita_sentences_CC0.tsv', 'eng_sentences_detailed.tsv', 'eng_sentences.tsv', 'ita_sentences_detailed.tsv', 'eng_sentences_CC0.tsv', 'ita_sentences.tsv', 'Sentence pairs in English-Italian - 2024-07-26.tsv', 'Helper_Functions.ipynb', 'Model_Train_Predict.ipynb', '__pycache__', 'Data_Intake_and_Preprocessing.ipynb', 'intake_preprocess_utils.ipynb', 'intake_preprocess_utils.py', 'Neural_Net.ipynb']\n",
            "[NbConvertApp] Converting notebook intake_preprocess_utils.ipynb to script\n",
            "[NbConvertApp] Writing 11518 bytes to intake_preprocess_utils.txt\n",
            "\n",
            "\n",
            "New files in current directory:\n",
            "['sentences_base.csv', 'ita_sentences_CC0.tsv', 'eng_sentences_detailed.tsv', 'eng_sentences.tsv', 'ita_sentences_detailed.tsv', 'eng_sentences_CC0.tsv', 'ita_sentences.tsv', 'Sentence pairs in English-Italian - 2024-07-26.tsv', 'Helper_Functions.ipynb', 'Model_Train_Predict.ipynb', '__pycache__', 'Data_Intake_and_Preprocessing.ipynb', 'intake_preprocess_utils.ipynb', 'intake_preprocess_utils.py', 'Neural_Net.ipynb']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##to obtain functions from another .ipynb file\n",
        "\n",
        "#go to current directory\n",
        "os.chdir('/content/drive/My Drive/Coding Projects/Machine Translation')\n",
        "\n",
        "#List the files in the current directory\n",
        "print('\\nFiles currently present:')\n",
        "print(os.listdir())\n",
        "\n",
        "#Convert the notebook to a Python script\n",
        "!jupyter nbconvert --to script intake_preprocess_utils.ipynb\n",
        "os.rename('intake_preprocess_utils.txt', 'intake_preprocess_utils.py')\n",
        "\n",
        "print('\\n\\nNew files in current directory:')\n",
        "print(os.listdir())\n",
        "print('\\n\\n')\n",
        "\n",
        "#import functions\n",
        "from intake_preprocess_utils import get_file_and_disp, get_sample, dump_sample, data_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "HOifKYsyxoIs"
      },
      "outputs": [],
      "source": [
        "# #english to italian translation - just to test\n",
        "# df_eng_it = get_file_and_disp(fileName=\"Sentence pairs in English-Italian - 2024-07-26.tsv.zip\" ,sep='\\t', stringName=\"English to Italian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "mRoEVDsAWxDV",
        "outputId": "27c380ed-0582-4a8a-af38-b507a3fba390"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   0                   1  2                    3\n",
              "0  1         hello world  1           ciao mondo\n",
              "1  2         how are you  2            come stai\n",
              "2  3  where are we going  3  dove stiamo andando"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73db6442-1076-4e59-a52d-f3bd477106bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>hello world</td>\n",
              "      <td>1</td>\n",
              "      <td>ciao mondo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how are you</td>\n",
              "      <td>2</td>\n",
              "      <td>come stai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>where are we going</td>\n",
              "      <td>3</td>\n",
              "      <td>dove stiamo andando</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73db6442-1076-4e59-a52d-f3bd477106bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73db6442-1076-4e59-a52d-f3bd477106bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73db6442-1076-4e59-a52d-f3bd477106bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-701c6553-2658-48e0-a6dd-8f6d2b08ee83\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-701c6553-2658-48e0-a6dd-8f6d2b08ee83')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-701c6553-2658-48e0-a6dd-8f6d2b08ee83 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_53358805-d6e6-4b58-a5e4-36bbcda150d1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_53358805-d6e6-4b58-a5e4-36bbcda150d1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hello world\",\n          \"how are you\",\n          \"where are we going\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ciao mondo\",\n          \"come stai\",\n          \"dove stiamo andando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#test data set\n",
        "df = pd.DataFrame({\n",
        "                  0:[1,2,3],\n",
        "                  1:[\"hello world\", \"how are you\", \"where are we going\"],\n",
        "                  2:[1,2,3],\n",
        "                  3: [\"ciao mondo\", \"come stai\", \"dove stiamo andando\"]})\n",
        "\n",
        "display(df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QmDxJKD6dQ2j",
        "outputId": "09700f13-4998-437c-ad5f-d1d1179a4368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nulls in English: 0\n",
            "Nulls in Italian: 0\n",
            "\n",
            "English/Italian Translations:\n",
            "\tEnglish vocabulary size: 11\n",
            "\tItalian vocabulary size: 10\n",
            "\n",
            "Done with Pytorch.\n",
            "\n",
            "English-Italian Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   eng_id        eng_sentence  it_id          it_sentence  \\\n",
              "0       1         hello world      1           ciao mondo   \n",
              "1       2         how are you      2            come stai   \n",
              "2       3  where are we going      3  dove stiamo andando   \n",
              "\n",
              "                              eng_tokens  \\\n",
              "0           [<sos>, hello, world, <eos>]   \n",
              "1          [<sos>, how, are, you, <eos>]   \n",
              "2  [<sos>, where, are, we, going, <eos>]   \n",
              "\n",
              "                               it_tokens      eng_tokens_enc    it_tokens_enc  \\\n",
              "0            [<sos>, ciao, mondo, <eos>]        [1, 5, 9, 2]     [1, 4, 7, 2]   \n",
              "1             [<sos>, come, stai, <eos>]    [1, 6, 3, 10, 2]     [1, 5, 8, 2]   \n",
              "2  [<sos>, dove, stiamo, andando, <eos>]  [1, 8, 3, 7, 4, 2]  [1, 6, 9, 3, 2]   \n",
              "\n",
              "                                                      eng_tokens_enc_p  \\\n",
              "0   [tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]   \n",
              "1  [tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]   \n",
              "2   [tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]   \n",
              "\n",
              "                                           it_tokens_enc_p  \n",
              "0  [tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]  \n",
              "1  [tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]  \n",
              "2  [tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c272e7d3-932c-4018-bbd2-0b0a12489212\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng_id</th>\n",
              "      <th>eng_sentence</th>\n",
              "      <th>it_id</th>\n",
              "      <th>it_sentence</th>\n",
              "      <th>eng_tokens</th>\n",
              "      <th>it_tokens</th>\n",
              "      <th>eng_tokens_enc</th>\n",
              "      <th>it_tokens_enc</th>\n",
              "      <th>eng_tokens_enc_p</th>\n",
              "      <th>it_tokens_enc_p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>hello world</td>\n",
              "      <td>1</td>\n",
              "      <td>ciao mondo</td>\n",
              "      <td>[&lt;sos&gt;, hello, world, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, ciao, mondo, &lt;eos&gt;]</td>\n",
              "      <td>[1, 5, 9, 2]</td>\n",
              "      <td>[1, 4, 7, 2]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how are you</td>\n",
              "      <td>2</td>\n",
              "      <td>come stai</td>\n",
              "      <td>[&lt;sos&gt;, how, are, you, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, come, stai, &lt;eos&gt;]</td>\n",
              "      <td>[1, 6, 3, 10, 2]</td>\n",
              "      <td>[1, 5, 8, 2]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>where are we going</td>\n",
              "      <td>3</td>\n",
              "      <td>dove stiamo andando</td>\n",
              "      <td>[&lt;sos&gt;, where, are, we, going, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, dove, stiamo, andando, &lt;eos&gt;]</td>\n",
              "      <td>[1, 8, 3, 7, 4, 2]</td>\n",
              "      <td>[1, 6, 9, 3, 2]</td>\n",
              "      <td>[tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c272e7d3-932c-4018-bbd2-0b0a12489212')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c272e7d3-932c-4018-bbd2-0b0a12489212 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c272e7d3-932c-4018-bbd2-0b0a12489212');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f7fa0adb-539f-4d19-a9ee-20b3913909d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7fa0adb-539f-4d19-a9ee-20b3913909d6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f7fa0adb-539f-4d19-a9ee-20b3913909d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  display(data_dict[key])\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"eng_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hello world\",\n          \"how are you\",\n          \"where are we going\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ciao mondo\",\n          \"come stai\",\n          \"dove stiamo andando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 5, 9, 2, 0, 0])\",\n          \"tensor([ 1,  6,  3, 10,  2,  0])\",\n          \"tensor([1, 8, 3, 7, 4, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 4, 7, 2, 0])\",\n          \"tensor([1, 5, 8, 2, 0])\",\n          \"tensor([1, 6, 9, 3, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian SING Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f0008267a00>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'are': 3,\n",
              " 'going': 4,\n",
              " 'hello': 5,\n",
              " 'how': 6,\n",
              " 'we': 7,\n",
              " 'where': 8,\n",
              " 'world': 9,\n",
              " 'you': 10,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'andando': 3,\n",
              " 'ciao': 4,\n",
              " 'come': 5,\n",
              " 'dove': 6,\n",
              " 'mondo': 7,\n",
              " 'stai': 8,\n",
              " 'stiamo': 9,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#go through preprocessing\n",
        "data_dict= data_preprocessing(df.copy(), pytorchB=True, tensorflowB=False, store=False, sample=False, download=False, sing=False)\n",
        "for key in data_dict.keys():\n",
        "  print('\\n'+key+':')\n",
        "  display(data_dict[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "FuiybsIls7m1"
      },
      "outputs": [],
      "source": [
        "#forward input: (batch size (aka. # sentences), # words in sentence (including padding))\n",
        "#forward output: (batch size (aka. # sentences), # words in sentence (including padding), embedding dim)\n",
        "class Embedding_Node(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Embedding_Node, self).__init__()\n",
        "\n",
        "    self.W_e = nn.Parameter(torch.randn(vocab_size, embedding_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.W_e[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "tjcCtOuDuH_t",
        "outputId": "8a93eb69-1798-45f2-8d6f-1068cd1dfc42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "batch:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 1,  8,  3,  7,  4,  2],\n",
              "        [ 1,  5,  9,  2,  0,  0],\n",
              "        [ 1,  6,  3, 10,  2,  0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1, 6, 9, 3, 2],\n",
              "        [1, 4, 7, 2, 0],\n",
              "        [1, 5, 8, 2, 0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "batch:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 1,  8,  3,  7,  4,  2],\n",
              "        [ 1,  5,  9,  2,  0,  0],\n",
              "        [ 1,  6,  3, 10,  2,  0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1, 6, 9, 3, 2],\n",
              "        [1, 4, 7, 2, 0],\n",
              "        [1, 5, 8, 2, 0]])"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "### Seperates data into batches --> NEED TO GO OVER\n",
        "\n",
        "for input_batch, target_batch in data_dict['English-Italian Pytorch Dataloader']:\n",
        "  print('\\nbatch:')\n",
        "  display(input_batch)\n",
        "  display(target_batch)\n",
        "\n",
        "print('\\n\\nbatch:')\n",
        "display(input_batch)\n",
        "display(target_batch)\n",
        "\n",
        "#get input and output\n",
        "input, output = input_batch, target_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "ctGekK2XXec4"
      },
      "outputs": [],
      "source": [
        "class Attention_Node(nn.Module):\n",
        "  def __init__(self,hidden_dim):\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    #key, query, value\n",
        "    self.W_key = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.W_query = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.W_value = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "  def forward(self, key_hidden, query_hidden, masked=False):\n",
        "    #key, query, value\n",
        "    key = self.W_key(key_hidden)\n",
        "    query = self.W_query(query_hidden)\n",
        "    value = self.W_value(key_hidden)\n",
        "\n",
        "    #get attention scores\n",
        "    attention_score = torch.matmul(query.T, key)\n",
        "\n",
        "    #masked - make upper triangle of values negative inf\n",
        "    if(masked):\n",
        "      mask = torch.triu(torch.ones_like(attention_score), diagonal=0).bool()\n",
        "      attention_score[~mask] = float('-inf')\n",
        "\n",
        "    #softmax\n",
        "    attention_dist = F.softmax(attention_score, dim=0)\n",
        "\n",
        "    #attention output - weighted sum\n",
        "    attention_output = torch.dot(attention_dist, value)\n",
        "\n",
        "    return attention_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "RFJnOWSM4CxZ"
      },
      "outputs": [],
      "source": [
        "# att_node = Attention_Node(embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "odBJfqGfnoLZ"
      },
      "outputs": [],
      "source": [
        "class RNN_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, input_dim):\n",
        "    super(RNN_Node, self).__init__()\n",
        "\n",
        "    #all parameters that go into the rnn node\n",
        "    self.layer_weight = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
        "    self.hidden_weight = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.bias = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #store dimensions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dim = input_dim\n",
        "\n",
        "  #forward pass is how its connected to the next rnn node (regardless of layer or column)\n",
        "  def forward(self, input, prev_hidden):\n",
        "    #broadcast bias\n",
        "    bias = self.bias.expand(input.shape[0], self.hidden_dim)\n",
        "\n",
        "    #get hidden node\n",
        "    hidden_node = torch.sigmoid(torch.matmul(self.hidden_weight, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.layer_weight, input.T).T+\n",
        "                                     bias) #could also do tanh instead of sigmoid\n",
        "\n",
        "    return hidden_node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "f8vTC4ea4iUE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "xuBYxuXSsus3"
      },
      "outputs": [],
      "source": [
        "class LSTM_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, embed_dim):\n",
        "    super(LSTM_Node, self).__init__()\n",
        "\n",
        "    #forget weight / prev layer forget weight / forget bias\n",
        "    self.W_f = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_f = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_f = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #input weight / prev layer input weight / input bias\n",
        "    self.W_i = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_i = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_i = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #output weight / prev layer output weight / output bis\n",
        "    self.W_o = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_o = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_o = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #cell weight / prev layer cell weight / cell bias\n",
        "    self.W_c = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_c = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_c = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #store dimensions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "\n",
        "  #forward pass is how its connected to the next lstm node (regardless of layer or column)\n",
        "  def forward(self, input, prev_hidden, prev_cell):\n",
        "\n",
        "\n",
        "    #broadcast bias\n",
        "    b_f = self.b_f.expand(input.shape[0], self.hidden_dim)\n",
        "    b_i = self.b_i.expand(input.shape[0], self.hidden_dim)\n",
        "    b_o = self.b_o.expand(input.shape[0], self.hidden_dim)\n",
        "    b_c = self.b_c.expand(input.shape[0], self.hidden_dim)\n",
        "\n",
        "\n",
        "    #forget\n",
        "    f_t = torch.sigmoid(torch.matmul(self.W_f, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_f, input.T).T+\n",
        "                                     b_f)\n",
        "    #input\n",
        "    i_t = torch.sigmoid(torch.matmul(self.W_i, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_i, input.T).T+\n",
        "                                     b_i)\n",
        "    #output\n",
        "    o_t = torch.sigmoid(torch.matmul(self.W_o, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_o, input.T).T+\n",
        "                                     b_o)\n",
        "\n",
        "    #new cell data\n",
        "    nc_t = torch.tanh(torch.matmul(self.W_c, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_c, input.T).T+\n",
        "                                     b_c)\n",
        "\n",
        "    #cell\n",
        "    c_t = f_t*prev_cell + i_t*nc_t\n",
        "\n",
        "    #hidden\n",
        "    h_t = o_t*torch.tanh(c_t)\n",
        "\n",
        "    return h_t, c_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "dHlOA5i1SlyU"
      },
      "outputs": [],
      "source": [
        "def add_norm(prev_x, new_x):\n",
        "  x = torch.cat(prev_x, new_x, dim=0)\n",
        "  x = nn.LayerNorm(x)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "JuQ3OUL-hvFx"
      },
      "outputs": [],
      "source": [
        "class Transformer_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, embed_dim, ff_dim, decoder=False):\n",
        "    super(Transformer_Node, self).__init__()\n",
        "\n",
        "    ##layers##\n",
        "    #attention\n",
        "    self.attention = Attention_Node(hidden_dim)\n",
        "    self.decoder = decoder\n",
        "    if(decoder):\n",
        "      self.decoder_encoder_att = Attention_Node(hidden_dim)\n",
        "\n",
        "    #feed forwards\n",
        "    self.linear1 = nn.Linear(hidden_dim, ff_dim)\n",
        "    self.linear2 = nn.Linear(ff_dim, hidden_dim)\n",
        "\n",
        "\n",
        "  #how its connected to the next transformer node\n",
        "  def forward(self, inputs, encoder_hidden=None):\n",
        "    #multihead attention (with mask option) ?\n",
        "    if(self.decoder): # if decoder, only look at values before\n",
        "      attention_out = self.attention.forward(inputs, inputs, masked=True)\n",
        "    else:\n",
        "      attention_out = self.attention.forward(inputs, inputs)\n",
        "\n",
        "    #add and norm\n",
        "    x = add_norm(inputs, attention_out)\n",
        "\n",
        "    #encoder decoder attention\n",
        "    if(self.decoder):\n",
        "      x_prev = x\n",
        "      self.decoder_encoder_att.forward(encoder_hidden, x)\n",
        "      x = add_norm(x_prev, x)\n",
        "\n",
        "    x_prev = x\n",
        "    #feed forward\n",
        "    x = self.linear1(x)\n",
        "    x = self.linear2(x)\n",
        "\n",
        "    #activation function\n",
        "    x = nn.relu(x)\n",
        "\n",
        "    #add and norm\n",
        "    x = add_norm(x_prev, x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "dZYVWsZ8haMS"
      },
      "outputs": [],
      "source": [
        "# class Transformer_Encoder(nn.Module):\n",
        "#   def __init__(self, hidden_dim, n_layers, vocab_size):\n",
        "#     super(Transformer_Encoder, self).__init__()\n",
        "\n",
        "#     #embedding\n",
        "#     self.embedding_node = Embedding_Node(vocab_size, hidden_dim)\n",
        "\n",
        "#     #layers\n",
        "#     self.layers = nn.ModuleList([Transformer_Node(hidden_dim) for i in range(0,n_layers)])\n",
        "\n",
        "#   def forward(self, inputs):\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "67QpPRLRXRlE"
      },
      "outputs": [],
      "source": [
        "# class Transformer_Node(nn.Module):\n",
        "#   def __init__(self, hidden_dim):\n",
        "#     super(Transformer_Node, self).__init__()\n",
        "\n",
        "#   def forward_encoder(self, inputs):\n",
        "#     pass\n",
        "\n",
        "#   def forward_decoder(self, inputs):\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "ZubrtWaX4r7z"
      },
      "outputs": [],
      "source": [
        "#for this, we basically said that what should be in the __init__ function should be any parameters that could be learned\n",
        "\n",
        "#ok, so for node elements, we'll say that in the __init__ funciton we should have the parameters whos weight should be learned\n",
        "#but for nn layers, well have things that define the layers/ hyperparameters\n",
        "\n",
        "#__init__ layer = anything that needs to be consistently referenced in forward pass (especially parameters that need to be updated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "_LbTrPpDu0UD"
      },
      "outputs": [],
      "source": [
        "  # #define initial hidden states at run time - b/c of batch size\n",
        "  # def init_hidden(self, batch_size):\n",
        "  #   init_hidden_list = [torch.zeros(batch_size, self.hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   init_cell_list = None\n",
        "  #   if(self.node_type==\"lstm\"):\n",
        "  #     init_cell_list = [torch.zeros(batch_size, self.hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   return init_hidden_list, init_cell_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "0a0efF-QRWMP"
      },
      "outputs": [],
      "source": [
        "#define initial hidden states at run time - b/c of batch size\n",
        "def init_hidden(self, batch_size):\n",
        "  #get device\n",
        "  device = next(self.parameters()).device\n",
        "\n",
        "  #itialize tens based on node type\n",
        "  init_hidden_tensor = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "  init_cell_tensor = None\n",
        "  if(self.node_type==\"lstm\"):\n",
        "    init_cell_tensor = torch.zeros(self.n_laryers, batch_size, self.hidden_dim).to(device)\n",
        "  return init_hidden_tensor, init_cell_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "li0D68hrlhen"
      },
      "outputs": [],
      "source": [
        "# input.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "KUrdwxzVmO4E"
      },
      "outputs": [],
      "source": [
        "class EncoderNN(nn.Module):\n",
        "  def __init__(self, node_type, n_layers, hidden_dim, embed_dim, vocab_size):\n",
        "    super(EncoderNN, self).__init__()\n",
        "    # self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    #model parameters\n",
        "    self.n_layers = n_layers\n",
        "    self.node_type = node_type\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    #define embedding node\n",
        "    self.embedding_node = Embedding_Node(vocab_size, embed_dim)\n",
        "\n",
        "\n",
        "    #create layer of nodes based on type\n",
        "    node_class = RNN_Node if node_type == \"rnn\" else LSTM_Node\n",
        "    self.nodes = nn.ModuleList(\n",
        "          [node_class(hidden_dim, embed_dim)] +\n",
        "          [node_class(hidden_dim, hidden_dim) for _ in range(n_layers - 1)])\n",
        "\n",
        "  # #define initial hidden states at run time - b/c of batch size\n",
        "  # def init_hidden(self, batch_size):\n",
        "  #   init_hidden_node = [torch.zeros(batch_size, self.hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   init_cell_node = None\n",
        "  #   if(self.node_type==\"lstm\"):\n",
        "  #     init_cell_node = [torch.zeros(batch_size, self.hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   return init_hidden_node, init_cell_node\n",
        "\n",
        "\n",
        "  #forward pass\n",
        "  def forward(self, inputs):\n",
        "\n",
        "    #get blank nodes\n",
        "    node_list = self.nodes\n",
        "\n",
        "    #get shape params\n",
        "    batch_size = inputs.shape[0]\n",
        "    seq_size = inputs.shape[1]\n",
        "\n",
        "    #get initial states\n",
        "    # hidden_list, cell_list = self.init_hidden(inputs.shape[0])\n",
        "    hidden_tensor, cell_tensor = init_hidden(self, batch_size)\n",
        "    last_layer_hidden = torch.zeros(batch_size, seq_size, self.hidden_dim)\n",
        "\n",
        "    #turn input into embedding\n",
        "    embed_input = self.embedding_node.forward(inputs)\n",
        "\n",
        "    # print('this is the embedding inputs:')\n",
        "    # display(embed_input)\n",
        "\n",
        "    #store final layer hidden nodes (for attention)\n",
        "    # final_hidden_layer = []\n",
        "    # final_hidden_tensor = torch.zeros(batch_size, )\n",
        "\n",
        "    #iterate over each word in sentence\n",
        "    for word_i in range(0, seq_size):\n",
        "\n",
        "      input = embed_input[:,word_i] #input = (batch_size, hidden_dim) ##1 for each word\n",
        "\n",
        "      for layer in range(0,self.n_layers):\n",
        "        #if not first layer, then input is previous hidden state\n",
        "        if layer!=0:\n",
        "          input = hidden_tensor[layer-1]\n",
        "\n",
        "        #TRY TO SEE IF CAN MAKE NEATER\n",
        "        #forward pass -- TRY TO FIX LATER - AFTER TRANSFORMER\n",
        "        if(self.node_type==\"rnn\"):\n",
        "          hidden_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer]) # (batch, hidden dim)\n",
        "        elif(self.node_type=='lstm'):\n",
        "          hidden_tensor[layer], cell_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer], cell_tensor[layer]) # both of size (batch, hidden dim)\n",
        "\n",
        "      #store final hidden layer for each word - for attention\n",
        "      last_layer_hidden[:, word_i, :self.hidden_dim] = hidden_tensor[-1]\n",
        "\n",
        "    #format outputs\n",
        "    outputs = (hidden_tensor[-1], None) if self.node_type==\"rnn\" else (hidden_tensor[-1], cell_tensor[-1]) if self.node_type=='lstm' else None\n",
        "\n",
        "    return outputs, last_layer_hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "nxcIFsTwXpvV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "gKiXWgCvfAuD"
      },
      "outputs": [],
      "source": [
        "class DecoderNN(nn.Module):\n",
        "  def __init__(self, node_type, n_layers, hidden_dim, embed_dim, vocab_size, attention=False):\n",
        "    super(DecoderNN, self).__init__()\n",
        "\n",
        "    #model parameters\n",
        "    self.n_layers = n_layers\n",
        "    self.node_type = node_type\n",
        "    # self.max_length = max_length\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.vocab_size = vocab_size\n",
        "\n",
        "    #define embedding node\n",
        "    self.embedding_node = Embedding_Node(vocab_size, embed_dim)\n",
        "\n",
        "    #create layer of nodes based on type\n",
        "    node_class = RNN_Node if node_type == \"rnn\" else LSTM_Node\n",
        "    self.nodes = nn.ModuleList(\n",
        "          [node_class(hidden_dim, embed_dim)] +\n",
        "          [node_class(hidden_dim, hidden_dim) for _ in range(n_layers - 1)])\n",
        "\n",
        "\n",
        "    # # #store initial hidden states\n",
        "    # # #self.hidden = torch.randn(n_layers, hidden_dim)\n",
        "    # # self.cell = torch.randn(n_layers, hidden_dim) #only really applicable for lstm\n",
        "    # self.prev_hidden = torch.randn(n_layers, hidden_dim)\n",
        "    # self.prev_cell = torch.randn(n_layers, hidden_dim) #only really applicable for lstm\n",
        "\n",
        "\n",
        "    #output weights\n",
        "    self.W_out = nn.Parameter(torch.randn(vocab_size, hidden_dim))\n",
        "\n",
        "    #attention\n",
        "    self.attention = attention\n",
        "    if(attention):\n",
        "      self.attention_node = Attention_Node(hidden_dim)\n",
        "\n",
        "\n",
        "  # #define initial hidden states at run time - b/c of batch size\n",
        "  # def init_hidden(self, batch_size):\n",
        "  #   init_hidden_list = [torch.zeros(batch_size, hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   init_cell_list = None\n",
        "  #   if(self.node_type==\"lstm\"):\n",
        "  #     init_cell_list = [torch.zeros(batch_size, hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   return init_hidden_list, init_cell_list\n",
        "\n",
        "  #forward pass - considered as going over one word (versus encoder going over entire sentence) - training\n",
        "  def forward(self, input, hidden_tensor, cell_tensor=None, encoder_flayer=None):\n",
        "    #initial nodes\n",
        "    node_list = self.nodes\n",
        "\n",
        "    print('\\nthis is the initial input of the decoder forward')\n",
        "    display(input)\n",
        "    print(\"this is the type: {}\".format(type(input)))\n",
        "    print('this is the shape: {}\\n\\n\\n'.format(input.shape))\n",
        "\n",
        "    #get embedding of input\n",
        "    input = self.embedding_node.forward(input)[:,0] #only take one word\n",
        "\n",
        "    #forward pass for all layers (remember - not entire sentence, just 1 word)\n",
        "    for layer in range(0,self.n_layers):\n",
        "      #if not first layer, then input is previous hidden state\n",
        "      if layer!=0:\n",
        "        input = hidden_tensor[layer-1]\n",
        "\n",
        "      #forward pass\n",
        "      if(self.node_type==\"rnn\"):\n",
        "        hidden_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer]) # (batch, hidden dim)\n",
        "      elif(self.node_type=='lstm'):\n",
        "        hidden_tensor[layer], cell_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer], cell_tensor[layer]) # both of size (batch, hidden dim)\n",
        "\n",
        "\n",
        "    #COME BACK TO ATTENTION\n",
        "    #attention\n",
        "    # if(self.attention):\n",
        "    #   attention_out = self.attention_node.forward(encoder_flayer, hidden_list[-1])\n",
        "    #   hidden_list[-1] = torch.cat((hidden_list[-1], attention_out), dim=0)\n",
        "\n",
        "    #generate final output\n",
        "    pred_output = torch.matmul(self.W_out, hidden_tensor[-1].T).T #during training - cross entropy fun converts this to prob\n",
        "\n",
        "    return hidden_tensor, cell_tensor, pred_output\n",
        "\n",
        "  #to generate predictions - generate one word at a time\n",
        "  #greedy decoding - uses/ predicts most probable word\n",
        "  def pred(self, prev_input, hidden_tensor, cell_tensor=None, encoder_flayer=None):\n",
        "    #generate predicted word & others\n",
        "    hidden_tensor, cell_tensor, pred_logit = self.forward(prev_input, hidden_tensor, cell_tensor, encoder_flayer)\n",
        "\n",
        "    print('this is the predicted logits')\n",
        "    display(pred_logit)\n",
        "    print('pred logit shape: {}'.format(pred_logit.shape))\n",
        "\n",
        "    #convert logits to prob\n",
        "    pred_prob = F.softmax(pred_logit, dim=1) #should be correct\n",
        "\n",
        "    print('this is the preicted probabilities ')\n",
        "    display(pred_prob)\n",
        "    print('pred prob shape: {}'.format(pred_prob.shape))\n",
        "\n",
        "    #get most prob word\n",
        "    _, pred_word_indx = torch.max(pred_prob, dim=1)\n",
        "\n",
        "    print('this is the predicted words:')\n",
        "    display(pred_word_indx)\n",
        "    print('pred_words shape: {}'.format(pred_word_indx.shape))\n",
        "\n",
        "    return hidden_tensor, cell_tensor, pred_word_indx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "pFcsmyCYZEEy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "RQS3dWtMfNjg"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder_args, decoder_args, max_length=30, sos_token=1, eos_token=2):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "\n",
        "    #model structure\n",
        "    self.encoder = EncoderNN(*encoder_args)\n",
        "    self.decoder = DecoderNN(*decoder_args)\n",
        "\n",
        "    # #set other model params to be ref later\n",
        "    # self.encoder.node_type = encoder_args[0]\n",
        "    # self.decoder.node_type = decoder_args[0]\n",
        "\n",
        "    #set other model params to be ref later\n",
        "    self.max_length = max_length\n",
        "    self.sos_token = sos_token\n",
        "    self.eos_token = eos_token\n",
        "\n",
        "\n",
        "    # Linear layer to project encoder hidden dim to decoder hidden dim\n",
        "    enc_hid = encoder_args[2]\n",
        "    dec_hid = decoder_args[2]\n",
        "    self.hidden_transform = nn.Linear(enc_hid, dec_hid)\n",
        "    self.cell_transform = nn.Linear(enc_hid, dec_hid)\n",
        "\n",
        "  #run encoder and initialize decoder with hidden states\n",
        "  def run_enc_init_dec(self, inputs):\n",
        "    #put on correct device\n",
        "    device = next(self.parameters()).device\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    #encoder\n",
        "    node_class = RNN_Node if self.encoder.node_type == \"rnn\" else LSTM_Node\n",
        "    (enc_hidden_node, enc_cell_node), enc_final_hidden_layer = self.encoder.forward(inputs)\n",
        "\n",
        "    #initialize hidden and cell tensor\n",
        "    dec_hidden_tensor, dec_cell_tensor = init_hidden(self.decoder, inputs.shape[0])\n",
        "\n",
        "    #linear transform encoder return values - in case hidden sizes don't match\n",
        "    dec_hidden_tensor[0] = self.hidden_transform(enc_hidden_node)\n",
        "    if (dec_cell_tensor!=None) and (enc_cell_node!=None):\n",
        "      dec_cell_tensor[0] = self.cell_transform(enc_cell_node)\n",
        "\n",
        "    return dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer\n",
        "\n",
        "\n",
        "  #for the full system\n",
        "  def forward(self, inputs, outputs):\n",
        "    #put on correct device\n",
        "    device = next(self.parameters()).device\n",
        "#    inputs = inputs.to(device)\n",
        "    outputs = outputs.to(device)\n",
        "\n",
        "    # #encoder\n",
        "    # node_class = RNN_Node if self.encoder.node_type == \"rnn\" else LSTM_Node\n",
        "    # (enc_hidden_node, enc_cell_node), enc_final_hidden_layer = self.encoder.forward(inputs)\n",
        "\n",
        "    # #initialize hidden and cell tensor\n",
        "    # dec_hidden_tensor, dec_cell_tensor = init_hidden(self.decoder, inputs.shape[0])\n",
        "\n",
        "    # #linear transform encoder return values - in case hidden sizes don't match\n",
        "    # dec_hidden_tensor[0] = self.hidden_transform(enc_hidden_node)\n",
        "    # if (dec_cell_tensor!=None) and (enc_cell_node!=None):\n",
        "    #   dec_cell_tensor[0] = self.cell_transform(enc_cell_node)\n",
        "\n",
        "    #run encoder and initialize decoder with hidden states\n",
        "    dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer = self.run_enc_init_dec(inputs)\n",
        "\n",
        "    #decoder\n",
        "    pred_out_tensor = torch.zeros(outputs.size(0), len(outputs[0]), self.decoder.vocab_size, device=device) #before was device = outputs.device\n",
        "\n",
        "    print('this is the predicted out tensor size: {}'.format(pred_out_tensor.shape))\n",
        "\n",
        "    for word_pos in range(0,len(outputs[0])):\n",
        "      #get particular word position for entire batch and reshape to have 2d array\n",
        "      word_batch = outputs[:,word_pos].unsqueeze(1)\n",
        "\n",
        "      #decoder forward pass\n",
        "      dec_hidden_tensor, dec_cell_tensor, pred_out = self.decoder.forward(word_batch, dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer)\n",
        "\n",
        "      print('decoder output type: {}'.format(type(pred_out)))\n",
        "      display(pred_out)\n",
        "      print('decoder output shape: {}'.format(pred_out.shape))\n",
        "\n",
        "      #add value to prediction tensor\n",
        "      pred_out_tensor[:, word_pos, :] = pred_out\n",
        "\n",
        "\n",
        "    return pred_out_tensor #must make sure has shape (batch size, seq length, vocab size)\n",
        "\n",
        "\n",
        "  def pred(self, inputs):\n",
        "\n",
        "    #run encoder and initialize decoder with hidden states\n",
        "    dec_hidden_tensor, dec_cell_tensor, enc_flayer = self.run_enc_init_dec(inputs)\n",
        "\n",
        "    #init single value prediction\n",
        "    size = (inputs.size(0), 1) #1 for each in batch\n",
        "    prev_out_sing_tens = torch.full(size, self.sos_token)\n",
        "\n",
        "    #init full prediction\n",
        "    pred_out_all_tens = torch.zeros(inputs.size(0), self.max_length)\n",
        "\n",
        "    print('\\n\\n\\nThis is seq2seq predicted tensor size: {}'.format(pred_out_all_tens.shape))\n",
        "\n",
        "    #mask for which seq endend\n",
        "    cont_tens = torch.ones(inputs.size(0), dtype=torch.bool)\n",
        "\n",
        "    #to check we don't exceed max length & index properly\n",
        "    it = 0\n",
        "\n",
        "    #continue while there are any sentences that are not finished\n",
        "    #and we haven't reached a max length\n",
        "    while mask_tens.any() and (it < self.max_length):\n",
        "\n",
        "      #get unmasked values\n",
        "      prev_out_sing_unmask = prev_out_sing_tens[mask_tens]\n",
        "      hidden_unmask = dec_hidden_tensor[mask_tens]\n",
        "      cell_unmask = dec_cell_tensor[mask_tens]\n",
        "\n",
        "      #pass to decoder\n",
        "      hidden_unmask, cell_unmask, pred_word_indx = self.decoder.pred(self, prev_out_sing_unmask, hidden_unmask, cell_unmask, enc_flayer)\n",
        "\n",
        "      #change mask\n",
        "      mask_tens = mask_tens & (pred_word_indx != self.eos_token)\n",
        "\n",
        "      #add predicted words to running full prediction - if not <eos> and cont_tens=True\n",
        "      indices_to_update = mask_tens.squeeze()\n",
        "      pred_out_all_tens[indices_to_update, it] = pred_word_indx[indices_to_update].squeeze()\n",
        "\n",
        "      #replace values where relevant\n",
        "      prev_out_sing_tens[mask_tens] = pred_word_indx\n",
        "      dec_hidden_tensor[mask_tens] = hidden_unmask\n",
        "      dec_cell_tensor[mask_tens] = cell_unmask\n",
        "\n",
        "      #update iterator\n",
        "      it += 1\n",
        "\n",
        "\n",
        "    return pred_out_all_tens\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict[\"English Vocabulary\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGhUmJQmJ2Px",
        "outputId": "296ee4f5-6a97-444a-89c8-86d6f0958b41"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'are': 3,\n",
              " 'going': 4,\n",
              " 'hello': 5,\n",
              " 'how': 6,\n",
              " 'we': 7,\n",
              " 'where': 8,\n",
              " 'world': 9,\n",
              " 'you': 10,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3G9it0h3vuL",
        "outputId": "4ef4304c-b5cb-4d29-d734-216ad46a559b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "#have to seperate by word\n",
        "output[:,0].reshape(len(output),1)\n",
        "# len(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0eLejyzHk-V7",
        "outputId": "1c1d7a6f-8209-42e2-d466-69c66b9dcba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocab size: 11\n",
            "Italian vocab size: 10\n",
            "this is the predicted out tensor size: torch.Size([3, 5, 10])\n",
            "\n",
            "this is the initial input of the decoder forward\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is the type: <class 'torch.Tensor'>\n",
            "this is the shape: torch.Size([3, 1])\n",
            "\n",
            "\n",
            "\n",
            "decoder output type: <class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[-0.0381,  0.2181, -0.5328, -2.4058, -0.2609, -1.5302, -0.1608, -0.1088,\n",
              "          1.0435, -0.9356],\n",
              "        [-0.0428,  0.2205, -0.5315, -2.4121, -0.2639, -1.5382, -0.1596, -0.1129,\n",
              "          1.0441, -0.9384],\n",
              "        [-0.0427,  0.2200, -0.5314, -2.4107, -0.2636, -1.5380, -0.1601, -0.1127,\n",
              "          1.0440, -0.9383]], grad_fn=<PermuteBackward0>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder output shape: torch.Size([3, 10])\n",
            "\n",
            "this is the initial input of the decoder forward\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[6],\n",
              "        [4],\n",
              "        [5]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is the type: <class 'torch.Tensor'>\n",
            "this is the shape: torch.Size([3, 1])\n",
            "\n",
            "\n",
            "\n",
            "decoder output type: <class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[-0.3995, -1.0571, -1.4084, -1.4986, -1.1522, -2.3609, -0.1721,  0.3703,\n",
              "          1.2977, -2.8812],\n",
              "        [-0.5926, -1.0749, -1.2376, -0.8393, -1.3304, -2.2429, -0.0632,  0.6582,\n",
              "          1.5270, -3.5346],\n",
              "        [-0.5462, -1.0594, -1.3070, -0.9881, -1.3581, -2.1886,  0.0632,  0.5263,\n",
              "          1.4178, -3.4444]], grad_fn=<PermuteBackward0>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder output shape: torch.Size([3, 10])\n",
            "\n",
            "this is the initial input of the decoder forward\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[9],\n",
              "        [7],\n",
              "        [8]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is the type: <class 'torch.Tensor'>\n",
            "this is the shape: torch.Size([3, 1])\n",
            "\n",
            "\n",
            "\n",
            "decoder output type: <class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[-0.1232, -0.7098, -1.1256, -1.6068, -0.7058, -2.4386, -0.3348,  0.1156,\n",
              "          1.9247, -2.9962],\n",
              "        [ 0.3294, -0.4000, -0.8865, -2.1563,  0.0954, -2.6435, -1.1198,  0.1930,\n",
              "          2.5691, -2.3931],\n",
              "        [ 0.3439, -0.1770, -0.5958, -1.8530,  0.2289, -2.6170, -1.1789,  0.3466,\n",
              "          3.1392, -2.9147]], grad_fn=<PermuteBackward0>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder output shape: torch.Size([3, 10])\n",
            "\n",
            "this is the initial input of the decoder forward\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[3],\n",
              "        [2],\n",
              "        [2]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is the type: <class 'torch.Tensor'>\n",
            "this is the shape: torch.Size([3, 1])\n",
            "\n",
            "\n",
            "\n",
            "decoder output type: <class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 0.0659, -0.5383, -0.9010, -1.7731, -0.2289, -2.5508, -0.9917,  0.5392,\n",
              "          2.4500, -2.7485],\n",
              "        [-0.4310, -0.9511, -1.1549, -1.0945, -1.0278, -2.3444, -0.2543,  0.3805,\n",
              "          1.5450, -3.0835],\n",
              "        [-0.4507, -0.9931, -1.2257, -1.1155, -1.1206, -2.3009, -0.1582,  0.3915,\n",
              "          1.4609, -3.1218]], grad_fn=<PermuteBackward0>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder output shape: torch.Size([3, 10])\n",
            "\n",
            "this is the initial input of the decoder forward\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [0],\n",
              "        [0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is the type: <class 'torch.Tensor'>\n",
            "this is the shape: torch.Size([3, 1])\n",
            "\n",
            "\n",
            "\n",
            "decoder output type: <class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[-0.3531, -0.9294, -1.1598, -1.1807, -0.9356, -2.3693, -0.2760,  0.2318,\n",
              "          1.5357, -2.9510],\n",
              "        [ 0.3243, -0.1650, -0.7066, -2.1139,  0.1177, -2.5947, -0.8943, -0.0687,\n",
              "          2.7245, -2.5976],\n",
              "        [ 0.3334, -0.1848, -0.7087, -2.0744,  0.1281, -2.6016, -0.9362, -0.0037,\n",
              "          2.7861, -2.6577]], grad_fn=<PermuteBackward0>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder output shape: torch.Size([3, 10])\n",
            "this is seq2seq forward output\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[[-0.0381,  0.2181, -0.5328, -2.4058, -0.2609, -1.5302, -0.1608,\n",
              "          -0.1088,  1.0435, -0.9356],\n",
              "         [-0.3995, -1.0571, -1.4084, -1.4986, -1.1522, -2.3609, -0.1721,\n",
              "           0.3703,  1.2977, -2.8812],\n",
              "         [-0.1232, -0.7098, -1.1256, -1.6068, -0.7058, -2.4386, -0.3348,\n",
              "           0.1156,  1.9247, -2.9962],\n",
              "         [ 0.0659, -0.5383, -0.9010, -1.7731, -0.2289, -2.5508, -0.9917,\n",
              "           0.5392,  2.4500, -2.7485],\n",
              "         [-0.3531, -0.9294, -1.1598, -1.1807, -0.9356, -2.3693, -0.2760,\n",
              "           0.2318,  1.5357, -2.9510]],\n",
              "\n",
              "        [[-0.0428,  0.2205, -0.5315, -2.4121, -0.2639, -1.5382, -0.1596,\n",
              "          -0.1129,  1.0441, -0.9384],\n",
              "         [-0.5926, -1.0749, -1.2376, -0.8393, -1.3304, -2.2429, -0.0632,\n",
              "           0.6582,  1.5270, -3.5346],\n",
              "         [ 0.3294, -0.4000, -0.8865, -2.1563,  0.0954, -2.6435, -1.1198,\n",
              "           0.1930,  2.5691, -2.3931],\n",
              "         [-0.4310, -0.9511, -1.1549, -1.0945, -1.0278, -2.3444, -0.2543,\n",
              "           0.3805,  1.5450, -3.0835],\n",
              "         [ 0.3243, -0.1650, -0.7066, -2.1139,  0.1177, -2.5947, -0.8943,\n",
              "          -0.0687,  2.7245, -2.5976]],\n",
              "\n",
              "        [[-0.0427,  0.2200, -0.5314, -2.4107, -0.2636, -1.5380, -0.1601,\n",
              "          -0.1127,  1.0440, -0.9383],\n",
              "         [-0.5462, -1.0594, -1.3070, -0.9881, -1.3581, -2.1886,  0.0632,\n",
              "           0.5263,  1.4178, -3.4444],\n",
              "         [ 0.3439, -0.1770, -0.5958, -1.8530,  0.2289, -2.6170, -1.1789,\n",
              "           0.3466,  3.1392, -2.9147],\n",
              "         [-0.4507, -0.9931, -1.2257, -1.1155, -1.1206, -2.3009, -0.1582,\n",
              "           0.3915,  1.4609, -3.1218],\n",
              "         [ 0.3334, -0.1848, -0.7087, -2.0744,  0.1281, -2.6016, -0.9362,\n",
              "          -0.0037,  2.7861, -2.6577]]], grad_fn=<CopySlices>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output shape: torch.Size([3, 5, 10])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#encoder param\n",
        "enc_node_type = \"rnn\"\n",
        "enc_n_layers = 2\n",
        "enc_hidden_dim = 4\n",
        "enc_embed_dim = 7\n",
        "eng_vocab_size = len(data_dict[\"English Vocabulary\"])\n",
        "\n",
        "#decoder_param\n",
        "dec_node_type = \"rnn\"\n",
        "dec_n_layers = 2\n",
        "dec_hidden_dim = 6\n",
        "dec_embed_dim = 8\n",
        "it_vocab_size = len(data_dict[\"Italian Vocabulary\"])\n",
        "\n",
        "#seq2seq param\n",
        "# max_length = 30\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# (self, node_type, n_layers, hidden_dim, embed_dim, vocab_size)\n",
        "# (self, node_type, n_layers, hidden_dim, embed_dim, vocab_size, attention=False, max_length=30)\n",
        "\n",
        "print('English vocab size: {}'.format(eng_vocab_size))\n",
        "print('Italian vocab size: {}'.format(it_vocab_size))\n",
        "\n",
        "#create seq2seq instance\n",
        "encoder_args = (enc_node_type, enc_n_layers, enc_hidden_dim, enc_embed_dim, eng_vocab_size)\n",
        "decoder_args = (dec_node_type, dec_n_layers, dec_hidden_dim, dec_embed_dim, it_vocab_size)\n",
        "seq2seq = Seq2Seq(encoder_args, decoder_args).to(device)\n",
        "\n",
        "\n",
        "temp = seq2seq.forward(input, output)\n",
        "print('this is seq2seq forward output')\n",
        "display(temp)\n",
        "print(\"output shape: {}\".format(temp.shape))\n",
        "# print(\"output type: {}\".format(type(temp)))\n",
        "# #forward step\n",
        "\n",
        "# #encoder instance\n",
        "# encoder = EncoderNN(*encoder_args)\n",
        "# enc_out, final_hidden_layer = encoder.forward(input)\n",
        "# enc_hidden_node = enc_out[0]\n",
        "\n",
        "# print('\\n\\n\\nafter encoder test step')\n",
        "\n",
        "\n",
        "\n",
        "# #decoder instance\n",
        "# decoder = DecoderNN(*decoder_args)\n",
        "# #initialize hidden and cell list\n",
        "# dec_hidden_list, dec_cell_list = init_hidden(decoder, output.shape[0])\n",
        "# dec_hidden_list[0] = enc_hidden_node\n",
        "\n",
        "# pred_out = decoder.forward(output[:,0].reshape(len(output), 1), dec_hidden_list, None, final_hidden_layer)\n",
        "# print('\\nafter decoder test step')\n",
        "\n",
        "# #create encoder instance\n",
        "# encoder = EncoderNN(node_type, n_layers, hidden_dim, embed_dim, eng_vocab_size)\n",
        "\n",
        "# #forward step\n",
        "# hidden_list, final_hidden_layer = encoder.forward(input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('true output')\n",
        "display(output)\n",
        "print(\"true output shape: {}\".format(output.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "68w2HKH1lNK5",
        "outputId": "7dcb0975-10f4-4450-8b0b-390ed16211fc"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true output\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1, 6, 9, 3, 2],\n",
              "        [1, 4, 7, 2, 0],\n",
              "        [1, 5, 8, 2, 0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true output shape: torch.Size([3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAVdhuINsyD3"
      },
      "source": [
        "Notes:\n",
        "\n",
        "- before running - write in comments how each dimension is looking like after each computation - helpful for debugging\n",
        "\n",
        "- incorporate batches!\n",
        "\n",
        "- transformers\n",
        "\n",
        "- beam search\n",
        "\n",
        "- bidirectional\n",
        "\n",
        "- different attention methods\n",
        "\n",
        "-- evaluate with Bleu scores\n",
        "\n",
        "\n",
        "SHOULD ADD\n",
        "- dependency parsing, pretraining, and fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X8KzhGEsRrD"
      },
      "source": [
        "Run time notes:\n",
        "\n",
        "- embedding size: Common values for the embedding dimension in NLP tasks range from 50 to 300, but larger values like 512 or 1024 can be used for more complex tasks or larger datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsAm8IVIdpr0"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/3Uay8GN1LdmTe2+R1eg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}