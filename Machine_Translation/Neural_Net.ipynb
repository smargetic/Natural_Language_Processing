{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smargetic/Natural_Language_Processing/blob/main/Machine_Translation/Neural_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-eYx0G4p02W",
        "outputId": "4782273f-6638-4ace-bfea-832aa29fe298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (7.16.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (3.1.5)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (3.1.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (5.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert) (24.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (2.18.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (5.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert) (1.4.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert) (4.3.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from mistune<4,>=2.0.3->nbconvert) (4.12.2)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.5.0->nbconvert) (6.1.12)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7->nbconvert) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7->nbconvert) (4.23.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert) (2.6)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.22.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.8.2)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.3.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nbconvert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E38McwRXbyKA",
        "outputId": "833aeb76-995d-4252-c58d-e62f195c0695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#data storage - not sure if important\n",
        "import pandas as pd\n",
        "import numpy as np #can take away later\n",
        "\n",
        "#make sure to show all values in pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "#pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#visualize\n",
        "from IPython.display import display\n",
        "\n",
        "#help import other functions\n",
        "import os\n",
        "\n",
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Disable scientific notation\n",
        "torch.set_printoptions(sci_mode=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FJRgbpQDJyVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814afcea-e396-4e4d-d941-3ba182cc7436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Files currently present:\n",
            "['sentences_base.csv', 'ita_sentences_CC0.tsv', 'eng_sentences_detailed.tsv', 'eng_sentences.tsv', 'ita_sentences_detailed.tsv', 'eng_sentences_CC0.tsv', 'ita_sentences.tsv', 'Sentence pairs in English-Italian - 2024-07-26.tsv', 'Helper_Functions.ipynb', 'Model_Train_Predict.ipynb', '__pycache__', 'Data_Intake_and_Preprocessing.ipynb', 'intake_preprocess_utils.ipynb', 'intake_preprocess_utils.py', 'Neural_Net.ipynb']\n",
            "[NbConvertApp] Converting notebook intake_preprocess_utils.ipynb to script\n",
            "[NbConvertApp] Writing 11518 bytes to intake_preprocess_utils.txt\n",
            "\n",
            "\n",
            "New files in current directory:\n",
            "['sentences_base.csv', 'ita_sentences_CC0.tsv', 'eng_sentences_detailed.tsv', 'eng_sentences.tsv', 'ita_sentences_detailed.tsv', 'eng_sentences_CC0.tsv', 'ita_sentences.tsv', 'Sentence pairs in English-Italian - 2024-07-26.tsv', 'Helper_Functions.ipynb', 'Model_Train_Predict.ipynb', '__pycache__', 'Data_Intake_and_Preprocessing.ipynb', 'intake_preprocess_utils.ipynb', 'intake_preprocess_utils.py', 'Neural_Net.ipynb']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##to obtain functions from another .ipynb file\n",
        "\n",
        "#go to current directory\n",
        "os.chdir('/content/drive/My Drive/Coding Projects/Machine Translation')\n",
        "\n",
        "#List the files in the current directory\n",
        "print('\\nFiles currently present:')\n",
        "print(os.listdir())\n",
        "\n",
        "#Convert the notebook to a Python script\n",
        "!jupyter nbconvert --to script intake_preprocess_utils.ipynb\n",
        "os.rename('intake_preprocess_utils.txt', 'intake_preprocess_utils.py')\n",
        "\n",
        "print('\\n\\nNew files in current directory:')\n",
        "print(os.listdir())\n",
        "print('\\n\\n')\n",
        "\n",
        "#import functions\n",
        "from intake_preprocess_utils import get_file_and_disp, get_sample, dump_sample, data_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HOifKYsyxoIs"
      },
      "outputs": [],
      "source": [
        "# #english to italian translation - just to test\n",
        "# df_eng_it = get_file_and_disp(fileName=\"Sentence pairs in English-Italian - 2024-07-26.tsv.zip\" ,sep='\\t', stringName=\"English to Italian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mRoEVDsAWxDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "6d77869a-bf81-46e9-f164-36b1e10a1b8b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   0                   1  2                    3\n",
              "0  1         hello world  1           ciao mondo\n",
              "1  2         how are you  2            come stai\n",
              "2  3  where are we going  3  dove stiamo andando"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1376f89-bbf9-45a0-a713-533653680509\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>hello world</td>\n",
              "      <td>1</td>\n",
              "      <td>ciao mondo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how are you</td>\n",
              "      <td>2</td>\n",
              "      <td>come stai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>where are we going</td>\n",
              "      <td>3</td>\n",
              "      <td>dove stiamo andando</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1376f89-bbf9-45a0-a713-533653680509')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f1376f89-bbf9-45a0-a713-533653680509 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f1376f89-bbf9-45a0-a713-533653680509');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb924672-593d-4e57-8fc5-067be1bb8c79\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb924672-593d-4e57-8fc5-067be1bb8c79')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb924672-593d-4e57-8fc5-067be1bb8c79 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a7d9b179-18b2-41d3-98c3-569b4eb1cea1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a7d9b179-18b2-41d3-98c3-569b4eb1cea1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hello world\",\n          \"how are you\",\n          \"where are we going\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ciao mondo\",\n          \"come stai\",\n          \"dove stiamo andando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#test data set\n",
        "df = pd.DataFrame({\n",
        "                  0:[1,2,3],\n",
        "                  1:[\"hello world\", \"how are you\", \"where are we going\"],\n",
        "                  2:[1,2,3],\n",
        "                  3: [\"ciao mondo\", \"come stai\", \"dove stiamo andando\"]})\n",
        "\n",
        "display(df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QmDxJKD6dQ2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2951b902-42d7-418a-dbd4-821b7538c6ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nulls in English: 0\n",
            "Nulls in Italian: 0\n",
            "\n",
            "English/Italian Translations:\n",
            "\tEnglish vocabulary size: 11\n",
            "\tItalian vocabulary size: 10\n",
            "\n",
            "Done with Pytorch.\n",
            "\n",
            "English-Italian Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   eng_id        eng_sentence  it_id          it_sentence  \\\n",
              "0       1         hello world      1           ciao mondo   \n",
              "1       2         how are you      2            come stai   \n",
              "2       3  where are we going      3  dove stiamo andando   \n",
              "\n",
              "                              eng_tokens  \\\n",
              "0           [<sos>, hello, world, <eos>]   \n",
              "1          [<sos>, how, are, you, <eos>]   \n",
              "2  [<sos>, where, are, we, going, <eos>]   \n",
              "\n",
              "                               it_tokens      eng_tokens_enc    it_tokens_enc  \\\n",
              "0            [<sos>, ciao, mondo, <eos>]        [1, 5, 9, 2]     [1, 4, 7, 2]   \n",
              "1             [<sos>, come, stai, <eos>]    [1, 6, 3, 10, 2]     [1, 5, 8, 2]   \n",
              "2  [<sos>, dove, stiamo, andando, <eos>]  [1, 8, 3, 7, 4, 2]  [1, 6, 9, 3, 2]   \n",
              "\n",
              "                                                      eng_tokens_enc_p  \\\n",
              "0   [tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]   \n",
              "1  [tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]   \n",
              "2   [tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]   \n",
              "\n",
              "                                           it_tokens_enc_p  \n",
              "0  [tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]  \n",
              "1  [tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]  \n",
              "2  [tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93b4dc9f-a83a-46ae-980e-ff5079f000d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng_id</th>\n",
              "      <th>eng_sentence</th>\n",
              "      <th>it_id</th>\n",
              "      <th>it_sentence</th>\n",
              "      <th>eng_tokens</th>\n",
              "      <th>it_tokens</th>\n",
              "      <th>eng_tokens_enc</th>\n",
              "      <th>it_tokens_enc</th>\n",
              "      <th>eng_tokens_enc_p</th>\n",
              "      <th>it_tokens_enc_p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>hello world</td>\n",
              "      <td>1</td>\n",
              "      <td>ciao mondo</td>\n",
              "      <td>[&lt;sos&gt;, hello, world, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, ciao, mondo, &lt;eos&gt;]</td>\n",
              "      <td>[1, 5, 9, 2]</td>\n",
              "      <td>[1, 4, 7, 2]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(9), tensor(2), tensor(0), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(4), tensor(7), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how are you</td>\n",
              "      <td>2</td>\n",
              "      <td>come stai</td>\n",
              "      <td>[&lt;sos&gt;, how, are, you, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, come, stai, &lt;eos&gt;]</td>\n",
              "      <td>[1, 6, 3, 10, 2]</td>\n",
              "      <td>[1, 5, 8, 2]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(3), tensor(10), tensor(2), tensor(0)]</td>\n",
              "      <td>[tensor(1), tensor(5), tensor(8), tensor(2), tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>where are we going</td>\n",
              "      <td>3</td>\n",
              "      <td>dove stiamo andando</td>\n",
              "      <td>[&lt;sos&gt;, where, are, we, going, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, dove, stiamo, andando, &lt;eos&gt;]</td>\n",
              "      <td>[1, 8, 3, 7, 4, 2]</td>\n",
              "      <td>[1, 6, 9, 3, 2]</td>\n",
              "      <td>[tensor(1), tensor(8), tensor(3), tensor(7), tensor(4), tensor(2)]</td>\n",
              "      <td>[tensor(1), tensor(6), tensor(9), tensor(3), tensor(2)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93b4dc9f-a83a-46ae-980e-ff5079f000d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93b4dc9f-a83a-46ae-980e-ff5079f000d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93b4dc9f-a83a-46ae-980e-ff5079f000d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d0c747bd-55a5-4ce7-a4c6-b2c57ff8af96\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d0c747bd-55a5-4ce7-a4c6-b2c57ff8af96')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d0c747bd-55a5-4ce7-a4c6-b2c57ff8af96 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  display(data_dict[key])\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"eng_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hello world\",\n          \"how are you\",\n          \"where are we going\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ciao mondo\",\n          \"come stai\",\n          \"dove stiamo andando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 5, 9, 2, 0, 0])\",\n          \"tensor([ 1,  6,  3, 10,  2,  0])\",\n          \"tensor([1, 8, 3, 7, 4, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it_tokens_enc_p\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tensor([1, 4, 7, 2, 0])\",\n          \"tensor([1, 5, 8, 2, 0])\",\n          \"tensor([1, 6, 9, 3, 2])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian SING Dataframe:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7e3851106260>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian Pytorch SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English-Italian TensorFlow SING Dataloader:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'are': 3,\n",
              " 'going': 4,\n",
              " 'hello': 5,\n",
              " 'how': 6,\n",
              " 'we': 7,\n",
              " 'where': 8,\n",
              " 'world': 9,\n",
              " 'you': 10,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'andando': 3,\n",
              " 'ciao': 4,\n",
              " 'come': 5,\n",
              " 'dove': 6,\n",
              " 'mondo': 7,\n",
              " 'stai': 8,\n",
              " 'stiamo': 9,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Italian Vocabulary SING:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#go through preprocessing\n",
        "data_dict= data_preprocessing(df.copy(), pytorchB=True, tensorflowB=False, store=False, sample=False, download=False, sing=False)\n",
        "for key in data_dict.keys():\n",
        "  print('\\n'+key+':')\n",
        "  display(data_dict[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FuiybsIls7m1"
      },
      "outputs": [],
      "source": [
        "#forward input: (batch size (aka. # sentences), # words in sentence (including padding))\n",
        "#forward output: (batch size (aka. # sentences), # words in sentence (including padding), embedding dim)\n",
        "class Embedding_Node(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Embedding_Node, self).__init__()\n",
        "\n",
        "    self.W_e = nn.Parameter(torch.randn(vocab_size, embedding_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.W_e[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tjcCtOuDuH_t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "343b7d7a-5c4d-4110-82dc-b8a039a5c17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "batch:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 1,  6,  3, 10,  2,  0],\n",
              "        [ 1,  8,  3,  7,  4,  2],\n",
              "        [ 1,  5,  9,  2,  0,  0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1, 5, 8, 2, 0],\n",
              "        [1, 6, 9, 3, 2],\n",
              "        [1, 4, 7, 2, 0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "batch:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 1,  6,  3, 10,  2,  0],\n",
              "        [ 1,  8,  3,  7,  4,  2],\n",
              "        [ 1,  5,  9,  2,  0,  0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1, 5, 8, 2, 0],\n",
              "        [1, 6, 9, 3, 2],\n",
              "        [1, 4, 7, 2, 0]])"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "### Seperates data into batches --> NEED TO GO OVER\n",
        "\n",
        "for input_batch, target_batch in data_dict['English-Italian Pytorch Dataloader']:\n",
        "  print('\\nbatch:')\n",
        "  display(input_batch)\n",
        "  display(target_batch)\n",
        "\n",
        "print('\\n\\nbatch:')\n",
        "display(input_batch)\n",
        "display(target_batch)\n",
        "\n",
        "#get input and output\n",
        "input, output = input_batch, target_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ctGekK2XXec4"
      },
      "outputs": [],
      "source": [
        "class Attention_Node(nn.Module):\n",
        "  def __init__(self,hidden_dim):\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    #key, query, value\n",
        "    self.W_key = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.W_query = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.W_value = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "  def forward(self, key_hidden, query_hidden, masked=False):\n",
        "    #key, query, value\n",
        "    key = self.W_key(key_hidden)\n",
        "    query = self.W_query(query_hidden)\n",
        "    value = self.W_value(key_hidden)\n",
        "\n",
        "    #get attention scores\n",
        "    attention_score = torch.matmul(query.T, key)\n",
        "\n",
        "    #masked - make upper triangle of values negative inf\n",
        "    if(masked):\n",
        "      mask = torch.triu(torch.ones_like(attention_score), diagonal=0).bool()\n",
        "      attention_score[~mask] = float('-inf')\n",
        "\n",
        "    #softmax\n",
        "    attention_dist = F.softmax(attention_score, dim=0)\n",
        "\n",
        "    #attention output - weighted sum\n",
        "    attention_output = torch.dot(attention_dist, value)\n",
        "\n",
        "    return attention_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RFJnOWSM4CxZ"
      },
      "outputs": [],
      "source": [
        "# att_node = Attention_Node(embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "odBJfqGfnoLZ"
      },
      "outputs": [],
      "source": [
        "class RNN_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, input_dim):\n",
        "    super(RNN_Node, self).__init__()\n",
        "\n",
        "    #all parameters that go into the rnn node\n",
        "    self.layer_weight = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
        "    self.hidden_weight = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.bias = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #store dimensions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dim = input_dim\n",
        "\n",
        "  #forward pass is how its connected to the next rnn node (regardless of layer or column)\n",
        "  def forward(self, input, prev_hidden):\n",
        "    #broadcast bias\n",
        "    bias = self.bias.expand(input.shape[0], self.hidden_dim)\n",
        "\n",
        "    #get hidden node\n",
        "    hidden_node = torch.sigmoid(torch.matmul(self.hidden_weight, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.layer_weight, input.T).T+\n",
        "                                     bias) #could also do tanh instead of sigmoid\n",
        "\n",
        "    return hidden_node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f8vTC4ea4iUE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xuBYxuXSsus3"
      },
      "outputs": [],
      "source": [
        "class LSTM_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, embed_dim):\n",
        "    super(LSTM_Node, self).__init__()\n",
        "\n",
        "    #forget weight / prev layer forget weight / forget bias\n",
        "    self.W_f = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_f = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_f = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #input weight / prev layer input weight / input bias\n",
        "    self.W_i = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_i = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_i = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #output weight / prev layer output weight / output bis\n",
        "    self.W_o = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_o = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_o = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #cell weight / prev layer cell weight / cell bias\n",
        "    self.W_c = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
        "    self.U_c = nn.Parameter(torch.randn(hidden_dim, embed_dim))\n",
        "    self.b_c = nn.Parameter(torch.zeros(hidden_dim))\n",
        "\n",
        "    #store dimensions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "\n",
        "  #forward pass is how its connected to the next lstm node (regardless of layer or column)\n",
        "  def forward(self, input, prev_hidden, prev_cell):\n",
        "\n",
        "\n",
        "    #broadcast bias\n",
        "    b_f = self.b_f.expand(input.shape[0], self.hidden_dim)\n",
        "    b_i = self.b_i.expand(input.shape[0], self.hidden_dim)\n",
        "    b_o = self.b_o.expand(input.shape[0], self.hidden_dim)\n",
        "    b_c = self.b_c.expand(input.shape[0], self.hidden_dim)\n",
        "\n",
        "\n",
        "    #forget\n",
        "    f_t = torch.sigmoid(torch.matmul(self.W_f, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_f, input.T).T+\n",
        "                                     b_f)\n",
        "    #input\n",
        "    i_t = torch.sigmoid(torch.matmul(self.W_i, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_i, input.T).T+\n",
        "                                     b_i)\n",
        "    #output\n",
        "    o_t = torch.sigmoid(torch.matmul(self.W_o, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_o, input.T).T+\n",
        "                                     b_o)\n",
        "\n",
        "    #new cell data\n",
        "    nc_t = torch.tanh(torch.matmul(self.W_c, prev_hidden.T).T+\n",
        "                                     torch.matmul(self.U_c, input.T).T+\n",
        "                                     b_c)\n",
        "\n",
        "    #cell\n",
        "    c_t = f_t*prev_cell + i_t*nc_t\n",
        "\n",
        "    #hidden\n",
        "    h_t = o_t*torch.tanh(c_t)\n",
        "\n",
        "    return h_t, c_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dHlOA5i1SlyU"
      },
      "outputs": [],
      "source": [
        "def add_norm(prev_x, new_x):\n",
        "  x = torch.cat(prev_x, new_x, dim=0)\n",
        "  x = nn.LayerNorm(x)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JuQ3OUL-hvFx"
      },
      "outputs": [],
      "source": [
        "class Transformer_Node(nn.Module):\n",
        "  def __init__(self, hidden_dim, embed_dim, ff_dim, decoder=False):\n",
        "    super(Transformer_Node, self).__init__()\n",
        "\n",
        "    ##layers##\n",
        "    #attention\n",
        "    self.attention = Attention_Node(hidden_dim)\n",
        "    self.decoder = decoder\n",
        "    if(decoder):\n",
        "      self.decoder_encoder_att = Attention_Node(hidden_dim)\n",
        "\n",
        "    #feed forwards\n",
        "    self.linear1 = nn.Linear(hidden_dim, ff_dim)\n",
        "    self.linear2 = nn.Linear(ff_dim, hidden_dim)\n",
        "\n",
        "\n",
        "  #how its connected to the next transformer node\n",
        "  def forward(self, inputs, encoder_hidden=None):\n",
        "    #multihead attention (with mask option) ?\n",
        "    if(self.decoder): # if decoder, only look at values before\n",
        "      attention_out = self.attention.forward(inputs, inputs, masked=True)\n",
        "    else:\n",
        "      attention_out = self.attention.forward(inputs, inputs)\n",
        "\n",
        "    #add and norm\n",
        "    x = add_norm(inputs, attention_out)\n",
        "\n",
        "    #encoder decoder attention\n",
        "    if(self.decoder):\n",
        "      x_prev = x\n",
        "      self.decoder_encoder_att.forward(encoder_hidden, x)\n",
        "      x = add_norm(x_prev, x)\n",
        "\n",
        "    x_prev = x\n",
        "    #feed forward\n",
        "    x = self.linear1(x)\n",
        "    x = self.linear2(x)\n",
        "\n",
        "    #activation function\n",
        "    x = nn.relu(x)\n",
        "\n",
        "    #add and norm\n",
        "    x = add_norm(x_prev, x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dZYVWsZ8haMS"
      },
      "outputs": [],
      "source": [
        "# class Transformer_Encoder(nn.Module):\n",
        "#   def __init__(self, hidden_dim, n_layers, vocab_size):\n",
        "#     super(Transformer_Encoder, self).__init__()\n",
        "\n",
        "#     #embedding\n",
        "#     self.embedding_node = Embedding_Node(vocab_size, hidden_dim)\n",
        "\n",
        "#     #layers\n",
        "#     self.layers = nn.ModuleList([Transformer_Node(hidden_dim) for i in range(0,n_layers)])\n",
        "\n",
        "#   def forward(self, inputs):\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "67QpPRLRXRlE"
      },
      "outputs": [],
      "source": [
        "# class Transformer_Node(nn.Module):\n",
        "#   def __init__(self, hidden_dim):\n",
        "#     super(Transformer_Node, self).__init__()\n",
        "\n",
        "#   def forward_encoder(self, inputs):\n",
        "#     pass\n",
        "\n",
        "#   def forward_decoder(self, inputs):\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZubrtWaX4r7z"
      },
      "outputs": [],
      "source": [
        "#for this, we basically said that what should be in the __init__ function should be any parameters that could be learned\n",
        "\n",
        "#ok, so for node elements, we'll say that in the __init__ funciton we should have the parameters whos weight should be learned\n",
        "#but for nn layers, well have things that define the layers/ hyperparameters\n",
        "\n",
        "#__init__ layer = anything that needs to be consistently referenced in forward pass (especially parameters that need to be updated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_LbTrPpDu0UD"
      },
      "outputs": [],
      "source": [
        "  # #define initial hidden states at run time - b/c of batch size\n",
        "  # def init_hidden(self, batch_size):\n",
        "  #   init_hidden_list = [torch.zeros(batch_size, self.hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   init_cell_list = None\n",
        "  #   if(self.node_type==\"lstm\"):\n",
        "  #     init_cell_list = [torch.zeros(batch_size, self.hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   return init_hidden_list, init_cell_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0a0efF-QRWMP"
      },
      "outputs": [],
      "source": [
        "#define initial hidden states at run time - b/c of batch size\n",
        "def init_hidden(self, batch_size):\n",
        "  #get device\n",
        "  device = next(self.parameters()).device\n",
        "\n",
        "  #itialize tens based on node type\n",
        "  init_hidden_tensor = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "  init_cell_tensor = None\n",
        "  if(self.node_type==\"lstm\"):\n",
        "    init_cell_tensor = torch.zeros(self.n_laryers, batch_size, self.hidden_dim).to(device)\n",
        "  return init_hidden_tensor, init_cell_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "li0D68hrlhen"
      },
      "outputs": [],
      "source": [
        "# input.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KUrdwxzVmO4E"
      },
      "outputs": [],
      "source": [
        "class EncoderNN(nn.Module):\n",
        "  def __init__(self, node_type, n_layers, hidden_dim, embed_dim, vocab_size):\n",
        "    super(EncoderNN, self).__init__()\n",
        "    # self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    #model parameters\n",
        "    self.n_layers = n_layers\n",
        "    self.node_type = node_type\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    #define embedding node\n",
        "    self.embedding_node = Embedding_Node(vocab_size, embed_dim)\n",
        "\n",
        "\n",
        "    #create layer of nodes based on type\n",
        "    node_class = RNN_Node if node_type == \"rnn\" else LSTM_Node\n",
        "    self.nodes = nn.ModuleList(\n",
        "          [node_class(hidden_dim, embed_dim)] +\n",
        "          [node_class(hidden_dim, hidden_dim) for _ in range(n_layers - 1)])\n",
        "\n",
        "  #forward pass\n",
        "  def forward(self, inputs):\n",
        "\n",
        "    #get blank nodes\n",
        "    node_list = self.nodes\n",
        "\n",
        "    #get shape params\n",
        "    batch_size = inputs.shape[0]\n",
        "    seq_size = inputs.shape[1]\n",
        "\n",
        "    #get initial states\n",
        "    # hidden_list, cell_list = self.init_hidden(inputs.shape[0])\n",
        "    hidden_tensor, cell_tensor = init_hidden(self, batch_size)\n",
        "    last_layer_hidden = torch.zeros(batch_size, seq_size, self.hidden_dim)\n",
        "\n",
        "    #turn input into embedding\n",
        "    embed_input = self.embedding_node.forward(inputs)\n",
        "\n",
        "    # print('this is the embedding inputs:')\n",
        "    # display(embed_input)\n",
        "\n",
        "    #store final layer hidden nodes (for attention)\n",
        "    # final_hidden_layer = []\n",
        "    # final_hidden_tensor = torch.zeros(batch_size, )\n",
        "\n",
        "\n",
        "    #iterate over each word in sentence\n",
        "    for word_i in range(0, seq_size):\n",
        "\n",
        "      input = embed_input[:,word_i] #input = (batch_size, hidden_dim) ##1 for each word\n",
        "\n",
        "      for layer in range(0,self.n_layers):\n",
        "        #if not first layer, then input is previous hidden state\n",
        "        if layer!=0:\n",
        "          input = hidden_tensor[layer-1]\n",
        "\n",
        "        #TRY TO SEE IF CAN MAKE NEATER\n",
        "        #forward pass -- TRY TO FIX LATER - AFTER TRANSFORMER\n",
        "        if(self.node_type==\"rnn\"):\n",
        "          hidden_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer]) # (batch, hidden dim)\n",
        "        elif(self.node_type=='lstm'):\n",
        "          hidden_tensor[layer], cell_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer], cell_tensor[layer]) # both of size (batch, hidden dim)\n",
        "\n",
        "      #store final hidden layer for each word - for attention\n",
        "      last_layer_hidden[:, word_i, :self.hidden_dim] = hidden_tensor[-1]\n",
        "\n",
        "    #format outputs\n",
        "    outputs = (hidden_tensor[-1], None) if self.node_type==\"rnn\" else (hidden_tensor[-1], cell_tensor[-1]) if self.node_type=='lstm' else None\n",
        "\n",
        "    return outputs, last_layer_hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nxcIFsTwXpvV"
      },
      "outputs": [],
      "source": [
        "class BeamNode(nn.Module):\n",
        "  def __init__(self, pred_vocab_indxs=[], pred_probs=[-np.inf], hidden_tens=None, cell_tens=None, parent_node=None):\n",
        "    super(BeamNode, self).__init__()\n",
        "\n",
        "    # #relationship\n",
        "    # self.parent_node = parent_node\n",
        "\n",
        "    # #values\n",
        "    # self.pred_prob = pred_prob\n",
        "    # self.pred_vocab_indx = pred_vocab_indx\n",
        "\n",
        "    #running values\n",
        "    self.pred_probs = pred_probs\n",
        "    self.pred_vocab_indxs = pred_vocab_indxs\n",
        "\n",
        "    #recurrent states\n",
        "    self.hidden_tens = hidden_tens\n",
        "    self.cell_tens = cell_tens\n",
        "\n",
        "    #current state\n",
        "    self.eof_flag = 0\n",
        "\n",
        "  def add_pred_probs(self, val):\n",
        "    self.pred_probs.append(val)\n",
        "\n",
        "  def add_pred_vocab_indx(self, val):\n",
        "    self.pred_vocab_indxs.append(val)\n",
        "\n",
        "  #calculate average log prob for comparing results\n",
        "  def avg_log_prob(self):\n",
        "    norm_score = np.sum(np.log(self.pred_probs))/len(self.pred_probs)\n",
        "    return norm_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gKiXWgCvfAuD"
      },
      "outputs": [],
      "source": [
        "class DecoderNN(nn.Module):\n",
        "  def __init__(self, node_type, n_layers, hidden_dim, embed_dim, vocab_size, attention=False):\n",
        "    super(DecoderNN, self).__init__()\n",
        "\n",
        "    #model parameters\n",
        "    self.n_layers = n_layers\n",
        "    self.node_type = node_type\n",
        "    # self.max_length = max_length\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.vocab_size = vocab_size\n",
        "\n",
        "    #define embedding node\n",
        "    self.embedding_node = Embedding_Node(vocab_size, embed_dim)\n",
        "\n",
        "    #create layer of nodes based on type\n",
        "    node_class = RNN_Node if node_type == \"rnn\" else LSTM_Node\n",
        "    self.nodes = nn.ModuleList(\n",
        "          [node_class(hidden_dim, embed_dim)] +\n",
        "          [node_class(hidden_dim, hidden_dim) for _ in range(n_layers - 1)])\n",
        "\n",
        "\n",
        "    # # #store initial hidden states\n",
        "    # # #self.hidden = torch.randn(n_layers, hidden_dim)\n",
        "    # # self.cell = torch.randn(n_layers, hidden_dim) #only really applicable for lstm\n",
        "    # self.prev_hidden = torch.randn(n_layers, hidden_dim)\n",
        "    # self.prev_cell = torch.randn(n_layers, hidden_dim) #only really applicable for lstm\n",
        "\n",
        "\n",
        "    #output weights\n",
        "    self.W_out = nn.Parameter(torch.randn(vocab_size, hidden_dim))\n",
        "\n",
        "    #attention\n",
        "    self.attention = attention\n",
        "    if(attention):\n",
        "      self.attention_node = Attention_Node(hidden_dim)\n",
        "\n",
        "\n",
        "  # #define initial hidden states at run time - b/c of batch size\n",
        "  # def init_hidden(self, batch_size):\n",
        "  #   init_hidden_list = [torch.zeros(batch_size, hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   init_cell_list = None\n",
        "  #   if(self.node_type==\"lstm\"):\n",
        "  #     init_cell_list = [torch.zeros(batch_size, hidden_dim) for _ in range(self.n_layers)]\n",
        "  #   return init_hidden_list, init_cell_list\n",
        "\n",
        "  #forward pass - considered as going over one word (versus encoder going over entire sentence) - training\n",
        "  def forward(self, input, hidden_tensor, cell_tensor=None, encoder_flayer=None):\n",
        "\n",
        "    #initial nodes\n",
        "    node_list = self.nodes\n",
        "\n",
        "    #get embedding of input\n",
        "    input = self.embedding_node.forward(input)[:,0] #only take one word\n",
        "\n",
        "    #forward pass for all layers (remember - not entire sentence, just 1 word)\n",
        "    for layer in range(0,self.n_layers):\n",
        "      #if not first layer, then input is previous hidden state\n",
        "      if layer!=0:\n",
        "        input = hidden_tensor[layer-1]\n",
        "\n",
        "      #forward pass\n",
        "      if(self.node_type==\"rnn\"):\n",
        "        hidden_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer]) # (batch, hidden dim)\n",
        "      elif(self.node_type=='lstm'):\n",
        "        hidden_tensor[layer], cell_tensor[layer] = node_list[layer].forward(input, hidden_tensor[layer], cell_tensor[layer]) # both of size (batch, hidden dim)\n",
        "\n",
        "      # print('\\nLAYER {}:'.format(layer))\n",
        "      # display(hidden_tensor)\n",
        "\n",
        "\n",
        "    #COME BACK TO ATTENTION\n",
        "    #attention\n",
        "    # if(self.attention):\n",
        "    #   attention_out = self.attention_node.forward(encoder_flayer, hidden_list[-1])\n",
        "    #   hidden_list[-1] = torch.cat((hidden_list[-1], attention_out), dim=0)\n",
        "\n",
        "    #generate final output\n",
        "    pred_output = torch.matmul(self.W_out, hidden_tensor[-1].T).T #during training - cross entropy fun converts this to prob\n",
        "\n",
        "    return hidden_tensor, cell_tensor, pred_output\n",
        "\n",
        "  #to generate predictions - generate one word at a time\n",
        "  #greedy decoding - uses/ predicts most probable word - singular\n",
        "  def pred(self, input, hidden_tens, cell_tens, encoder_flayer=None, sos_token=1,pad_token=0,eos_token=2):\n",
        "    # print('\\nIN DECODER PREDICTIONS')\n",
        "\n",
        "    # #turn to list\n",
        "    # prev_input_nodes = prev_input_nodes.tolist()\n",
        "\n",
        "    # print('\\nHIDDEN STATE IN ONE NODE')\n",
        "    # display(prev_input_nodes[0].hidden_tens)\n",
        "    # print('shape: {}'.format(prev_input_nodes[0].hidden_tens.shape))\n",
        "\n",
        "    # #unpack and format values from nodes\n",
        "    # prev_input = torch.tensor([node.pred_vocab_indxs[-1] for node in prev_input_nodes]).unsqueeze(dim=1) #dim (batch, 1)\n",
        "    # hidden_tensor = torch.stack([node.hidden_tens for node in prev_input_nodes]).permute(1,0,2) # dim (layers, batch, hidden dim)\n",
        "    # cell_tensor = torch.stack([node.cell_tens for node in prev_input_nodes]).permute(1,0,2) if prev_input_nodes[0].cell_tens!=None else None\n",
        "\n",
        "    #check if any are eof token\n",
        "\n",
        "\n",
        "    # print('this is prev input:')\n",
        "    # display(prev_input)\n",
        "    # print('prev input shape: {}'.format(prev_input.shape))\n",
        "\n",
        "\n",
        "    #adjust input\n",
        "    input = input.unsqueeze(1)\n",
        "\n",
        "    print('\\nthis is input')\n",
        "    display(input)\n",
        "    print('input shape: {}'.format(input.shape))\n",
        "\n",
        "\n",
        "    print('\\nthis is hidden_tensor')\n",
        "    display(hidden_tens)\n",
        "    print('hidden_tensor shape: {}'.format(hidden_tens.shape))\n",
        "\n",
        "    # print('\\nthis is cell_tensor')\n",
        "    # display(cell_tensor)\n",
        "    # print('cell_tensor shape: {}'.format(cell_tensor.shape))\n",
        "\n",
        "\n",
        "    #generate predicted word & others\n",
        "    hidden_tensor, cell_tensor, pred_logit = self.forward(input, hidden_tens, cell_tens, encoder_flayer)\n",
        "\n",
        "    #convert logits to prob\n",
        "    pred_prob = F.softmax(pred_logit, dim=1) #should be correct\n",
        "\n",
        "    #turn sos and pad tokens to not be possible predictions\n",
        "    pred_prob[:, sos_token] = -np.inf\n",
        "    pred_prob[:, pad_token] = -np.inf\n",
        "\n",
        "    return hidden_tensor, cell_tensor, pred_prob\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pFcsmyCYZEEy"
      },
      "outputs": [],
      "source": [
        "def print_beam_nodes(node, order_count):\n",
        "  print('\\nNode {}:'.format(order_count))\n",
        "  # print('\\tParent Node:')\n",
        "  # display(node.parent_node)\n",
        "  print('\\tPred Prob List: {}'.format(node.pred_probs))\n",
        "  print('\\tPred Vocab Index: {}'.format(node.pred_vocab_indxs))\n",
        "  print('\\tHidden Tensor:')\n",
        "  display(node.hidden_tens)\n",
        "  print('shape: {}'.format(node.hidden_tens.shape))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def avg_log_prob(prob_list):\n",
        "#   norm_score = np.sum(np.log(prob_list))/len(prob_list)\n",
        "#   return norm_score"
      ],
      "metadata": {
        "id": "-bXP3iFqyJlE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "RQS3dWtMfNjg"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder_args, decoder_args, sos_token=1, eos_token=2, pad_token=0):#, greedy=True, beam_width=2):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "\n",
        "    #model structure\n",
        "    self.encoder = EncoderNN(*encoder_args)\n",
        "    self.decoder = DecoderNN(*decoder_args)\n",
        "\n",
        "    # #set other model params to be ref later\n",
        "    # self.encoder.node_type = encoder_args[0]\n",
        "    # self.decoder.node_type = decoder_args[0]\n",
        "\n",
        "    #set other model params to be ref later\n",
        "    # self.max_length = max_length\n",
        "    self.sos_token = sos_token\n",
        "    self.eos_token = eos_token\n",
        "    self.pad_token = pad_token\n",
        "\n",
        "    # #search params\n",
        "    # self.greedy = greedy\n",
        "    # self.beam_width = beam_width\n",
        "\n",
        "    # Linear layer to project encoder hidden dim to decoder hidden dim\n",
        "    enc_hid = encoder_args[2]\n",
        "    dec_hid = decoder_args[2]\n",
        "    self.hidden_transform = nn.Linear(enc_hid, dec_hid)\n",
        "    self.cell_transform = nn.Linear(enc_hid, dec_hid)\n",
        "\n",
        "  #run encoder and initialize decoder with hidden states\n",
        "  def run_enc_init_dec(self, inputs):\n",
        "    #put on correct device\n",
        "    device = next(self.parameters()).device\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    #encoder\n",
        "    node_class = RNN_Node if self.encoder.node_type == \"rnn\" else LSTM_Node\n",
        "    (enc_hidden_node, enc_cell_node), enc_final_hidden_layer = self.encoder.forward(inputs)\n",
        "\n",
        "    #initialize hidden and cell tensor\n",
        "    dec_hidden_tensor, dec_cell_tensor = init_hidden(self.decoder, inputs.shape[0])\n",
        "\n",
        "    #linear transform encoder return values - in case hidden sizes don't match\n",
        "    dec_hidden_tensor[0] = self.hidden_transform(enc_hidden_node)\n",
        "    if (dec_cell_tensor!=None) and (enc_cell_node!=None):\n",
        "      dec_cell_tensor[0] = self.cell_transform(enc_cell_node)\n",
        "\n",
        "    return dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer\n",
        "\n",
        "\n",
        "  #for the full system\n",
        "  def forward(self, inputs, outputs):\n",
        "    #put on correct device\n",
        "    device = next(self.parameters()).device\n",
        "#    inputs = inputs.to(device)\n",
        "    outputs = outputs.to(device)\n",
        "\n",
        "    # #encoder\n",
        "    # node_class = RNN_Node if self.encoder.node_type == \"rnn\" else LSTM_Node\n",
        "    # (enc_hidden_node, enc_cell_node), enc_final_hidden_layer = self.encoder.forward(inputs)\n",
        "\n",
        "    # #initialize hidden and cell tensor\n",
        "    # dec_hidden_tensor, dec_cell_tensor = init_hidden(self.decoder, inputs.shape[0])\n",
        "\n",
        "    # #linear transform encoder return values - in case hidden sizes don't match\n",
        "    # dec_hidden_tensor[0] = self.hidden_transform(enc_hidden_node)\n",
        "    # if (dec_cell_tensor!=None) and (enc_cell_node!=None):\n",
        "    #   dec_cell_tensor[0] = self.cell_transform(enc_cell_node)\n",
        "\n",
        "    #run encoder and initialize decoder with hidden states\n",
        "    dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer = self.run_enc_init_dec(inputs)\n",
        "\n",
        "    #decoder\n",
        "    pred_out_tensor = torch.zeros(outputs.size(0), len(outputs[0]), self.decoder.vocab_size, device=device) #before was device = outputs.device\n",
        "\n",
        "    for word_pos in range(0,len(outputs[0])):\n",
        "      # print('\\nWORD POSITION: {}'.format(word_pos))\n",
        "      #get particular word position for entire batch and reshape to have 2d array\n",
        "      word_batch = outputs[:,word_pos].unsqueeze(1)\n",
        "\n",
        "      #decoder forward pass\n",
        "      dec_hidden_tensor, dec_cell_tensor, pred_out = self.decoder.forward(word_batch, dec_hidden_tensor, dec_cell_tensor, enc_final_hidden_layer)\n",
        "\n",
        "      #add value to prediction tensor\n",
        "      pred_out_tensor[:, word_pos, :] = pred_out\n",
        "\n",
        "\n",
        "    return pred_out_tensor #must make sure has shape (batch size, seq length, vocab size)\n",
        "\n",
        "  #for greedy search, beam_width = 1. ow. beam search\n",
        "  def pred(self, inputs, beam_width=1, max_length=30):\n",
        "\n",
        "    #run encoder and initialize decoder with hidden states\n",
        "    dec_hidden_tensor, dec_cell_tensor, enc_flayer = self.run_enc_init_dec(inputs)\n",
        "\n",
        "    #dimensions\n",
        "    batch_size = inputs.size(0)\n",
        "    vocab_size = self.decoder.vocab_size\n",
        "\n",
        "\n",
        "    #generate root nodes\n",
        "    pred_probs = torch.tensor([[] for _ in range(batch_size)])\n",
        "\n",
        "    last_pred_vocab = torch.tensor([self.sos_token for _ in range(batch_size)])\n",
        "    running_pred_vocab = torch.tensor([[self.sos_token] for _ in range(batch_size)])\n",
        "\n",
        "    hidden_tens = [dec_hidden_tensor[:,b,:] for b in range(batch_size)]\n",
        "    hidden_tens = torch.stack(hidden_tens, dim=1)\n",
        "    cell_tens = [dec_cell_tensor[:,b,:] for b in range(batch_size)] if dec_cell_tensor is not None else None\n",
        "    cell_tens = torch.stack(cell_tens, dim=1) if cell_tens is not None else None\n",
        "\n",
        "\n",
        "    print('\\nIN PREDICTION')\n",
        "    print('pred probs:')\n",
        "    display(pred_probs)\n",
        "    print('pred probs shape: {}'.format(pred_probs.shape))\n",
        "\n",
        "    print('\\npred vocab indxs:')\n",
        "    display(running_pred_vocab)\n",
        "    print('pred vocab indxs shape: {}'.format(running_pred_vocab.shape))\n",
        "\n",
        "    print('\\nhidden tensors')\n",
        "    display(hidden_tens)\n",
        "    print('hidden tensors shape: {}'.format(hidden_tens.shape))\n",
        "\n",
        "\n",
        "    it = 0\n",
        "    while(it<max_length):\n",
        "      print('\\nITERATION {}'.format(it))\n",
        "\n",
        "      #get indexes that are eos and not eos\n",
        "      eos_indxs = torch.nonzero(last_pred_vocab == self.eos_token).squeeze()\n",
        "      non_eos_indx = torch.nonzero(last_pred_vocab != self.eos_token).squeeze()\n",
        "\n",
        "      #if all sentences are completed\n",
        "      if(non_eos_indx.numel() == 0):\n",
        "        break\n",
        "\n",
        "      #grab non eos items\n",
        "      last_vocab_neos = last_pred_vocab[non_eos_indx]\n",
        "      hidden_tens_neos = hidden_tens[:,non_eos_indx,:]\n",
        "      cell_tens_neos = cell_tens[:,non_eos_indx,:] if cell_tens is not None else None\n",
        "\n",
        "      #generate predictions based on this\n",
        "      hidden_new_neos, cell_new_neos, pred_prob_new_neos = self.decoder.pred(last_vocab_neos, hidden_tens_neos, cell_tens_neos, sos_token=self.sos_token, pad_token=self.pad_token)\n",
        "\n",
        "\n",
        "      #fill in missing\n",
        "      hidden_tens[:,non_eos_indx,:] = hidden_new_neos\n",
        "      if(cell_tens is not None):\n",
        "        cell_tens[:,non_eos_indx,:] = cell_new_neos\n",
        "\n",
        "      #create new array in full size\n",
        "      tot_vals = len(last_pred_vocab)\n",
        "      new_shape = (tot_vals, pred_prob_new_neos.size(1))\n",
        "      pred_prob_full = torch.full(new_shape, -np.inf)\n",
        "      pred_prob_full[non_eos_indx] = pred_prob_new_neos[non_eos_indx]\n",
        "      pred_prob_full = pred_prob_full.reshape((batch_size,-1, pred_prob_full.size(1)))  # DOUBLE CHECK\n",
        "\n",
        "      print('\\npred prob full')\n",
        "      display(pred_prob_full)\n",
        "      print('pred prob full shape: {}'.format(pred_prob_full.shape))\n",
        "\n",
        "      #flatten on appropriate axis - original should be shape [[[vocab 1][vocab 2]],[[vocab 1][vocab 2]]]\n",
        "      pred_prob_full = pred_prob_full.squeeze(1)\n",
        "\n",
        "      print('\\nnew pred prob full')\n",
        "      display(pred_prob_full)\n",
        "      print('pred prob full shape: {}'.format(pred_prob_full.shape))\n",
        "\n",
        "      #find top k vals\n",
        "      topk_vals, topk_indx = torch.topk(pred_prob_full, beam_width, dim=1)\n",
        "\n",
        "      print('\\nTOP K Indx')\n",
        "      display(topk_indx)\n",
        "      print('shape: {}'.format(topk_indx.shape))\n",
        "\n",
        "      #find out which parent it belongs to\n",
        "      pred_parent_indx = (topk_indx // vocab_size).flatten()\n",
        "\n",
        "      print('\\npredicted parents')\n",
        "      display(pred_parent_indx)\n",
        "      print('shape: {}'.format(pred_parent_indx.shape))\n",
        "\n",
        "      #adjust parent indx to find out what order out of orginal total it is in\n",
        "      elem_per_batch = tot_vals//batch_size\n",
        "      batch_adj = (torch.arange(len(pred_parent_indx))//elem_per_batch)*elem_per_batch\n",
        "      pred_parent_indx_cont = pred_parent_indx + batch_adj\n",
        "\n",
        "      #find out true vocab value\n",
        "      pred_vocab_indx = (topk_indx % vocab_size).flatten()\n",
        "\n",
        "\n",
        "      #### update values ####\n",
        "      #get new possible running vals\n",
        "      new_running_pred_vocab = torch.empty((batch_size, 1)) ## DOUBLE CHECK\n",
        "      #fill in eos values\n",
        "      running_pred_vocab = running_pred_vocab.reshape((batch_size, elem_per_batch, -1))\n",
        "      new_running_pred_vocab = [\n",
        "        running_pred_vocab[batch_idx][(eos_indxs // elem_per_batch == batch_idx).nonzero(as_tuple=True)[0]]\n",
        "        for batch_idx in range(batch_size)\n",
        "      ]\n",
        "\n",
        "\n",
        "\n",
        "      #create list of dictionaries\n",
        "\n",
        "      # batch_dic = {b:{for bw in beam_width} for b in batch_size}\n",
        "\n",
        "\n",
        "\n",
        "      # #pred_prob_new_neos # shape should be [[vocab size][vocab size] x non eos vals]\n",
        "      # pred_probs_new =\n",
        "\n",
        "      # def fill_missing_values(eos_indx):\n",
        "\n",
        "\n",
        "      return\n",
        "      it+=1\n",
        "      # if(it==2):\n",
        "      #   break\n",
        "\n",
        "    #create root nodes\n",
        "    # nodes = np.array([[BeamNode(\n",
        "    #     pred_vocab_indxs=[self.sos_token],\n",
        "    #     hidden_tens=dec_hidden_tensor[:,b,:],\n",
        "    #     cell_tens=dec_cell_tensor[:b,:] if dec_cell_tensor is not None else None\n",
        "    # )] for b in batch_size])\n",
        "\n",
        "    # ### TESTING ###\n",
        "    # nodes = np.array([[\n",
        "    #     BeamNode(\n",
        "    #       # pred_probs=[-np.inf],\n",
        "    #       pred_vocab_indxs=[1],\n",
        "    #       hidden_tens=dec_hidden_tensor[:,b,:],\n",
        "    #       cell_tens=dec_cell_tensor[:b,:] if dec_cell_tensor is not None else None),\n",
        "    #     BeamNode(\n",
        "    #       # pred_probs=[-np.inf],\n",
        "    #       pred_vocab_indxs=[2],\n",
        "    #       hidden_tens=dec_hidden_tensor[:,b,:],\n",
        "    #       cell_tens=dec_cell_tensor[:b,:] if dec_cell_tensor is not None else None),\n",
        "    #     BeamNode(\n",
        "    #       # pred_probs=[-np.inf],\n",
        "    #       pred_vocab_indxs=[3],\n",
        "    #       hidden_tens=dec_hidden_tensor[:,b,:],\n",
        "    #       cell_tens=dec_cell_tensor[:b,:] if dec_cell_tensor is not None else None),\n",
        "    #     BeamNode(\n",
        "    #       # pred_probs=[-np.inf],\n",
        "    #       pred_vocab_indxs=[4],\n",
        "    #       hidden_tens=dec_hidden_tensor[:,b,:],\n",
        "    #       cell_tens=dec_cell_tensor[:b,:] if dec_cell_tensor is not None else None)\n",
        "    #     ] for b in range(batch_size)])\n",
        "\n",
        "\n",
        "\n",
        "    # print('\\nTHESE ARE THE INPUT NODES')\n",
        "    # display(nodes)\n",
        "    # print('input node shape: {}'.format(nodes.shape))\n",
        "\n",
        "    # #### just to see - testing ####\n",
        "    # count = 0\n",
        "    # for idx, x in np.ndenumerate(nodes):\n",
        "    #   print_beam_nodes(x, count)\n",
        "    #   count += 1\n",
        "\n",
        "    # #create mask\n",
        "    # size = (inputs.size(0), beam_width)\n",
        "    # mask_tens = torch.ones(size, dtype=torch.bool)\n",
        "\n",
        "    # print('\\nThis is currently the mask:')\n",
        "    # display(mask_tens)\n",
        "    # print('shape: {}'.format(mask_tens.shape))\n",
        "\n",
        "\n",
        "    # print('\\n\\nBEAM WIDTH: {}'.format(beam_width))\n",
        "    # it = 0\n",
        "    # while(mask_tens.any() and it<max_length):\n",
        "      # #unstack nodes\n",
        "      # input_nodes = nodes.flatten().tolist()\n",
        "\n",
        "      # #seperate nodes that have eof_flag=1 and eof_flag=0 -- maybe replace ones with eof=1 as None\n",
        "\n",
        "\n",
        "      # # #turn to list\n",
        "      # # prev_input_nodes = prev_input_nodes.tolist()\n",
        "\n",
        "      # #unpack and format values from nodes\n",
        "      # prev_input = torch.tensor([node.pred_vocab_indxs[-1] for node in input_nodes]).unsqueeze(dim=1) #dim (batch, 1)\n",
        "      # hidden_tensor = torch.stack([node.hidden_tens for node in input_nodes]).permute(1,0,2) # dim (layers, batch, hidden dim)\n",
        "      # cell_tensor = torch.stack([node.cell_tens for node in input_nodes]).permute(1,0,2) if input_nodes[0].cell_tens!=None else None\n",
        "\n",
        "      # #check if any prev inputs are eos\n",
        "      # eos_indx = torch.nonzero(torch.eq(prev_input, self.eos_token)).squeeze().tolist()\n",
        "      # non_eos_indxs = torch.nonzero(torch.ne(prev_input, self.eos_token)).squeeze().tolist()\n",
        "\n",
        "      # #if there are no no_eos_indxs break\n",
        "      # if (non_eos_indxs == []):\n",
        "      #   break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # #generate predictions on eos_flag=0\n",
        "      # hidden, cell, pred_prob = self.decoder.pred(input_nodes, sos_token=self.sos_token, pad_token=self.pad_token)\n",
        "\n",
        "      #\n",
        "\n",
        "      # #unstack nodes to run alomost as\n",
        "      # input_nodes = nodes.flatten()\n",
        "\n",
        "      # #generate predictions\n",
        "      # hidden, cell, pred_prob = self.decoder.pred(input_nodes, sos_token=self.sos_token, pad_token=self.pad_token)\n",
        "\n",
        "      # #group pred prob by batch\n",
        "      # new_dim = nodes.shape[1] * self.decoder.vocab_size\n",
        "      # pred_prob = pred_prob.reshape(batch_size, new_dim)\n",
        "      # print('PRED RESHAPE')\n",
        "      # display(pred_prob)\n",
        "      # print('shape: {}'.format(pred_prob.shape))\n",
        "\n",
        "      # #choose amt to keep based on beam width\n",
        "      # topk_vals, topk_indx = torch.topk(pred_prob, beam_width, dim=1)\n",
        "\n",
        "      # print('\\nTOP K VALUES')\n",
        "      # display(topk_vals)\n",
        "\n",
        "      # print('\\nTOP K INDICES')\n",
        "      # display(topk_indx)\n",
        "      # #flatten for consistancy\n",
        "      # topk_vals = topk_vals.flatten()\n",
        "\n",
        "      # #find out actual value in vocabulary\n",
        "      # pred_vocab_indx = (topk_indx % self.decoder.vocab_size).flatten()\n",
        "      # print('\\nPRED VOCAB INDX')\n",
        "      # display(pred_vocab_indx)\n",
        "      # print('shape: {}'.format(pred_vocab_indx.shape))\n",
        "\n",
        "\n",
        "      # ##find out parent indx value\n",
        "      # parent_indx = topk_indx // self.decoder.vocab_size\n",
        "\n",
        "\n",
        "      # ###########just temporarily change it\n",
        "      # parent_indx = torch.tensor([[1, 1, 2 ],\n",
        "      #               [1, 1, 2 ],\n",
        "      #               [2, 2, 1]])\n",
        "\n",
        "      # #adjust for batch\n",
        "      # row_add = (torch.arange(parent_indx.size(0)) * nodes.shape[1]).unsqueeze(1)\n",
        "      # parent_indx = (parent_indx + row_add).flatten()\n",
        "\n",
        "      # print('\\nParent indx')\n",
        "      # display(parent_indx)\n",
        "      # print('shape: {}'.format(parent_indx.shape))\n",
        "\n",
        "      # #take hidden and cell states accordingly\n",
        "      # hidden_vals = hidden[:, parent_indx,:]\n",
        "      # print('\\nHIDDEN VALS')\n",
        "      # display(hidden_vals)\n",
        "      # print('shape: {}'.format(hidden_vals.shape))\n",
        "\n",
        "      # cell_vals = cell[:, parent_indx,:] if cell is not None else None\n",
        "\n",
        "      # #get the actual parent nodes\n",
        "      # parent_nodes = input_nodes[parent_indx]\n",
        "\n",
        "      # #create new nodes\n",
        "      # total_node_count = len(topk_vals)\n",
        "      # nodes = np.array([\n",
        "      #     BeamNode(\n",
        "      #         parent_node = parent_nodes[i],\n",
        "\n",
        "      #         pred_prob = topk_vals[i],\n",
        "      #         pred_vocab_indx = pred_vocab_indx[i],\n",
        "\n",
        "      #         hidden_tens = hidden_vals[:,i,:],\n",
        "      #         cell_tens = cell_vals[:,i,:] if cell_vals!=None else None #MUST DOUBLE CHECK\n",
        "      #         )\n",
        "      # for i in range(total_node_count) ])\n",
        "\n",
        "\n",
        "      # print('\\n\\n\\nNEW NODES:')\n",
        "      # display(nodes)\n",
        "      # print('shape: {}'.format(nodes.shape))\n",
        "\n",
        "      # count = 0\n",
        "      # _ = [print_beam_nodes(nodes[i],i) for i in range(0,len(nodes))]\n",
        "\n",
        "      # #reshape accordingly\n",
        "      # nodes = nodes.reshape(batch_size, beam_width)\n",
        "\n",
        "      # print('\\nNew Nodes')\n",
        "      # display(nodes)\n",
        "      # print('shape: {}'.format(nodes.shape))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #       #relationship\n",
        "    # self.parent_node = parent_node\n",
        "\n",
        "    # #values\n",
        "    # self.pred_prob = pred_prob\n",
        "    # self.pred_vocab_indx = pred_vocab_indx\n",
        "\n",
        "    # #recurrent states\n",
        "    # self.hidden_tens = hidden_tens\n",
        "    # self.cell_tens = cell_tens\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # print('\\nCELL')\n",
        "      # display(cell)\n",
        "      # print('shape: {}'.format(cell.shape))\n",
        "\n",
        "\n",
        "      #create new nodes with information\n",
        "\n",
        "      # print('\\nHIDDEN')\n",
        "      # display(hidden)\n",
        "      # print('shape: {}'.format(hidden.shape))\n",
        "\n",
        "      # print('\\nCELL')\n",
        "      # display(cell)\n",
        "      # print('shape: {}'.format(cell.shape))\n",
        "\n",
        "      # break\n",
        "\n",
        "\n",
        "      # it+=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGhUmJQmJ2Px"
      },
      "outputs": [],
      "source": [
        "data_dict[\"English Vocabulary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3G9it0h3vuL"
      },
      "outputs": [],
      "source": [
        "#have to seperate by word\n",
        "output[:,0].reshape(len(output),1)\n",
        "# len(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFKRkAER4pI0"
      },
      "outputs": [],
      "source": [
        "prev_input = torch.tensor([[1], [1], [1]])\n",
        "prev_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUnpyblF9s4z"
      },
      "outputs": [],
      "source": [
        "input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "0eLejyzHk-V7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd0f28dc-8d66-47b9-d040-64d3c784e25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocab size: 11\n",
            "Italian vocab size: 10\n",
            "\n",
            "IN PREDICTION\n",
            "pred probs:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([], size=(3, 0))"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred probs shape: torch.Size([3, 0])\n",
            "\n",
            "pred vocab indxs:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred vocab indxs shape: torch.Size([3, 1])\n",
            "\n",
            "hidden tensors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[[-0.1367, -0.1486,  0.2058,  0.2270,  0.5152,  0.3603],\n",
              "         [-0.1374, -0.1532,  0.1975,  0.1908,  0.4879,  0.3942],\n",
              "         [-0.1201, -0.1823,  0.1834,  0.2642,  0.4904,  0.4066]],\n",
              "\n",
              "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
              "       grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden tensors shape: torch.Size([5, 3, 6])\n",
            "\n",
            "ITERATION 0\n",
            "\n",
            "this is input\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: torch.Size([3, 1])\n",
            "\n",
            "this is hidden_tensor\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[[-0.1367, -0.1486,  0.2058,  0.2270,  0.5152,  0.3603],\n",
              "         [-0.1374, -0.1532,  0.1975,  0.1908,  0.4879,  0.3942],\n",
              "         [-0.1201, -0.1823,  0.1834,  0.2642,  0.4904,  0.4066]],\n",
              "\n",
              "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_tensor shape: torch.Size([5, 3, 6])\n",
            "\n",
            "pred prob full\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[[  -inf,   -inf, 0.0457, 0.0255, 0.0211, 0.0963, 0.1371, 0.0178,\n",
              "          0.1862, 0.3557]],\n",
              "\n",
              "        [[  -inf,   -inf, 0.0457, 0.0255, 0.0211, 0.0963, 0.1371, 0.0178,\n",
              "          0.1863, 0.3558]],\n",
              "\n",
              "        [[  -inf,   -inf, 0.0457, 0.0255, 0.0211, 0.0964, 0.1370, 0.0178,\n",
              "          0.1861, 0.3558]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred prob full shape: torch.Size([3, 1, 10])\n",
            "\n",
            "new pred prob full\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[  -inf,   -inf, 0.0457, 0.0255, 0.0211, 0.0963, 0.1371, 0.0178, 0.1862,\n",
              "         0.3557],\n",
              "        [  -inf,   -inf, 0.0457, 0.0255, 0.0211, 0.0963, 0.1371, 0.0178, 0.1863,\n",
              "         0.3558],\n",
              "        [  -inf,   -inf, 0.0457, 0.0255, 0.0211, 0.0964, 0.1370, 0.0178, 0.1861,\n",
              "         0.3558]], grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred prob full shape: torch.Size([3, 10])\n",
            "\n",
            "TOP K Indx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[9, 8],\n",
              "        [9, 8],\n",
              "        [9, 8]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: torch.Size([3, 2])\n",
            "\n",
            "predicted parents\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#encoder param\n",
        "enc_node_type = \"rnn\"\n",
        "enc_n_layers = 2\n",
        "enc_hidden_dim = 4\n",
        "enc_embed_dim = 7\n",
        "eng_vocab_size = len(data_dict[\"English Vocabulary\"])\n",
        "\n",
        "#decoder_param\n",
        "dec_node_type = \"rnn\"\n",
        "dec_n_layers = 5\n",
        "dec_hidden_dim = 6\n",
        "dec_embed_dim = 8\n",
        "it_vocab_size = len(data_dict[\"Italian Vocabulary\"])\n",
        "\n",
        "#seq2seq param\n",
        "# max_length = 30\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "greedy=True\n",
        "beam_width=2\n",
        "sos_token=1\n",
        "eos_token=2\n",
        "pad_token=0\n",
        "\n",
        "# (self, node_type, n_layers, hidden_dim, embed_dim, vocab_size)\n",
        "# (self, node_type, n_layers, hidden_dim, embed_dim, vocab_size, attention=False, max_length=30)\n",
        "\n",
        "print('English vocab size: {}'.format(eng_vocab_size))\n",
        "print('Italian vocab size: {}'.format(it_vocab_size))\n",
        "\n",
        "#create seq2seq instance\n",
        "encoder_args = (enc_node_type, enc_n_layers, enc_hidden_dim, enc_embed_dim, eng_vocab_size)\n",
        "decoder_args = (dec_node_type, dec_n_layers, dec_hidden_dim, dec_embed_dim, it_vocab_size)\n",
        "seq2seq = Seq2Seq(encoder_args, decoder_args).to(device)#, greedy=greedy, beam_width=beam_width).to(device)\n",
        "\n",
        "#testing out decoder prediction\n",
        "pred_out = seq2seq.pred(input, beam_width=2)\n",
        "pred_out\n",
        "\n",
        "# temp = seq2seq.forward(input, output)\n",
        "\n",
        "# prev_input = torch.tensor([[1], [1], [1]])\n",
        "# #itialize tens based on node type\n",
        "# batch_size = 3\n",
        "# init_hidden_tensor = torch.zeros(dec_n_layers, batch_size, dec_hidden_dim).to(device)\n",
        "# init_cell_tensor = None\n",
        "# #create decoder instance\n",
        "# decoder = DecoderNN(*decoder_args)\n",
        "# hidden_tensor, cell_tensor, pred_word_indx = decoder.pred(prev_input, init_hidden_tensor, init_cell_tensor)\n",
        "# pred_word_indx\n",
        "\n",
        "#init_hidden_tensor, init_cell_tensor = init_hidden(batch_size=3)\n",
        "\n",
        "\n",
        "# #################################################\n",
        "\n",
        "# temp = seq2seq.forward(input, output)\n",
        "# print('this is seq2seq forward output')\n",
        "# display(temp)\n",
        "# print(\"output shape: {}\".format(temp.shape))\n",
        "# print(\"output type: {}\".format(type(temp)))\n",
        "# #forward step\n",
        "\n",
        "# # #encoder instance\n",
        "# encoder = EncoderNN(*encoder_args)\n",
        "# enc_out, final_hidden_layer = encoder.forward(input)\n",
        "# enc_hidden_node = enc_out[0]\n",
        "\n",
        "# print('\\n\\n\\nafter encoder test step')\n",
        "\n",
        "\n",
        "\n",
        "# #decoder instance\n",
        "# decoder = DecoderNN(*decoder_args)\n",
        "# #initialize hidden and cell list\n",
        "# dec_hidden_list, dec_cell_list = init_hidden(decoder, output.shape[0])\n",
        "# dec_hidden_list[0] = enc_hidden_node\n",
        "\n",
        "# pred_out = decoder.forward(output[:,0].reshape(len(output), 1), dec_hidden_list, None, final_hidden_layer)\n",
        "# print('\\nafter decoder test step')\n",
        "\n",
        "# #create encoder instance\n",
        "# encoder = EncoderNN(node_type, n_layers, hidden_dim, embed_dim, eng_vocab_size)\n",
        "\n",
        "# #forward step\n",
        "# hidden_list, final_hidden_layer = encoder.forward(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68w2HKH1lNK5"
      },
      "outputs": [],
      "source": [
        "print('true output')\n",
        "display(output)\n",
        "print(\"true output shape: {}\".format(output.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAVdhuINsyD3"
      },
      "source": [
        "Notes:\n",
        "\n",
        "- before running - write in comments how each dimension is looking like after each computation - helpful for debugging\n",
        "\n",
        "- incorporate batches!\n",
        "\n",
        "- transformers\n",
        "\n",
        "- beam search\n",
        "\n",
        "- bidirectional\n",
        "\n",
        "- different attention methods\n",
        "\n",
        "-- evaluate with Bleu scores\n",
        "\n",
        "\n",
        "SHOULD ADD\n",
        "- dependency parsing, pretraining, and fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X8KzhGEsRrD"
      },
      "source": [
        "Run time notes:\n",
        "\n",
        "- embedding size: Common values for the embedding dimension in NLP tasks range from 50 to 300, but larger values like 512 or 1024 can be used for more complex tasks or larger datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsAm8IVIdpr0"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT3Jpd4+r6q/HSjTaJXn8L",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}